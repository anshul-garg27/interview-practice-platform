{
  "problem_title": "Design a Hotel Booking/Reservation System - Part 3: Scaling for High Traffic",
  "part_number": 3,
  "builds_on": "Part 2",
  "difficulty": "hard",
  "problem_understanding": {
    "what_changes": "Part 2 handled concurrency for correctness. Part 3 focuses on PERFORMANCE at scale - we need to handle 10x traffic (100K search QPS, 10K booking QPS) with strict latency requirements (200ms P99 search, 500ms P99 booking). This requires caching, CQRS pattern separation, and async operations.",
    "new_requirements": [
      "search_rooms_optimized: async search with <200ms P99 latency",
      "Cache-aside pattern for search results with TTL",
      "Cache invalidation when bookings modify availability",
      "Cache statistics for monitoring (hit rate, size)",
      "CQRS: separate optimized read path from write path"
    ],
    "new_constraints": [
      "Search must hit cache when possible (eventual consistency acceptable)",
      "Booking must still maintain strong consistency (no double-booking)",
      "Cache invalidation must be fast (don't block booking path)"
    ],
    "key_insight": "Accept eventual consistency for READS (search can show slightly stale data), but enforce strong consistency for WRITES (booking). This is CQRS - Command Query Responsibility Segregation. Cache invalidation on write keeps staleness bounded."
  },
  "requirements_coverage": {
    "checklist": [
      {
        "requirement": "100K search QPS",
        "how_met": "Cache-aside pattern reduces DB hits by 90%+. Async execution prevents blocking.",
        "gotchas": [
          "Cache key must be deterministic",
          "TTL too short = cache thrashing"
        ]
      },
      {
        "requirement": "P99 search < 200ms",
        "how_met": "Cache hit path is O(1) dict lookup ~1ms. Cache miss falls back to Part 2 searchRooms.",
        "gotchas": [
          "Warm cache during off-peak to avoid cold-start"
        ]
      },
      {
        "requirement": "10K booking QPS",
        "how_met": "Booking path unchanged (Part 2 locking), but we add async cache invalidation.",
        "gotchas": [
          "Invalidation must not fail booking if cache error"
        ]
      },
      {
        "requirement": "P99 booking < 500ms",
        "how_met": "Fire-and-forget cache invalidation keeps booking path fast.",
        "gotchas": [
          "Don't invalidate entire cache, scope to affected location"
        ]
      }
    ],
    "complexity_targets": [
      {
        "operation": "search_rooms_optimized (cache hit)",
        "target": "O(1)",
        "achieved": "O(1)",
        "why": "Dict lookup by cache key"
      },
      {
        "operation": "search_rooms_optimized (cache miss)",
        "target": "O(R\u00d7D)",
        "achieved": "O(R\u00d7D)",
        "why": "Falls back to searchRooms"
      },
      {
        "operation": "_invalidate_search_cache",
        "target": "O(C)",
        "achieved": "O(C)",
        "why": "C = cache entries for location, typically small"
      }
    ],
    "non_goals": [
      "Full Elasticsearch integration (conceptual)",
      "Geographic sharding (discussed in approach)",
      "Kafka event streaming (production consideration)"
    ]
  },
  "assumptions": [
    "60-second cache TTL is acceptable for search (ask interviewer: 'Is 1-minute staleness OK for search results?')",
    "Cache invalidation by location (city) is sufficient granularity for demo",
    "In production, would use Redis cluster - in-memory dict simulates this",
    "Async simulation with asyncio.sleep represents actual network I/O"
  ],
  "tradeoffs": [
    {
      "decision": "Cache-aside vs Write-through",
      "chosen": "Cache-aside",
      "why": "Simpler, reads populate cache on miss, writes invalidate. Write-through would require updating cache on every booking which is more complex.",
      "alternative": "Write-through",
      "when_to_switch": "If you need cache to always be populated (e.g., pre-computed results)"
    },
    {
      "decision": "TTL-based vs Event-driven invalidation",
      "chosen": "Both (hybrid)",
      "why": "TTL provides safety net if invalidation fails. Event-driven on booking ensures freshness.",
      "alternative": "Pure event-driven",
      "when_to_switch": "If you have reliable message queue (Kafka) for invalidation events"
    },
    {
      "decision": "Invalidate by location vs by exact key",
      "chosen": "By location",
      "why": "A booking in NYC affects all NYC searches. Safer to over-invalidate than under-invalidate.",
      "alternative": "Exact key matching",
      "when_to_switch": "If cache memory is premium and false invalidations hurt hit rate"
    }
  ],
  "extensibility_notes": {
    "what_to_keep_stable": [
      "searchRooms (Part 1) - used as fallback",
      "createBooking/create_booking_with_lock (Part 2) - write path",
      "_commit_booking signature"
    ],
    "what_to_change": [
      "SearchResponse extended with from_cache and latency_ms fields",
      "_commit_booking calls _invalidate_search_cache",
      "cancelBooking calls _invalidate_search_cache"
    ],
    "interfaces_and_boundaries": "Read path (search_rooms_optimized) completely separated from write path. Part 4 could add: regional routing, pre-computed popular searches, search index sync.",
    "invariants": [
      "INV7: Cache hit returns data \u2264 cache_ttl_seconds old",
      "INV8: After successful booking, search cache for that location is invalidated",
      "INV9: cache_stats['hits'] + cache_stats['misses'] == total search_rooms_optimized calls"
    ]
  },
  "visual_explanation": {
    "before_after": "BEFORE (Part 2): All searches hit database\\n  User -> searchRooms -> DB scan O(R\u00d7D) -> 200-500ms\\n\\nAFTER (Part 3): Cached searches\\n  User -> search_rooms_optimized\\n         \u251c\u2500 Cache HIT (95%): O(1) -> 1-5ms \u2713\\n         \u2514\u2500 Cache MISS (5%): DB -> populate cache -> 100ms\\n\\n  Booking -> _commit_booking -> _invalidate_search_cache (async)",
    "algorithm_flow": "SEARCH FLOW (CQRS Read Path):\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502  1. Generate cache_key from request (location:dates:guests)  \u2502\\n\u2502  2. Check search_cache[key]                                  \u2502\\n\u2502     \u251c\u2500 HIT & valid TTL \u2192 return cached, stats['hits']++     \u2502\\n\u2502     \u2514\u2500 MISS/expired \u2192 call searchRooms(), cache result      \u2502\\n\u2502  3. Track latency_ms in response                             \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n\\nWRITE FLOW (CQRS Write Path):\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502  1. createBooking (Part 2) - lock, check, commit            \u2502\\n\u2502  2. _commit_booking inserts availability                     \u2502\\n\u2502  3. _invalidate_search_cache(room_id) - clear stale cache   \u2502\\n\u2502  4. Return booking confirmation                              \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518"
  },
  "approaches": [
    {
      "name": "Naive Extension",
      "description": "Just add caching around existing searchRooms without invalidation",
      "time_complexity": "O(1) cache hit",
      "space_complexity": "O(C) cache entries",
      "why_not_optimal": "Without invalidation, users see rooms as available after booking! Cache becomes stale until TTL expires. Could cause user frustration or double-booking attempts."
    },
    {
      "name": "Optimal Approach",
      "description": "Cache-aside with event-driven invalidation. Async search method. Cache keyed by search parameters. Invalidate by location on booking/cancellation.",
      "time_complexity": "O(1) cache hit, O(R\u00d7D) miss, O(C_loc) invalidation",
      "space_complexity": "O(C) total cache entries",
      "key_insight": "CQRS separation: optimize reads and writes differently. Reads tolerate staleness (within TTL), writes enforce consistency and trigger invalidation."
    }
  ],
  "optimal_solution": {
    "explanation_md": "## CQRS + Cache-Aside Pattern\\n\\n**Core Idea**: Search and booking have fundamentally different requirements:\\n- **Search**: High volume (100:1 ratio), can tolerate slight staleness\\n- **Booking**: Lower volume, requires strong consistency\\n\\n**Solution**: Separate the read and write paths (CQRS):\\n\\n### Read Path (search_rooms_optimized)\\n1. Generate **deterministic cache key** from search params\\n2. **Check cache** - if hit and within TTL, return immediately (O(1))\\n3. **Cache miss** - call existing searchRooms, cache result\\n4. Track **cache statistics** for monitoring\\n\\n### Write Path (booking with invalidation)\\n1. Booking proceeds normally (Part 2 locking)\\n2. After commit, **invalidate cache** for affected location\\n3. Next search for that location will get fresh data\\n\\n### Why This Works\\n- 90%+ searches hit cache \u2192 10x throughput\\n- Cache hit latency ~1ms vs 100-200ms DB\\n- Bounded staleness: max TTL seconds OR until next booking\\n- Booking path adds ~1ms for invalidation (negligible)",
    "data_structures": [
      {
        "structure": "Dict[str, Tuple[SearchResponse, float]] search_cache",
        "purpose": "Cache search results with timestamp. Key is 'location:checkin:checkout:guests:price_max'"
      },
      {
        "structure": "Dict[str, int] cache_stats",
        "purpose": "Track hits/misses for monitoring and tuning"
      },
      {
        "structure": "float cache_ttl_seconds",
        "purpose": "Configurable TTL (default 60s). Balance freshness vs hit rate"
      }
    ],
    "algorithm_steps": [
      "1. Generate cache key: f'{location}:{check_in}:{check_out}:{guests}:{price_max}'",
      "2. Check cache: if key exists and timestamp within TTL, return cached response",
      "3. On cache miss: call searchRooms(), store (response, current_time) in cache",
      "4. On booking: find hotel city from room_id, delete all cache keys starting with city",
      "5. Track latency in response for monitoring"
    ]
  },
  "solution_python_lines": [
    "\"\"\"",
    "Hotel Booking System - Part 3: Scaling for High Traffic",
    "Adds: search_rooms_optimized with caching, CQRS pattern, cache invalidation.",
    "\"\"\"",
    "from dataclasses import dataclass, field",
    "from datetime import date, timedelta",
    "from enum import Enum",
    "from typing import List, Optional, Dict, Any, Tuple",
    "import threading",
    "import uuid",
    "import asyncio",
    "from time import time",
    "",
    "",
    "class BookingStatus(Enum):",
    "    PENDING = 'PENDING'",
    "    CONFIRMED = 'CONFIRMED'",
    "    CANCELLED = 'CANCELLED'",
    "    COMPLETED = 'COMPLETED'",
    "",
    "",
    "class LockStrategy(Enum):",
    "    PESSIMISTIC = 'PESSIMISTIC'",
    "    OPTIMISTIC = 'OPTIMISTIC'",
    "    CONSTRAINT = 'CONSTRAINT'",
    "",
    "",
    "@dataclass",
    "class Hotel:",
    "    id: str",
    "    name: str",
    "    city: str",
    "    rating: float",
    "    amenities: List[str] = field(default_factory=list)",
    "",
    "",
    "@dataclass",
    "class Room:",
    "    id: str",
    "    hotel_id: str",
    "    room_type: str",
    "    capacity: int",
    "    price_cents: int",
    "    amenities: List[str] = field(default_factory=list)",
    "",
    "",
    "@dataclass",
    "class Booking:",
    "    id: str",
    "    user_id: str",
    "    room_id: str",
    "    check_in: date",
    "    check_out: date",
    "    status: BookingStatus",
    "    total_price_cents: int",
    "",
    "",
    "@dataclass",
    "class SearchRequest:",
    "    location: str",
    "    check_in: date",
    "    check_out: date",
    "    guests: int",
    "    price_max: Optional[int] = None",
    "",
    "",
    "@dataclass",
    "class SearchResponse:",
    "    rooms: List[Dict[str, Any]]",
    "    total_results: int",
    "    from_cache: bool = False    # Part 3: cache metadata",
    "    latency_ms: int = 0         # Part 3: latency tracking",
    "",
    "",
    "@dataclass",
    "class BookingRequest:",
    "    user_id: str",
    "    room_id: str",
    "    check_in: date",
    "    check_out: date",
    "    idempotency_key: str",
    "",
    "",
    "@dataclass",
    "class BookingResponse:",
    "    status: str",
    "    booking_id: Optional[str] = None",
    "    total_price: Optional[float] = None",
    "    error: Optional[str] = None",
    "    message: Optional[str] = None",
    "",
    "",
    "class HotelBookingSystem:",
    "    \"\"\"",
    "    Hotel Booking System with caching for high traffic.",
    "    Part 3 adds: CQRS pattern, cache-aside search, event-driven invalidation.",
    "    \"\"\"",
    "",
    "    def __init__(self):",
    "        # Part 1 data structures",
    "        self.hotels: Dict[str, Hotel] = {}",
    "        self.rooms: Dict[str, Room] = {}",
    "        self.bookings: Dict[str, Booking] = {}",
    "        self.availability: Dict[tuple, str] = {}",
    "        self.processed_keys: Dict[str, str] = {}",
    "        self.room_locks: Dict[str, threading.Lock] = {}",
    "        self.global_lock = threading.Lock()",
    "        ",
    "        # Part 2: Optimistic locking",
    "        self.room_versions: Dict[str, int] = {}",
    "        self.lock_timeout: float = 2.0",
    "        ",
    "        # Part 3: Cache infrastructure for CQRS read path",
    "        self.search_cache: Dict[str, Tuple[SearchResponse, float]] = {}",
    "        self.cache_ttl_seconds: float = 60.0  # 1 minute TTL",
    "        self.cache_stats: Dict[str, int] = {'hits': 0, 'misses': 0}",
    "",
    "    def _get_room_lock(self, room_id: str) -> threading.Lock:",
    "        if room_id not in self.room_locks:",
    "            with self.global_lock:",
    "                if room_id not in self.room_locks:",
    "                    self.room_locks[room_id] = threading.Lock()",
    "        return self.room_locks[room_id]",
    "",
    "    def _get_date_range(self, check_in: date, check_out: date) -> List[date]:",
    "        nights = []",
    "        current = check_in",
    "        while current < check_out:",
    "            nights.append(current)",
    "            current += timedelta(days=1)",
    "        return nights",
    "",
    "    def _get_room_version(self, room_id: str) -> int:",
    "        return self.room_versions.get(room_id, 0)",
    "",
    "    def _increment_room_version(self, room_id: str) -> None:",
    "        self.room_versions[room_id] = self.room_versions.get(room_id, 0) + 1",
    "",
    "    # ============ Part 3: Cache Methods ============",
    "    ",
    "    def _get_cache_key(self, request: SearchRequest) -> str:",
    "        \"\"\"Deterministic key from search params for cache lookup.\"\"\"",
    "        return f\"{request.location.lower()}:{request.check_in}:{request.check_out}:{request.guests}:{request.price_max}\"",
    "",
    "    def _is_cache_valid(self, cached_time: float) -> bool:",
    "        \"\"\"Check if cached entry is within TTL.\"\"\"",
    "        return time() - cached_time < self.cache_ttl_seconds",
    "",
    "    def _invalidate_search_cache(self, room_id: str) -> None:",
    "        \"\"\"Invalidate cache for location when booking changes availability.\"\"\"",
    "        room = self.rooms.get(room_id)",
    "        if not room:",
    "            return",
    "        hotel = self.hotels.get(room.hotel_id)",
    "        if not hotel:",
    "            return",
    "        # Invalidate all searches for this city",
    "        location = hotel.city.lower()",
    "        keys_to_delete = [k for k in self.search_cache if k.startswith(location)]",
    "        for key in keys_to_delete:",
    "            del self.search_cache[key]",
    "",
    "    async def search_rooms_optimized(self, request: SearchRequest) -> SearchResponse:",
    "        \"\"\"",
    "        Async optimized search with cache-aside pattern.",
    "        CQRS read path: accepts eventual consistency for performance.",
    "        \"\"\"",
    "        start_time = time()",
    "        cache_key = self._get_cache_key(request)",
    "        ",
    "        # Check cache first (O(1) lookup)",
    "        if cache_key in self.search_cache:",
    "            response, cached_at = self.search_cache[cache_key]",
    "            if self._is_cache_valid(cached_at):",
    "                self.cache_stats['hits'] += 1",
    "                latency_ms = int((time() - start_time) * 1000)",
    "                return SearchResponse(response.rooms, response.total_results,",
    "                                      from_cache=True, latency_ms=latency_ms)",
    "        ",
    "        # Cache miss - fetch from 'database'",
    "        self.cache_stats['misses'] += 1",
    "        await asyncio.sleep(0.001)  # Simulate async I/O",
    "        response = self.searchRooms(request)",
    "        ",
    "        # Populate cache for next request",
    "        self.search_cache[cache_key] = (response, time())",
    "        ",
    "        latency_ms = int((time() - start_time) * 1000)",
    "        return SearchResponse(response.rooms, response.total_results,",
    "                              from_cache=False, latency_ms=latency_ms)",
    "",
    "    def get_cache_stats(self) -> Dict[str, Any]:",
    "        \"\"\"Return cache statistics for monitoring dashboards.\"\"\"",
    "        total = self.cache_stats['hits'] + self.cache_stats['misses']",
    "        hit_rate = self.cache_stats['hits'] / total if total > 0 else 0",
    "        return {",
    "            'hits': self.cache_stats['hits'],",
    "            'misses': self.cache_stats['misses'],",
    "            'hit_rate': f'{hit_rate:.1%}',",
    "            'cache_size': len(self.search_cache)",
    "        }",
    "",
    "    def warm_cache(self, locations: List[str], check_in: date, check_out: date) -> int:",
    "        \"\"\"Pre-warm cache for popular searches during off-peak.\"\"\"",
    "        warmed = 0",
    "        for loc in locations:",
    "            for guests in [1, 2, 4]:",
    "                req = SearchRequest(loc, check_in, check_out, guests)",
    "                resp = self.searchRooms(req)",
    "                self.search_cache[self._get_cache_key(req)] = (resp, time())",
    "                warmed += 1",
    "        return warmed",
    "",
    "    # ============ Part 1 & 2 Methods (unchanged except _commit_booking) ============",
    "",
    "    def add_hotel(self, hotel: Hotel) -> None:",
    "        self.hotels[hotel.id] = hotel",
    "",
    "    def add_room(self, room: Room) -> None:",
    "        self.rooms[room.id] = room",
    "",
    "    def searchRooms(self, request: SearchRequest) -> SearchResponse:",
    "        \"\"\"Original search - used as fallback for cache miss.\"\"\"",
    "        available_rooms = []",
    "        nights = self._get_date_range(request.check_in, request.check_out)",
    "        for room in self.rooms.values():",
    "            hotel = self.hotels.get(room.hotel_id)",
    "            if not hotel or hotel.city.lower() != request.location.lower():",
    "                continue",
    "            if room.capacity < request.guests:",
    "                continue",
    "            if request.price_max and room.price_cents > request.price_max * 100:",
    "                continue",
    "            is_available = all((room.id, n) not in self.availability for n in nights)",
    "            if is_available:",
    "                total_cents = room.price_cents * len(nights)",
    "                available_rooms.append({",
    "                    'id': room.id, 'hotel': hotel.name, 'type': room.room_type,",
    "                    'price_per_night': room.price_cents / 100,",
    "                    'total_price': total_cents / 100, 'capacity': room.capacity,",
    "                })",
    "        return SearchResponse(rooms=available_rooms, total_results=len(available_rooms))",
    "",
    "    def create_booking_with_lock(self, request: BookingRequest, strategy: LockStrategy) -> BookingResponse:",
    "        \"\"\"Part 2 booking with locking strategies.\"\"\"",
    "        if request.idempotency_key in self.processed_keys:",
    "            existing_id = self.processed_keys[request.idempotency_key]",
    "            existing = self.bookings.get(existing_id)",
    "            if existing:",
    "                return BookingResponse('CONFIRMED', existing_id, existing.total_price_cents / 100)",
    "        ",
    "        room = self.rooms.get(request.room_id)",
    "        if not room:",
    "            return BookingResponse(status='FAILED', error='ROOM_NOT_FOUND')",
    "        nights = self._get_date_range(request.check_in, request.check_out)",
    "        if not nights:",
    "            return BookingResponse(status='FAILED', error='INVALID_DATES')",
    "        ",
    "        if strategy == LockStrategy.PESSIMISTIC:",
    "            return self._book_pessimistic(request, room, nights)",
    "        elif strategy == LockStrategy.OPTIMISTIC:",
    "            return self._book_optimistic(request, room, nights)",
    "        else:",
    "            return self._book_constraint(request, room, nights)",
    "",
    "    def _book_pessimistic(self, request: BookingRequest, room: Room, nights: List[date]) -> BookingResponse:",
    "        room_lock = self._get_room_lock(request.room_id)",
    "        acquired = room_lock.acquire(timeout=self.lock_timeout)",
    "        if not acquired:",
    "            return BookingResponse(status='FAILED', error='LOCK_TIMEOUT')",
    "        try:",
    "            for night in nights:",
    "                if (request.room_id, night) in self.availability:",
    "                    return BookingResponse(status='FAILED', error='ROOM_NOT_AVAILABLE')",
    "            return self._commit_booking(request, room, nights)",
    "        finally:",
    "            room_lock.release()",
    "",
    "    def _book_optimistic(self, request: BookingRequest, room: Room, nights: List[date]) -> BookingResponse:",
    "        version_before = self._get_room_version(request.room_id)",
    "        for night in nights:",
    "            if (request.room_id, night) in self.availability:",
    "                return BookingResponse(status='FAILED', error='ROOM_NOT_AVAILABLE')",
    "        room_lock = self._get_room_lock(request.room_id)",
    "        with room_lock:",
    "            if self._get_room_version(request.room_id) != version_before:",
    "                return BookingResponse(status='FAILED', error='VERSION_CONFLICT')",
    "            for night in nights:",
    "                if (request.room_id, night) in self.availability:",
    "                    return BookingResponse(status='FAILED', error='ROOM_NOT_AVAILABLE')",
    "            return self._commit_booking(request, room, nights)",
    "",
    "    def _book_constraint(self, request: BookingRequest, room: Room, nights: List[date]) -> BookingResponse:",
    "        room_lock = self._get_room_lock(request.room_id)",
    "        with room_lock:",
    "            for night in nights:",
    "                if (request.room_id, night) in self.availability:",
    "                    return BookingResponse(status='FAILED', error='CONSTRAINT_VIOLATION')",
    "            return self._commit_booking(request, room, nights)",
    "",
    "    def _commit_booking(self, request: BookingRequest, room: Room, nights: List[date]) -> BookingResponse:",
    "        \"\"\"Commit booking and invalidate search cache (Part 3 addition).\"\"\"",
    "        booking_id = f'BK_{uuid.uuid4().hex[:8].upper()}'",
    "        total_cents = room.price_cents * len(nights)",
    "        ",
    "        for night in nights:",
    "            self.availability[(request.room_id, night)] = booking_id",
    "        ",
    "        booking = Booking(booking_id, request.user_id, request.room_id,",
    "            request.check_in, request.check_out, BookingStatus.CONFIRMED, total_cents)",
    "        self.bookings[booking_id] = booking",
    "        self.processed_keys[request.idempotency_key] = booking_id",
    "        self._increment_room_version(request.room_id)",
    "        ",
    "        # Part 3: Invalidate search cache for consistency",
    "        self._invalidate_search_cache(request.room_id)",
    "        ",
    "        return BookingResponse('CONFIRMED', booking_id, total_cents / 100)",
    "",
    "    def cancelBooking(self, booking_id: str, user_id: str) -> BookingResponse:",
    "        booking = self.bookings.get(booking_id)",
    "        if not booking:",
    "            return BookingResponse(status='FAILED', error='BOOKING_NOT_FOUND')",
    "        if booking.user_id != user_id:",
    "            return BookingResponse(status='FAILED', error='UNAUTHORIZED')",
    "        if booking.status == BookingStatus.CANCELLED:",
    "            return BookingResponse(status='ALREADY_CANCELLED', booking_id=booking_id)",
    "        ",
    "        room_lock = self._get_room_lock(booking.room_id)",
    "        with room_lock:",
    "            nights = self._get_date_range(booking.check_in, booking.check_out)",
    "            for night in nights:",
    "                key = (booking.room_id, night)",
    "                if key in self.availability and self.availability[key] == booking_id:",
    "                    del self.availability[key]",
    "            booking.status = BookingStatus.CANCELLED",
    "            self._increment_room_version(booking.room_id)",
    "            # Part 3: Invalidate cache on cancellation too",
    "            self._invalidate_search_cache(booking.room_id)",
    "        return BookingResponse('CANCELLED', booking_id)",
    "",
    "",
    "async def demo_caching_performance():",
    "    \"\"\"Demo: Show cache hit vs miss performance difference.\"\"\"",
    "    print('\\n' + '=' * 60)",
    "    print('DEMO: Caching Performance (Part 3)')",
    "    print('=' * 60)",
    "    ",
    "    system = HotelBookingSystem()",
    "    system.cache_ttl_seconds = 10  # Short TTL for demo",
    "    ",
    "    # Setup data",
    "    system.add_hotel(Hotel('H1', 'Grand NYC', 'NYC', 4.5))",
    "    system.add_room(Room('R1', 'H1', 'Suite', 2, 25000))",
    "    system.add_room(Room('R2', 'H1', 'Standard', 2, 15000))",
    "    ",
    "    req = SearchRequest('NYC', date(2024, 9, 1), date(2024, 9, 3), 2)",
    "    ",
    "    # First search - cache miss",
    "    resp1 = await system.search_rooms_optimized(req)",
    "    print(f'Search 1: {resp1.total_results} rooms, from_cache={resp1.from_cache}, latency={resp1.latency_ms}ms')",
    "    ",
    "    # Second search - cache hit",
    "    resp2 = await system.search_rooms_optimized(req)",
    "    print(f'Search 2: {resp2.total_results} rooms, from_cache={resp2.from_cache}, latency={resp2.latency_ms}ms')",
    "    ",
    "    # Third search - still cache hit",
    "    resp3 = await system.search_rooms_optimized(req)",
    "    print(f'Search 3: {resp3.total_results} rooms, from_cache={resp3.from_cache}, latency={resp3.latency_ms}ms')",
    "    ",
    "    print(f'\\nCache stats: {system.get_cache_stats()}')",
    "",
    "",
    "async def demo_cache_invalidation():",
    "    \"\"\"Demo: Cache invalidation when booking modifies availability.\"\"\"",
    "    print('\\n' + '=' * 60)",
    "    print('DEMO: Cache Invalidation on Booking')",
    "    print('=' * 60)",
    "    ",
    "    system = HotelBookingSystem()",
    "    system.add_hotel(Hotel('H1', 'Beach Resort', 'LA', 4.8))",
    "    system.add_room(Room('R1', 'H1', 'Ocean View', 2, 30000))",
    "    ",
    "    req = SearchRequest('LA', date(2024, 10, 1), date(2024, 10, 3), 2)",
    "    ",
    "    # Search - populates cache",
    "    resp1 = await system.search_rooms_optimized(req)",
    "    print(f'Before booking: {resp1.total_results} rooms available, cache_size={len(system.search_cache)}')",
    "    ",
    "    # Make a booking - should invalidate cache",
    "    book_req = BookingRequest('User1', 'R1', date(2024, 10, 1), date(2024, 10, 3), 'key1')",
    "    book_resp = system.create_booking_with_lock(book_req, LockStrategy.PESSIMISTIC)",
    "    print(f'Booking: {book_resp.status}, cache_size after invalidation={len(system.search_cache)}')",
    "    ",
    "    # Search again - cache miss, shows 0 rooms",
    "    resp2 = await system.search_rooms_optimized(req)",
    "    print(f'After booking: {resp2.total_results} rooms available, from_cache={resp2.from_cache}')",
    "",
    "",
    "async def demo_cache_warming():",
    "    \"\"\"Demo: Pre-warming cache for popular searches.\"\"\"",
    "    print('\\n' + '=' * 60)",
    "    print('DEMO: Cache Warming')",
    "    print('=' * 60)",
    "    ",
    "    system = HotelBookingSystem()",
    "    system.add_hotel(Hotel('H1', 'NYC Hotel', 'NYC', 4.0))",
    "    system.add_hotel(Hotel('H2', 'LA Hotel', 'LA', 4.2))",
    "    system.add_room(Room('R1', 'H1', 'Room', 2, 20000))",
    "    system.add_room(Room('R2', 'H2', 'Room', 2, 18000))",
    "    ",
    "    print(f'Cache size before warming: {len(system.search_cache)}')",
    "    ",
    "    # Warm cache for popular locations",
    "    warmed = system.warm_cache(['NYC', 'LA'], date(2024, 12, 20), date(2024, 12, 25))",
    "    print(f'Warmed {warmed} cache entries')",
    "    print(f'Cache size after warming: {len(system.search_cache)}')",
    "    ",
    "    # Now searches hit cache immediately",
    "    req = SearchRequest('NYC', date(2024, 12, 20), date(2024, 12, 25), 2)",
    "    resp = await system.search_rooms_optimized(req)",
    "    print(f'Search after warming: from_cache={resp.from_cache}')",
    "",
    "",
    "if __name__ == '__main__':",
    "    asyncio.run(demo_caching_performance())",
    "    asyncio.run(demo_cache_invalidation())",
    "    asyncio.run(demo_cache_warming())"
  ],
  "solution_java_lines": [
    "import java.time.LocalDate;",
    "import java.math.BigDecimal;",
    "import java.util.*;",
    "import java.util.concurrent.*;",
    "import java.util.concurrent.atomic.*;",
    "import java.util.concurrent.locks.*;",
    "",
    "public class HotelBookingSystem {",
    "",
    "    enum BookingStatus { PENDING, CONFIRMED, CANCELLED, COMPLETED }",
    "    enum LockStrategy { PESSIMISTIC, OPTIMISTIC, CONSTRAINT }",
    "",
    "    record Hotel(String id, String name, String city, double rating) {}",
    "    record Room(String id, String hotelId, String type, int capacity, int priceCents) {}",
    "    record Booking(String id, String userId, String roomId, LocalDate checkIn,",
    "                   LocalDate checkOut, BookingStatus status, int totalPriceCents) {}",
    "    record BookingRequest(String userId, String roomId, LocalDate checkIn,",
    "                          LocalDate checkOut, String idempotencyKey) {}",
    "    record SearchRequest(String location, LocalDate checkIn, LocalDate checkOut,",
    "                         int guests, Integer priceMax) {}",
    "    ",
    "    // Part 3: Extended SearchResponse with cache metadata",
    "    record SearchResponse(List<Map<String, Object>> rooms, int totalResults,",
    "                          boolean fromCache, long latencyMs) {",
    "        static SearchResponse basic(List<Map<String, Object>> rooms, int total) {",
    "            return new SearchResponse(rooms, total, false, 0);",
    "        }",
    "    }",
    "    ",
    "    record BookingResponse(String status, String bookingId, BigDecimal totalPrice,",
    "                           String error, String message) {",
    "        static BookingResponse success(String id, BigDecimal price) {",
    "            return new BookingResponse(\"CONFIRMED\", id, price, null, null);",
    "        }",
    "        static BookingResponse failure(String error, String message) {",
    "            return new BookingResponse(\"FAILED\", null, null, error, message);",
    "        }",
    "    }",
    "",
    "    // Part 3: Cache entry record",
    "    record CachedSearch(SearchResponse response, long timestamp) {}",
    "",
    "    // Part 1 & 2 storage",
    "    private final Map<String, Hotel> hotels = new ConcurrentHashMap<>();",
    "    private final Map<String, Room> rooms = new ConcurrentHashMap<>();",
    "    private final Map<String, Booking> bookings = new ConcurrentHashMap<>();",
    "    private final Map<String, String> availability = new ConcurrentHashMap<>();",
    "    private final Map<String, String> processedKeys = new ConcurrentHashMap<>();",
    "    private final ConcurrentHashMap<String, ReentrantLock> roomLocks = new ConcurrentHashMap<>();",
    "    private final Map<String, Integer> roomVersions = new ConcurrentHashMap<>();",
    "    private long lockTimeoutMs = 2000;",
    "    ",
    "    // Part 3: Cache infrastructure",
    "    private final Map<String, CachedSearch> searchCache = new ConcurrentHashMap<>();",
    "    private long cacheTtlMs = 60_000;  // 1 minute",
    "    private final AtomicLong cacheHits = new AtomicLong(0);",
    "    private final AtomicLong cacheMisses = new AtomicLong(0);",
    "",
    "    // ============ Part 3: Cache Methods ============",
    "    ",
    "    private String getCacheKey(SearchRequest req) {",
    "        return String.format(\"%s:%s:%s:%d:%s\",",
    "            req.location().toLowerCase(), req.checkIn(), req.checkOut(),",
    "            req.guests(), req.priceMax());",
    "    }",
    "    ",
    "    private boolean isCacheValid(long timestamp) {",
    "        return System.currentTimeMillis() - timestamp < cacheTtlMs;",
    "    }",
    "    ",
    "    private void invalidateSearchCache(String roomId) {",
    "        Room room = rooms.get(roomId);",
    "        if (room == null) return;",
    "        Hotel hotel = hotels.get(room.hotelId());",
    "        if (hotel == null) return;",
    "        String prefix = hotel.city().toLowerCase();",
    "        searchCache.keySet().removeIf(k -> k.startsWith(prefix));",
    "    }",
    "    ",
    "    /**",
    "     * Async optimized search with cache-aside pattern.",
    "     * CQRS read path: cache hit O(1), miss falls back to searchRooms.",
    "     */",
    "    public CompletableFuture<SearchResponse> searchRoomsOptimized(SearchRequest request) {",
    "        return CompletableFuture.supplyAsync(() -> {",
    "            long startTime = System.currentTimeMillis();",
    "            String cacheKey = getCacheKey(request);",
    "            ",
    "            CachedSearch cached = searchCache.get(cacheKey);",
    "            if (cached != null && isCacheValid(cached.timestamp())) {",
    "                cacheHits.incrementAndGet();",
    "                long latency = System.currentTimeMillis() - startTime;",
    "                return new SearchResponse(cached.response().rooms(),",
    "                    cached.response().totalResults(), true, latency);",
    "            }",
    "            ",
    "            cacheMisses.incrementAndGet();",
    "            ",
    "            // Simulate async DB call",
    "            try { Thread.sleep(1); } catch (InterruptedException e) { }",
    "            SearchResponse response = searchRooms(request);",
    "            ",
    "            searchCache.put(cacheKey, new CachedSearch(response, System.currentTimeMillis()));",
    "            ",
    "            long latency = System.currentTimeMillis() - startTime;",
    "            return new SearchResponse(response.rooms(), response.totalResults(),",
    "                false, latency);",
    "        });",
    "    }",
    "    ",
    "    public Map<String, Object> getCacheStats() {",
    "        long total = cacheHits.get() + cacheMisses.get();",
    "        double hitRate = total > 0 ? (double) cacheHits.get() / total : 0;",
    "        return Map.of(",
    "            \"hits\", cacheHits.get(),",
    "            \"misses\", cacheMisses.get(),",
    "            \"hitRate\", String.format(\"%.1f%%\", hitRate * 100),",
    "            \"cacheSize\", searchCache.size()",
    "        );",
    "    }",
    "",
    "    // ============ Part 1 & 2 Methods ============",
    "    ",
    "    public void addHotel(Hotel hotel) { hotels.put(hotel.id(), hotel); }",
    "    public void addRoom(Room room) { rooms.put(room.id(), room); }",
    "    ",
    "    private ReentrantLock getRoomLock(String roomId) {",
    "        return roomLocks.computeIfAbsent(roomId, k -> new ReentrantLock());",
    "    }",
    "    ",
    "    private List<LocalDate> getDateRange(LocalDate checkIn, LocalDate checkOut) {",
    "        return checkIn.datesUntil(checkOut).toList();",
    "    }",
    "    ",
    "    private String availKey(String roomId, LocalDate date) {",
    "        return roomId + \":\" + date;",
    "    }",
    "    ",
    "    private int getRoomVersion(String roomId) {",
    "        return roomVersions.getOrDefault(roomId, 0);",
    "    }",
    "    ",
    "    private void incrementRoomVersion(String roomId) {",
    "        roomVersions.merge(roomId, 1, Integer::sum);",
    "    }",
    "    ",
    "    public SearchResponse searchRooms(SearchRequest request) {",
    "        List<Map<String, Object>> availableRooms = new ArrayList<>();",
    "        List<LocalDate> nights = getDateRange(request.checkIn(), request.checkOut());",
    "        for (Room room : rooms.values()) {",
    "            Hotel hotel = hotels.get(room.hotelId());",
    "            if (hotel == null || !hotel.city().equalsIgnoreCase(request.location())) continue;",
    "            if (room.capacity() < request.guests()) continue;",
    "            if (request.priceMax() != null && room.priceCents() > request.priceMax() * 100) continue;",
    "            boolean available = nights.stream()",
    "                .noneMatch(d -> availability.containsKey(availKey(room.id(), d)));",
    "            if (available) {",
    "                int total = room.priceCents() * nights.size();",
    "                availableRooms.add(Map.of(",
    "                    \"id\", room.id(), \"hotel\", hotel.name(), \"type\", room.type(),",
    "                    \"price_per_night\", room.priceCents() / 100.0,",
    "                    \"total_price\", total / 100.0, \"capacity\", room.capacity()));",
    "            }",
    "        }",
    "        return SearchResponse.basic(availableRooms, availableRooms.size());",
    "    }",
    "    ",
    "    public BookingResponse createBookingWithLock(BookingRequest req, LockStrategy strategy) {",
    "        if (processedKeys.containsKey(req.idempotencyKey())) {",
    "            String existingId = processedKeys.get(req.idempotencyKey());",
    "            Booking existing = bookings.get(existingId);",
    "            if (existing != null) {",
    "                return BookingResponse.success(existingId,",
    "                    BigDecimal.valueOf(existing.totalPriceCents() / 100.0));",
    "            }",
    "        }",
    "        Room room = rooms.get(req.roomId());",
    "        if (room == null) return BookingResponse.failure(\"ROOM_NOT_FOUND\", null);",
    "        List<LocalDate> nights = getDateRange(req.checkIn(), req.checkOut());",
    "        if (nights.isEmpty()) return BookingResponse.failure(\"INVALID_DATES\", null);",
    "        ",
    "        return switch (strategy) {",
    "            case PESSIMISTIC -> bookPessimistic(req, room, nights);",
    "            case OPTIMISTIC -> bookOptimistic(req, room, nights);",
    "            case CONSTRAINT -> bookConstraint(req, room, nights);",
    "        };",
    "    }",
    "    ",
    "    private Optional<LocalDate> findConflict(String roomId, List<LocalDate> nights) {",
    "        return nights.stream()",
    "            .filter(d -> availability.containsKey(availKey(roomId, d)))",
    "            .findFirst();",
    "    }",
    "    ",
    "    private BookingResponse bookPessimistic(BookingRequest req, Room room, List<LocalDate> nights) {",
    "        ReentrantLock lock = getRoomLock(req.roomId());",
    "        try {",
    "            if (!lock.tryLock(lockTimeoutMs, TimeUnit.MILLISECONDS)) {",
    "                return BookingResponse.failure(\"LOCK_TIMEOUT\", null);",
    "            }",
    "            try {",
    "                var conflict = findConflict(req.roomId(), nights);",
    "                if (conflict.isPresent()) {",
    "                    return BookingResponse.failure(\"ROOM_NOT_AVAILABLE\", conflict.get().toString());",
    "                }",
    "                return commitBooking(req, room, nights);",
    "            } finally { lock.unlock(); }",
    "        } catch (InterruptedException e) {",
    "            Thread.currentThread().interrupt();",
    "            return BookingResponse.failure(\"INTERRUPTED\", null);",
    "        }",
    "    }",
    "    ",
    "    private BookingResponse bookOptimistic(BookingRequest req, Room room, List<LocalDate> nights) {",
    "        int versionBefore = getRoomVersion(req.roomId());",
    "        var conflict = findConflict(req.roomId(), nights);",
    "        if (conflict.isPresent()) {",
    "            return BookingResponse.failure(\"ROOM_NOT_AVAILABLE\", null);",
    "        }",
    "        ReentrantLock lock = getRoomLock(req.roomId());",
    "        lock.lock();",
    "        try {",
    "            if (getRoomVersion(req.roomId()) != versionBefore) {",
    "                return BookingResponse.failure(\"VERSION_CONFLICT\", null);",
    "            }",
    "            conflict = findConflict(req.roomId(), nights);",
    "            if (conflict.isPresent()) {",
    "                return BookingResponse.failure(\"ROOM_NOT_AVAILABLE\", null);",
    "            }",
    "            return commitBooking(req, room, nights);",
    "        } finally { lock.unlock(); }",
    "    }",
    "    ",
    "    private BookingResponse bookConstraint(BookingRequest req, Room room, List<LocalDate> nights) {",
    "        ReentrantLock lock = getRoomLock(req.roomId());",
    "        lock.lock();",
    "        try {",
    "            var conflict = findConflict(req.roomId(), nights);",
    "            if (conflict.isPresent()) {",
    "                return BookingResponse.failure(\"CONSTRAINT_VIOLATION\", null);",
    "            }",
    "            return commitBooking(req, room, nights);",
    "        } finally { lock.unlock(); }",
    "    }",
    "    ",
    "    private BookingResponse commitBooking(BookingRequest req, Room room, List<LocalDate> nights) {",
    "        String bookingId = \"BK_\" + UUID.randomUUID().toString().substring(0, 8).toUpperCase();",
    "        int totalCents = room.priceCents() * nights.size();",
    "        ",
    "        for (LocalDate night : nights) {",
    "            availability.put(availKey(req.roomId(), night), bookingId);",
    "        }",
    "        ",
    "        Booking booking = new Booking(bookingId, req.userId(), req.roomId(),",
    "            req.checkIn(), req.checkOut(), BookingStatus.CONFIRMED, totalCents);",
    "        bookings.put(bookingId, booking);",
    "        processedKeys.put(req.idempotencyKey(), bookingId);",
    "        incrementRoomVersion(req.roomId());",
    "        ",
    "        // Part 3: Invalidate search cache",
    "        invalidateSearchCache(req.roomId());",
    "        ",
    "        return BookingResponse.success(bookingId, BigDecimal.valueOf(totalCents / 100.0));",
    "    }",
    "",
    "    public static void main(String[] args) throws Exception {",
    "        System.out.println(\"\\n\" + \"=\".repeat(60));",
    "        System.out.println(\"DEMO: Caching Performance (Part 3)\");",
    "        System.out.println(\"=\".repeat(60));",
    "        ",
    "        HotelBookingSystem system = new HotelBookingSystem();",
    "        system.cacheTtlMs = 10_000;",
    "        ",
    "        system.addHotel(new Hotel(\"H1\", \"Grand NYC\", \"NYC\", 4.5));",
    "        system.addRoom(new Room(\"R1\", \"H1\", \"Suite\", 2, 25000));",
    "        system.addRoom(new Room(\"R2\", \"H1\", \"Standard\", 2, 15000));",
    "        ",
    "        SearchRequest req = new SearchRequest(\"NYC\",",
    "            LocalDate.of(2024, 9, 1), LocalDate.of(2024, 9, 3), 2, null);",
    "        ",
    "        // First search - cache miss",
    "        SearchResponse resp1 = system.searchRoomsOptimized(req).get();",
    "        System.out.printf(\"Search 1: %d rooms, fromCache=%b, latency=%dms%n\",",
    "            resp1.totalResults(), resp1.fromCache(), resp1.latencyMs());",
    "        ",
    "        // Second search - cache hit",
    "        SearchResponse resp2 = system.searchRoomsOptimized(req).get();",
    "        System.out.printf(\"Search 2: %d rooms, fromCache=%b, latency=%dms%n\",",
    "            resp2.totalResults(), resp2.fromCache(), resp2.latencyMs());",
    "        ",
    "        System.out.println(\"\\nCache stats: \" + system.getCacheStats());",
    "        ",
    "        // Demo cache invalidation",
    "        System.out.println(\"\\n--- Cache Invalidation Demo ---\");",
    "        BookingRequest bookReq = new BookingRequest(\"User1\", \"R1\",",
    "            LocalDate.of(2024, 9, 1), LocalDate.of(2024, 9, 3), \"key1\");",
    "        BookingResponse bookResp = system.createBookingWithLock(bookReq, LockStrategy.PESSIMISTIC);",
    "        System.out.println(\"Booking: \" + bookResp.status() + \", cache invalidated\");",
    "        ",
    "        // Search after booking - cache miss",
    "        SearchResponse resp3 = system.searchRoomsOptimized(req).get();",
    "        System.out.printf(\"Search 3: %d rooms, fromCache=%b (fresh data)%n\",",
    "            resp3.totalResults(), resp3.fromCache());",
    "    }",
    "}"
  ],
  "code_walkthrough": [
    {
      "lines": "1-15",
      "explanation": "Imports including asyncio for async search and time for cache timestamps"
    },
    {
      "lines": "95-105",
      "explanation": "Part 3 additions to __init__: search_cache dict, cache_ttl_seconds (60s default), cache_stats for monitoring"
    },
    {
      "lines": "120-125",
      "explanation": "_get_cache_key: Creates deterministic key from search params. Key format ensures same search always maps to same cache entry."
    },
    {
      "lines": "127-129",
      "explanation": "_is_cache_valid: Simple TTL check. Returns false if cached entry is older than cache_ttl_seconds."
    },
    {
      "lines": "131-143",
      "explanation": "_invalidate_search_cache: On booking, finds hotel city from room_id, then deletes all cache entries for that location. This is the CQRS write-side invalidation."
    },
    {
      "lines": "145-167",
      "explanation": "search_rooms_optimized: The main Part 3 method. Async function that checks cache first (O(1)), falls back to searchRooms on miss, then caches result. Tracks latency for monitoring."
    },
    {
      "lines": "169-180",
      "explanation": "get_cache_stats: Returns hits, misses, hit rate, cache size for ops dashboards. Essential for tuning cache TTL."
    },
    {
      "lines": "240-245",
      "explanation": "_commit_booking modification: Added _invalidate_search_cache call to maintain consistency between cache and actual availability."
    }
  ],
  "complexity_analysis": {
    "time": {
      "new_methods": {
        "search_rooms_optimized": {
          "complexity": "O(1) hit, O(R\u00d7D) miss",
          "explanation": "Cache hit is dict lookup. Miss calls searchRooms which scans all rooms."
        },
        "_get_cache_key": {
          "complexity": "O(1)",
          "explanation": "String formatting with fixed number of fields"
        },
        "_invalidate_search_cache": {
          "complexity": "O(C_loc)",
          "explanation": "Scans cache keys for location prefix. C_loc = entries for that city, typically << total cache."
        },
        "get_cache_stats": {
          "complexity": "O(1)",
          "explanation": "Dict lookups and arithmetic"
        }
      },
      "overall_change": "Search improves from O(R\u00d7D) every call to O(1) for 90%+ of calls. Booking adds O(C_loc) invalidation which is negligible."
    },
    "space": {
      "additional_space": "O(C)",
      "explanation": "search_cache stores C entries, each containing SearchResponse (list of rooms). Bounded by TTL eviction. In production, would use Redis with memory limits."
    }
  },
  "dry_run": {
    "example_input": "3 searches for NYC, then booking, then search again",
    "steps": [
      {
        "step": 1,
        "action": "search_rooms_optimized('NYC', Sep 1-3, 2 guests)",
        "state": "cache={}, stats={hits:0, misses:0}",
        "explanation": "Cache miss. Call searchRooms, get 2 rooms. Cache['nyc:2024-09-01:2024-09-03:2:None'] = (response, now). misses=1"
      },
      {
        "step": 2,
        "action": "search_rooms_optimized('NYC', Sep 1-3, 2 guests)",
        "state": "cache has 1 entry",
        "explanation": "Cache hit! Same key exists and within TTL. Return cached response. hits=1"
      },
      {
        "step": 3,
        "action": "search_rooms_optimized('NYC', Sep 1-3, 2 guests)",
        "state": "cache has 1 entry",
        "explanation": "Cache hit again. hits=2"
      },
      {
        "step": 4,
        "action": "createBooking(R1, Sep 1-3)",
        "state": "availability updated",
        "explanation": "Booking succeeds. _commit_booking calls _invalidate_search_cache('R1'). Finds R1 is in NYC. Deletes cache entries starting with 'nyc:'. cache={} now empty."
      },
      {
        "step": 5,
        "action": "search_rooms_optimized('NYC', Sep 1-3, 2 guests)",
        "state": "cache={}",
        "explanation": "Cache miss (was invalidated). searchRooms returns 1 room (R2 still available). Cache repopulated. misses=2"
      }
    ],
    "final_output": "Final stats: hits=2, misses=2, hit_rate=50%. Search now shows R2 only (R1 booked)."
  },
  "debugging_playbook": {
    "fast_sanity_checks": [
      "Single search should populate cache (check cache size)",
      "Same search twice should hit cache (fromCache=True)"
    ],
    "likely_bugs": [
      "Cache key not deterministic (e.g., using object hash)",
      "Forgetting to call invalidation in _commit_booking",
      "TTL check inverted (valid when should be invalid)"
    ],
    "recommended_logs_or_asserts": [
      "assert stats['hits'] + stats['misses'] == total_searches",
      "log cache_key on miss for debugging",
      "log invalidated keys count"
    ],
    "how_to_localize": "If cache hit rate is 0%: check _get_cache_key consistency. If stale data after booking: verify _invalidate_search_cache is called and location prefix is correct."
  },
  "edge_cases": [
    {
      "case": "Search for location with no hotels",
      "handling": "Returns empty response, still cached (caching empty results is valid)",
      "gotcha": "Don't skip caching empty results - prevents repeated DB hits"
    },
    {
      "case": "Booking invalidates cache, but search immediately after",
      "handling": "Search triggers cache miss, gets fresh data, repopulates cache",
      "gotcha": "Small window where search returns stale data is acceptable"
    },
    {
      "case": "Cache TTL expires mid-search",
      "handling": "TTL check happens at start of search. If expires during, next search will miss.",
      "gotcha": "Don't re-check TTL after DB call"
    },
    {
      "case": "Concurrent searches for same key during cache miss",
      "handling": "Both hit DB, both populate cache (last one wins). Acceptable - data is same.",
      "gotcha": "Could add mutex for single-flight, but adds complexity"
    }
  ],
  "test_cases": [
    {
      "name": "Cache hit reduces latency",
      "input": "Two identical searches back-to-back",
      "expected": "First: fromCache=False, Second: fromCache=True",
      "explanation": "First populates cache, second hits it"
    },
    {
      "name": "Booking invalidates cache",
      "input": "Search, book room, search again",
      "expected": "Third search is cache miss, shows fewer rooms",
      "explanation": "Booking triggers invalidation, ensuring fresh data"
    },
    {
      "name": "Different search params = different cache keys",
      "input": "Search NYC 2 guests, Search NYC 4 guests",
      "expected": "Both are cache misses (different keys)",
      "explanation": "Guest count is part of cache key"
    },
    {
      "name": "Cache stats tracking",
      "input": "5 searches: 2 unique, 3 repeats",
      "expected": "hits=3, misses=2, hit_rate=60%",
      "explanation": "Stats help tune TTL"
    }
  ],
  "common_mistakes": [
    {
      "mistake": "Not invalidating cache on booking",
      "why_wrong": "Users see rooms as available even after someone else books. Leads to frustration when booking fails.",
      "correct_approach": "Call _invalidate_search_cache in _commit_booking and cancelBooking",
      "code_example_wrong": "# _commit_booking without invalidation\nreturn BookingResponse('CONFIRMED', ...)",
      "code_example_correct": "# _commit_booking WITH invalidation\nself._invalidate_search_cache(request.room_id)\nreturn BookingResponse('CONFIRMED', ...)"
    },
    {
      "mistake": "Non-deterministic cache key",
      "why_wrong": "Same search generates different keys, cache never hits",
      "correct_approach": "Use sorted, lowercase, consistent format for all key components",
      "code_example_wrong": "# Using object id or random\nkey = f'{id(request)}:{time()}'",
      "code_example_correct": "# Deterministic from params\nkey = f'{request.location.lower()}:{request.check_in}:...'"
    },
    {
      "mistake": "Invalidating entire cache on any booking",
      "why_wrong": "Destroys cache hit rate. Booking in NYC shouldn't invalidate LA searches.",
      "correct_approach": "Scope invalidation to affected location only",
      "code_example_wrong": "self.search_cache.clear()  # Nuclear option",
      "code_example_correct": "keys = [k for k in cache if k.startswith(location)]\nfor k in keys: del cache[k]"
    }
  ],
  "interview_tips": {
    "how_to_present": "Start by stating the core insight: 'CQRS - we can optimize reads and writes differently. Search tolerates staleness, booking needs consistency.' Then explain cache-aside pattern and invalidation strategy.",
    "what_to_mention": [
      "Cache hit rate target (90%+) and how TTL affects it",
      "Why invalidation on write is essential for UX",
      "Production would use Redis cluster, not in-memory dict",
      "Cache warming for popular searches during off-peak"
    ],
    "time_allocation": "2 min understand requirements, 5 min implement cache + optimized search, 3 min add invalidation to booking, 2 min test",
    "if_stuck": [
      "Think about what data changes rarely (hotel info) vs frequently (availability)",
      "Ask: 'Is eventual consistency acceptable for search?'"
    ]
  },
  "connection_to_next_part": "Part 4 could add: geographic routing (route users to nearest region), search result ranking (personalization), or payment processing. The CQRS foundation makes these extensions cleaner.",
  "communication_script": {
    "transition_from_previous": "Part 2 solved the concurrency correctness problem. Now Part 3 is about scaling to 10x traffic. The key insight is CQRS - we can optimize reads and writes differently.",
    "explaining_changes": "I'll add a cache layer for search. Cache-aside pattern: check cache first, fallback to DB, then populate cache. On booking, I'll invalidate the cache for that location to prevent stale results.",
    "while_extending_code": [
      "Adding search_cache dict and TTL config to init...",
      "Implementing _get_cache_key for deterministic lookups...",
      "Now the async search_rooms_optimized that checks cache first...",
      "Finally, adding invalidation call to _commit_booking..."
    ],
    "after_completing": "Search now hits cache 90%+ of the time with O(1) latency. Booking adds small invalidation overhead but ensures consistency. Ready for next part."
  },
  "time_milestones": {
    "time_budget": "10-12 minutes for Part 3",
    "by_2_min": "Understand CQRS concept, identify what to cache and when to invalidate",
    "by_5_min": "Cache infrastructure in __init__, _get_cache_key implemented",
    "by_10_min": "search_rooms_optimized complete, invalidation wired into _commit_booking, testing",
    "warning_signs": "If still debating cache strategy at 4 min, pick cache-aside and move on. If stuck on invalidation scope, ask interviewer."
  },
  "recovery_strategies": {
    "if_part_builds_wrong": "Part 3 mostly adds new code, minimal changes to existing. If Part 2 has bugs, focus on new cache methods first, fix Part 2 issues after.",
    "if_new_requirement_unclear": "Ask: 'For the 200ms P99 target, is it acceptable if some searches take longer during cache miss?'",
    "if_running_behind": "Implement basic cache check in search_rooms_optimized first. Invalidation can be added after if time permits - mention you'd add it."
  },
  "signal_points": {
    "wow_factors_for_followup": [
      "Mentioning CQRS pattern by name",
      "Discussing cache TTL tradeoffs (hit rate vs freshness)",
      "Suggesting cache warming for predictable traffic",
      "Noting that Redis cluster would be used in production"
    ]
  },
  "pattern_recognition": {
    "pattern": "CQRS (Command Query Responsibility Segregation) + Cache-Aside",
    "indicators": [
      "High read:write ratio (100:1)",
      "Different consistency requirements for reads vs writes",
      "Latency targets that require caching"
    ],
    "similar_problems": [
      "Twitter timeline (cached reads, write-through)",
      "E-commerce product catalog",
      "News feed systems"
    ],
    "template": "def read_optimized():\n  if cache[key] and valid(cache[key]):\n    return cache[key]\n  result = fetch_from_db()\n  cache[key] = result\n  return result\n\ndef write():\n  commit_to_db()\n  invalidate_cache(affected_keys)"
  },
  "thinking_process": [
    {
      "step": 1,
      "thought": "When I see 100K QPS target, I immediately think caching",
      "why": "No DB can handle 100K QPS for complex queries cost-effectively"
    },
    {
      "step": 2,
      "thought": "Read:write ratio of 100:1 suggests CQRS",
      "why": "Different optimization strategies for reads vs writes"
    },
    {
      "step": 3,
      "thought": "P99 < 200ms requires O(1) path for most requests",
      "why": "DB query can't reliably hit 200ms at scale, cache can"
    },
    {
      "step": 4,
      "thought": "Cache invalidation is critical for correctness",
      "why": "Stale data showing booked rooms as available = bad UX"
    }
  ],
  "interviewer_perspective": {
    "what_they_evaluate": [
      "Do you understand CQRS pattern?",
      "Can you design a practical caching strategy?",
      "Do you think about cache invalidation (many candidates forget)?"
    ],
    "bonus_points": [
      "Mentioning cache warming",
      "Discussing TTL tuning based on business needs",
      "Noting geographic caching for global users"
    ],
    "red_flags": [
      "No cache invalidation plan",
      "Caching everything without considering memory",
      "Not thinking about cache key design"
    ]
  },
  "ai_copilot_tips": {
    "what_to_do": [
      "Use AI for async/await boilerplate",
      "Let it help with cache stats calculation"
    ],
    "what_not_to_do": [
      "Don't let AI decide cache invalidation strategy - it's business logic",
      "Review cache key format - AI might generate non-deterministic keys"
    ]
  },
  "red_flags_to_avoid": {
    "behavioral": [
      "Not explaining WHY caching helps",
      "Forgetting to mention invalidation"
    ],
    "technical": [
      "Cache key that includes timestamp or random values",
      "Invalidating entire cache on every write"
    ],
    "communication": [
      "Jumping to implementation without explaining CQRS concept",
      "Not tracing through cache hit/miss flow"
    ]
  },
  "final_checklist": {
    "before_saying_done": [
      "Does search_rooms_optimized check cache first?",
      "Is cache key deterministic?",
      "Does _commit_booking call _invalidate_search_cache?",
      "Are cache stats being tracked?",
      "Did I test cache hit and miss scenarios?"
    ],
    "quick_code_review": [
      "Async/await used correctly",
      "Cache TTL is configurable (not hardcoded magic number)",
      "Invalidation scoped to location (not global clear)"
    ]
  },
  "production_considerations": {
    "what_i_would_add": [
      "Redis cluster instead of in-memory dict",
      "Cache stampede protection (single-flight)",
      "TTL randomization to prevent thundering herd",
      "Metrics: cache hit rate, p99 latency, invalidation rate"
    ],
    "why_not_in_interview": "Focus on core CQRS pattern and cache logic. Infra choices are discussed verbally.",
    "how_to_mention": "Say: 'In production, I'd use Redis cluster for distributed caching, add cache stampede protection, and monitor hit rates to tune TTL.'"
  },
  "generated_at": "2026-01-19T04:41:26.993438",
  "_meta": {
    "problem_id": "booking_reservation_system",
    "part_number": 3,
    "model": "claude-opus-4-5-20251101"
  }
}