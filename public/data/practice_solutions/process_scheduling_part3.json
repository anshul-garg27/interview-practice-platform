{
  "problem_title": "Process Scheduling on Processors - Part 3: Token Bucket Rate Limiter",
  "part_number": 3,
  "builds_on": "Part 2",
  "difficulty": "medium",
  "problem_understanding": {
    "what_changes": "This is a completely separate design problem asked in the same interview loop. Instead of process scheduling, we're designing a token bucket rate limiter - a classic system design component. The bucket holds tokens up to a capacity, with optional 'dripping' that fills the bucket over time at a configurable rate.",
    "new_requirements": [
      "Implement TokenBucket class with capacity-limited token storage",
      "add(token) - Add token, return false if bucket full",
      "get() - Peek at token without removing, return null if empty",
      "set_drip_rate(rate) - Enable automatic token generation at r tokens/second",
      "Dripped tokens accumulate lazily and fill available capacity"
    ],
    "new_constraints": [
      "Bucket cannot exceed capacity",
      "Dripped tokens must be computed lazily (not actually stored until needed)",
      "get() does NOT remove tokens - it's a peek operation",
      "Dripped tokens should be named 'dripped_0', 'dripped_1', etc."
    ],
    "key_insight": "Use lazy evaluation: instead of spawning a background thread to add dripped tokens, compute the drip count on each access based on elapsed time since last update. Formula: new_drips = floor(elapsed_time \u00d7 rate), capped at available capacity."
  },
  "requirements_coverage": {
    "checklist": [
      {
        "requirement": "add() returns true if added, false if dropped",
        "how_met": "Check total count (explicit + dripped) against capacity before adding",
        "gotchas": [
          "Must update drips first to get accurate count"
        ]
      },
      {
        "requirement": "get() peeks without removing",
        "how_met": "Return first explicit token or dripped_0, don't modify tokens list",
        "gotchas": [
          "Multiple get() calls return same token"
        ]
      },
      {
        "requirement": "Dripping fills bucket over time",
        "how_met": "Track last_update time and drip_count, compute on access",
        "gotchas": [
          "Drips can't exceed remaining capacity"
        ]
      },
      {
        "requirement": "Lazy evaluation for drips",
        "how_met": "Only compute dripped count when add/get/setDripRate called",
        "gotchas": [
          "Don't actually create dripped token objects"
        ]
      }
    ],
    "complexity_targets": [
      {
        "operation": "add",
        "target": "O(1)",
        "achieved": "O(1)",
        "why": "List append is O(1) amortized"
      },
      {
        "operation": "get",
        "target": "O(1)",
        "achieved": "O(1)",
        "why": "Just index into list or return constant string"
      },
      {
        "operation": "setDripRate",
        "target": "O(1)",
        "achieved": "O(1)",
        "why": "Just update rate variable"
      }
    ],
    "non_goals": [
      "Thread-safe implementation",
      "Persistent storage",
      "Multiple bucket coordination"
    ]
  },
  "assumptions": [
    "Time source is monotonically increasing (no clock adjustments)",
    "Drip rate is non-negative (0 means no dripping)",
    "Capacity is positive integer",
    "Token names are strings",
    "Dripped tokens named sequentially: dripped_0, dripped_1, etc."
  ],
  "tradeoffs": [
    {
      "decision": "Lazy vs Eager drip computation",
      "chosen": "Lazy",
      "why": "O(1) operations, no background threads needed",
      "alternative": "Timer/Thread",
      "when_to_switch": "If real-time guarantees needed across distributed systems"
    },
    {
      "decision": "List vs Set for tokens",
      "chosen": "List",
      "why": "Preserves insertion order, supports duplicates",
      "alternative": "Set",
      "when_to_switch": "If deduplication required"
    },
    {
      "decision": "Real time vs Injectable time",
      "chosen": "Real time with test helper",
      "why": "Simpler for interview, still testable",
      "alternative": "Full dependency injection",
      "when_to_switch": "Production code requiring comprehensive testing"
    }
  ],
  "extensibility_notes": {
    "what_to_keep_stable": [
      "Public method signatures",
      "Lazy evaluation approach",
      "O(1) complexity"
    ],
    "what_to_change": [
      "TokenBucket is a new class added alongside Solution",
      "Internal time tracking"
    ],
    "interfaces_and_boundaries": "TokenBucket is completely independent of Solution class - they were asked in same interview loop but solve different problems",
    "invariants": [
      "len(tokens) + drip_count <= capacity always",
      "drip_count is never negative",
      "last_update tracks when drips were last computed"
    ]
  },
  "visual_explanation": {
    "before_after": "Before (empty bucket, rate=2/sec):\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502  Capacity: 5    \u2502\\n\u2502                 \u2502  \u2190 empty\\n\u2502                 \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n\\nAfter 3 seconds:\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502  Capacity: 5    \u2502\\n\u2502 [D][D][D][D][D] \u2502  \u2190 5 dripped (capped)\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n\\nAfter add('X') -> returns False (full)",
    "algorithm_flow": "Access Operation Flow:\\n1. _update_drips()\\n   \u2514\u2500 elapsed = now - last_update\\n   \u2514\u2500 new_drips = floor(elapsed \u00d7 rate)\\n   \u2514\u2500 space = capacity - tokens - drip_count\\n   \u2514\u2500 drip_count += min(new_drips, space)\\n   \u2514\u2500 last_update = now\\n\\n2. Perform actual operation (add/get)\\n   \u2514\u2500 Check total count\\n   \u2514\u2500 Return result"
  },
  "approaches": [
    {
      "name": "Eager Dripping (Timer/Thread)",
      "description": "Use a background timer to actually add dripped tokens at regular intervals",
      "time_complexity": "O(1) for operations, but requires threading overhead",
      "space_complexity": "O(capacity) - actually stores all dripped tokens",
      "why_not_optimal": "Unnecessary complexity, threading issues, wastes memory on unused dripped tokens"
    },
    {
      "name": "Lazy Evaluation (Optimal)",
      "description": "Don't store dripped tokens. On each access, compute how many would have dripped based on elapsed time. Only track the count, not actual tokens.",
      "time_complexity": "O(1) for all operations",
      "space_complexity": "O(n) where n = explicitly added tokens only",
      "key_insight": "Dripped tokens are fungible - we only need to know HOW MANY exist, not store them individually"
    }
  ],
  "optimal_solution": {
    "explanation_md": "The **lazy evaluation** pattern is key here. Instead of spawning threads or timers to add dripped tokens:\n\n1. **Track state minimally**: `drip_count` (virtual count), `last_update` (timestamp), `drip_rate`\n\n2. **Update on access**: Before any add/get operation, call `_update_drips()` which computes:\n   - `elapsed = current_time - last_update`\n   - `new_drips = floor(elapsed \u00d7 rate)`\n   - Add to `drip_count`, but cap at available space\n\n3. **Virtual tokens**: Dripped tokens aren't real objects - we just track the count. When `get()` needs to return a dripped token, generate the name on the fly (`dripped_0`).\n\nThis gives us **O(1)** for all operations with minimal memory footprint.",
    "data_structures": [
      {
        "structure": "List[str]",
        "purpose": "Store explicitly added tokens in order"
      },
      {
        "structure": "int drip_count",
        "purpose": "Virtual count of dripped tokens (not stored)"
      },
      {
        "structure": "float last_update",
        "purpose": "Timestamp for lazy drip calculation"
      }
    ],
    "algorithm_steps": [
      "1. On __init__: Set capacity, empty token list, drip_rate=0, last_update=now",
      "2. On _update_drips(): Compute elapsed time \u00d7 rate, add to drip_count (capped at space)",
      "3. On add(token): Update drips, check if full, append token if not",
      "4. On get(): Update drips, return first explicit token or 'dripped_0' if drips exist",
      "5. On set_drip_rate(): Update drips with old rate first, then set new rate"
    ]
  },
  "solution_python_lines": [
    "from typing import List, Optional",
    "import time",
    "",
    "",
    "class Solution:",
    "    \"\"\"Process scheduling solutions from Parts 1-2 (unchanged).\"\"\"",
    "    ",
    "    def min_time(self, process_size: List[int], capacity: List[int]) -> int:",
    "        \"\"\"Part 1: Unit execution time scheduling.\"\"\"",
    "        processes = sorted(process_size, reverse=True)",
    "        caps = sorted(capacity, reverse=True)",
    "        n, m = len(processes), len(caps)",
    "        ",
    "        if processes[0] > caps[0]:",
    "            return -1",
    "        ",
    "        def can_complete(time: int) -> bool:",
    "            slots = (time + 1) // 2",
    "            proc_idx = 0",
    "            for cap in caps:",
    "                assigned = 0",
    "                while assigned < slots and proc_idx < n:",
    "                    if processes[proc_idx] <= cap:",
    "                        proc_idx += 1",
    "                        assigned += 1",
    "                    else:",
    "                        break",
    "                if proc_idx == n:",
    "                    return True",
    "            return proc_idx == n",
    "        ",
    "        lo, hi = 1, 2 * n - 1",
    "        while lo < hi:",
    "            mid = (lo + hi) // 2",
    "            if can_complete(mid):",
    "                hi = mid",
    "            else:",
    "                lo = mid + 1",
    "        return lo",
    "",
    "    def min_time_variable(self, process_size: List[int], exec_time: List[int], capacity: List[int]) -> int:",
    "        \"\"\"Part 2: Variable execution time scheduling.\"\"\"",
    "        n, m = len(process_size), len(capacity)",
    "        processes = sorted(zip(process_size, exec_time), key=lambda x: (-x[0], -x[1]))",
    "        caps = sorted(capacity, reverse=True)",
    "        ",
    "        if processes[0][0] > caps[0]:",
    "            return -1",
    "        ",
    "        def can_complete(time: int) -> bool:",
    "            proc_idx = 0",
    "            for cap in caps:",
    "                current_time = 0",
    "                while proc_idx < n:",
    "                    size, exec_t = processes[proc_idx]",
    "                    if size > cap:",
    "                        break",
    "                    add_time = exec_t if current_time == 0 else (1 + exec_t)",
    "                    if current_time + add_time <= time:",
    "                        current_time += add_time",
    "                        proc_idx += 1",
    "                    else:",
    "                        break",
    "                if proc_idx == n:",
    "                    return True",
    "            return proc_idx == n",
    "        ",
    "        total_exec = sum(exec_time)",
    "        lo, hi = 1, total_exec + n - 1",
    "        while lo < hi:",
    "            mid = (lo + hi) // 2",
    "            if can_complete(mid):",
    "                hi = mid",
    "            else:",
    "                lo = mid + 1",
    "        return lo",
    "",
    "",
    "class TokenBucket:",
    "    \"\"\"",
    "    Token bucket rate limiter with lazy dripping.",
    "    Key insight: Don't store dripped tokens - just track count and compute on access.",
    "    \"\"\"",
    "    ",
    "    def __init__(self, capacity: int):",
    "        self.capacity = capacity",
    "        self.tokens: List[str] = []  # Explicitly added tokens",
    "        self.drip_rate = 0.0",
    "        self.last_update = time.time()",
    "        self.drip_count = 0  # Virtual dripped token count",
    "    ",
    "    def _update_drips(self) -> None:",
    "        \"\"\"Lazily compute dripped tokens based on elapsed time.\"\"\"",
    "        if self.drip_rate <= 0:",
    "            return",
    "        ",
    "        now = time.time()",
    "        elapsed = now - self.last_update",
    "        new_drips = int(elapsed * self.drip_rate)",
    "        ",
    "        # Add drips up to available capacity",
    "        space = self.capacity - len(self.tokens) - self.drip_count",
    "        self.drip_count += min(new_drips, max(0, space))",
    "        self.last_update = now",
    "    ",
    "    def add(self, token: str) -> bool:",
    "        \"\"\"Add token to bucket. Returns False if full.\"\"\"",
    "        self._update_drips()",
    "        ",
    "        if len(self.tokens) + self.drip_count >= self.capacity:",
    "            return False",
    "        ",
    "        self.tokens.append(token)",
    "        return True",
    "    ",
    "    def get(self) -> Optional[str]:",
    "        \"\"\"Peek at a token (doesn't remove). Returns None if empty.\"\"\"",
    "        self._update_drips()",
    "        ",
    "        if self.tokens:",
    "            return self.tokens[0]",
    "        if self.drip_count > 0:",
    "            return \"dripped_0\"",
    "        return None",
    "    ",
    "    def set_drip_rate(self, rate: float) -> None:",
    "        \"\"\"Set dripping rate (tokens per second).\"\"\"",
    "        self._update_drips()  # Update with old rate first",
    "        self.drip_rate = rate",
    "    ",
    "    def _simulate_wait(self, seconds: float) -> None:",
    "        \"\"\"Testing helper: simulate time passing.\"\"\"",
    "        self.last_update -= seconds",
    "",
    "",
    "if __name__ == '__main__':",
    "    print(\"=\" * 60)",
    "    print(\"Part 3: Token Bucket Rate Limiter\")",
    "    print(\"=\" * 60)",
    "    ",
    "    # Example 1: Basic add/get",
    "    print(\"\\nTest 1: Basic operations (capacity=3)\")",
    "    bucket = TokenBucket(3)",
    "    print(f\"  add('A'): {bucket.add('A')}  (expected: True)\")",
    "    print(f\"  add('B'): {bucket.add('B')}  (expected: True)\")",
    "    print(f\"  add('C'): {bucket.add('C')}  (expected: True)\")",
    "    print(f\"  get():    {bucket.get()}  (expected: A)\")",
    "    print(f\"  add('D'): {bucket.add('D')}  (expected: False - full)\")",
    "    print(f\"  get():    {bucket.get()}  (expected: A - didn't remove)\")",
    "    ",
    "    # Example 2: Dripping",
    "    print(\"\\nTest 2: Dripping (capacity=5, rate=2/sec, wait 3s)\")",
    "    bucket2 = TokenBucket(5)",
    "    bucket2.set_drip_rate(2)",
    "    bucket2._simulate_wait(3)  # Simulate 3 seconds passing",
    "    print(f\"  After 3s: get() = {bucket2.get()}  (expected: dripped_0)\")",
    "    print(f\"  add('X'): {bucket2.add('X')}  (expected: False - 6 drips capped at 5)\")",
    "    ",
    "    # Example 3: Mixed explicit and dripped",
    "    print(\"\\nTest 3: Mixed tokens (capacity=5)\")",
    "    bucket3 = TokenBucket(5)",
    "    bucket3.add(\"A\")",
    "    bucket3.add(\"B\")",
    "    bucket3.set_drip_rate(2)",
    "    bucket3._simulate_wait(2)  # 4 drips, but only 3 spaces",
    "    print(f\"  Explicit: 2, Dripped: 3 (capped at space)\")",
    "    print(f\"  get(): {bucket3.get()}  (expected: A - explicit first)\")",
    "    print(f\"  add('C'): {bucket3.add('C')}  (expected: False - full)\")",
    "    ",
    "    # Example 4: Empty bucket",
    "    print(\"\\nTest 4: Empty bucket\")",
    "    bucket4 = TokenBucket(3)",
    "    print(f\"  get() on empty: {bucket4.get()}  (expected: None)\")",
    "    ",
    "    # Parts 1-2 still work",
    "    print(\"\\n\" + \"=\" * 60)",
    "    print(\"Parts 1-2 Tests (unchanged):\")",
    "    print(\"=\" * 60)",
    "    sol = Solution()",
    "    print(f\"Part 1: {sol.min_time([2, 5, 3], [6, 2, 4])}  (expected: 1)\")",
    "    print(f\"Part 2: {sol.min_time_variable([2,5,3], [1,3,2], [6,6])}  (expected: 4)\")",
    "    ",
    "    print(\"\\nAll tests completed!\")"
  ],
  "solution_java_lines": [
    "import java.util.*;",
    "",
    "public class Solution {",
    "    // Parts 1-2 unchanged",
    "    public int minTime(int[] processSize, int[] capacity) {",
    "        int n = processSize.length;",
    "        Integer[] processes = Arrays.stream(processSize).boxed().toArray(Integer[]::new);",
    "        Integer[] caps = Arrays.stream(capacity).boxed().toArray(Integer[]::new);",
    "        Arrays.sort(processes, Collections.reverseOrder());",
    "        Arrays.sort(caps, Collections.reverseOrder());",
    "        ",
    "        if (processes[0] > caps[0]) return -1;",
    "        ",
    "        int lo = 1, hi = 2 * n - 1;",
    "        while (lo < hi) {",
    "            int mid = (lo + hi) / 2;",
    "            if (canComplete(processes, caps, mid)) hi = mid;",
    "            else lo = mid + 1;",
    "        }",
    "        return lo;",
    "    }",
    "    ",
    "    private boolean canComplete(Integer[] processes, Integer[] caps, int time) {",
    "        int slots = (time + 1) / 2, procIdx = 0, n = processes.length;",
    "        for (int cap : caps) {",
    "            int assigned = 0;",
    "            while (assigned < slots && procIdx < n && processes[procIdx] <= cap) {",
    "                procIdx++; assigned++;",
    "            }",
    "            if (procIdx == n) return true;",
    "        }",
    "        return procIdx == n;",
    "    }",
    "    ",
    "    public int minTimeVariable(int[] processSize, int[] execTime, int[] capacity) {",
    "        int n = processSize.length, totalExec = 0;",
    "        int[][] processes = new int[n][2];",
    "        for (int i = 0; i < n; i++) {",
    "            processes[i] = new int[]{processSize[i], execTime[i]};",
    "            totalExec += execTime[i];",
    "        }",
    "        Arrays.sort(processes, (a, b) -> a[0] != b[0] ? b[0] - a[0] : b[1] - a[1]);",
    "        Integer[] caps = Arrays.stream(capacity).boxed().toArray(Integer[]::new);",
    "        Arrays.sort(caps, Collections.reverseOrder());",
    "        ",
    "        if (processes[0][0] > caps[0]) return -1;",
    "        ",
    "        int lo = 1, hi = totalExec + n - 1;",
    "        while (lo < hi) {",
    "            int mid = (lo + hi) / 2;",
    "            if (canCompleteVariable(processes, caps, mid)) hi = mid;",
    "            else lo = mid + 1;",
    "        }",
    "        return lo;",
    "    }",
    "    ",
    "    private boolean canCompleteVariable(int[][] processes, Integer[] caps, int time) {",
    "        int procIdx = 0, n = processes.length;",
    "        for (int cap : caps) {",
    "            int currentTime = 0;",
    "            while (procIdx < n && processes[procIdx][0] <= cap) {",
    "                int addTime = (currentTime == 0) ? processes[procIdx][1] : 1 + processes[procIdx][1];",
    "                if (currentTime + addTime <= time) {",
    "                    currentTime += addTime;",
    "                    procIdx++;",
    "                } else break;",
    "            }",
    "            if (procIdx == n) return true;",
    "        }",
    "        return procIdx == n;",
    "    }",
    "    ",
    "    public static void main(String[] args) {",
    "        Solution sol = new Solution();",
    "        System.out.println(\"Parts 1-2: \" + sol.minTime(new int[]{2,5,3}, new int[]{6,2,4}));",
    "        ",
    "        System.out.println(\"\\n=== Part 3: Token Bucket ===\");",
    "        TokenBucket bucket = new TokenBucket(3);",
    "        System.out.println(\"add(A): \" + bucket.add(\"A\"));",
    "        System.out.println(\"add(B): \" + bucket.add(\"B\"));",
    "        System.out.println(\"add(C): \" + bucket.add(\"C\"));",
    "        System.out.println(\"get(): \" + bucket.get());",
    "        System.out.println(\"add(D): \" + bucket.add(\"D\") + \" (expected: false)\");",
    "        ",
    "        TokenBucket bucket2 = new TokenBucket(5);",
    "        bucket2.setDripRate(2);",
    "        bucket2.simulateWait(3);",
    "        System.out.println(\"After drip: \" + bucket2.get());",
    "        System.out.println(\"add(X): \" + bucket2.add(\"X\") + \" (expected: false)\");",
    "    }",
    "}",
    "",
    "class TokenBucket {",
    "    private final int capacity;",
    "    private final List<String> tokens;",
    "    private double dripRate;",
    "    private long lastUpdateNanos;",
    "    private int dripCount;",
    "    ",
    "    public TokenBucket(int capacity) {",
    "        this.capacity = capacity;",
    "        this.tokens = new ArrayList<>();",
    "        this.dripRate = 0.0;",
    "        this.lastUpdateNanos = System.nanoTime();",
    "        this.dripCount = 0;",
    "    }",
    "    ",
    "    private void updateDrips() {",
    "        if (dripRate <= 0) return;",
    "        long now = System.nanoTime();",
    "        double elapsed = (now - lastUpdateNanos) / 1_000_000_000.0;",
    "        int newDrips = (int) (elapsed * dripRate);",
    "        int space = capacity - tokens.size() - dripCount;",
    "        dripCount += Math.min(newDrips, Math.max(0, space));",
    "        lastUpdateNanos = now;",
    "    }",
    "    ",
    "    public boolean add(String token) {",
    "        updateDrips();",
    "        if (tokens.size() + dripCount >= capacity) return false;",
    "        tokens.add(token);",
    "        return true;",
    "    }",
    "    ",
    "    public String get() {",
    "        updateDrips();",
    "        if (!tokens.isEmpty()) return tokens.get(0);",
    "        if (dripCount > 0) return \"dripped_0\";",
    "        return null;",
    "    }",
    "    ",
    "    public void setDripRate(double rate) {",
    "        updateDrips();",
    "        this.dripRate = rate;",
    "    }",
    "    ",
    "    void simulateWait(double seconds) {",
    "        lastUpdateNanos -= (long)(seconds * 1_000_000_000);",
    "    }",
    "}"
  ],
  "code_walkthrough": [
    {
      "lines": "1-2",
      "explanation": "Imports: typing for type hints, time for timestamp tracking"
    },
    {
      "lines": "71-78",
      "explanation": "TokenBucket constructor: Initialize capacity, empty token list, no dripping, record start time"
    },
    {
      "lines": "80-90",
      "explanation": "_update_drips(): The core lazy evaluation logic - compute elapsed time \u00d7 rate, add to drip_count capped at available space"
    },
    {
      "lines": "92-99",
      "explanation": "add(): Update drips first, check if full (explicit + dripped >= capacity), append if space available"
    },
    {
      "lines": "101-108",
      "explanation": "get(): Update drips, return first explicit token OR 'dripped_0' for virtual drips, None if empty"
    },
    {
      "lines": "110-113",
      "explanation": "set_drip_rate(): Update drips with old rate first (important!), then set new rate"
    }
  ],
  "complexity_analysis": {
    "time": {
      "new_methods": {
        "__init__": {
          "complexity": "O(1)",
          "explanation": "Just initialize fields"
        },
        "add": {
          "complexity": "O(1)",
          "explanation": "Drip update is O(1), list append is O(1) amortized"
        },
        "get": {
          "complexity": "O(1)",
          "explanation": "Drip update is O(1), list access is O(1)"
        },
        "set_drip_rate": {
          "complexity": "O(1)",
          "explanation": "Just update numeric field"
        }
      },
      "overall_change": "TokenBucket is independent of Solution - no impact on scheduling algorithms"
    },
    "space": {
      "additional_space": "O(n) where n = explicitly added tokens",
      "explanation": "Dripped tokens are virtual (just a count), so only explicit tokens consume memory"
    }
  },
  "dry_run": {
    "example_input": "capacity=5, setDripRate(2), wait 3 seconds, get(), add('X')",
    "steps": [
      {
        "step": 1,
        "action": "TokenBucket(5)",
        "state": "tokens=[], drip_count=0, rate=0, last_update=t0",
        "explanation": "Initialize empty bucket"
      },
      {
        "step": 2,
        "action": "setDripRate(2)",
        "state": "rate=2, last_update=t0",
        "explanation": "Start dripping at 2/sec"
      },
      {
        "step": 3,
        "action": "wait 3 seconds",
        "state": "Time advances to t0+3",
        "explanation": "Simulate time passing (no actual drip update yet - lazy!)"
      },
      {
        "step": 4,
        "action": "get()",
        "state": "_update_drips: elapsed=3, newDrips=6, space=5, dripCount=min(6,5)=5",
        "explanation": "Lazy update computes 6 drips but caps at capacity"
      },
      {
        "step": 5,
        "action": "get() returns",
        "state": "tokens empty, dripCount=5 > 0",
        "explanation": "Return 'dripped_0' for virtual dripped token"
      },
      {
        "step": 6,
        "action": "add('X')",
        "state": "tokens.size()=0, dripCount=5, total=5 >= capacity=5",
        "explanation": "Bucket full, return False"
      }
    ],
    "final_output": "get() returns 'dripped_0', add('X') returns False"
  },
  "debugging_playbook": {
    "fast_sanity_checks": [
      "Empty bucket get() returns None",
      "add() to capacity, then add() returns False",
      "get() returns same token on repeated calls"
    ],
    "likely_bugs": [
      "Forgetting to call _update_drips() before operations",
      "Not updating last_update after drip calculation",
      "Integer overflow in drip calculation"
    ],
    "recommended_logs_or_asserts": [
      "assert drip_count >= 0",
      "assert len(tokens) + drip_count <= capacity",
      "Log elapsed time and new_drips in _update_drips"
    ],
    "how_to_localize": "Add print statements in _update_drips() to trace elapsed time, new_drips, space calculations"
  },
  "edge_cases": [
    {
      "case": "Empty bucket get()",
      "handling": "Return None",
      "gotcha": "Don't throw exception"
    },
    {
      "case": "Bucket full from explicit tokens",
      "handling": "add() returns False, drips have no space",
      "gotcha": "Drips still try to accumulate"
    },
    {
      "case": "Rate set to 0",
      "handling": "_update_drips() early returns",
      "gotcha": "Don't divide by zero"
    },
    {
      "case": "Very small elapsed time",
      "handling": "int() truncation gives 0 new drips",
      "gotcha": "Frequent calls won't accumulate fractional drips"
    },
    {
      "case": "Rate changed mid-stream",
      "handling": "Update drips with old rate first, then set new rate",
      "gotcha": "Order matters!"
    }
  ],
  "test_cases": [
    {
      "name": "Basic add/get/full",
      "input": "TokenBucket(3); add(A,B,C); get(); add(D)",
      "expected": "[true, true, true, 'A', false]",
      "explanation": "Fill bucket, peek returns first, add fails when full"
    },
    {
      "name": "Dripping fills bucket",
      "input": "TokenBucket(5); setDripRate(2); wait(3); get(); add(X)",
      "expected": "['dripped_0', false]",
      "explanation": "6 drips (capped at 5), bucket full"
    },
    {
      "name": "Mixed explicit and dripped",
      "input": "TokenBucket(5); add(A,B); setDripRate(2); wait(2); add(C)",
      "expected": "[true, true, false]",
      "explanation": "2 explicit + 3 dripped (capped) = 5, full"
    }
  ],
  "common_mistakes": [
    {
      "mistake": "Actually storing dripped token objects",
      "why_wrong": "Wastes memory, dripped tokens are fungible",
      "correct_approach": "Track drip_count only, generate names on demand",
      "code_example_wrong": "for i in range(new_drips): self.tokens.append(f'dripped_{i}')",
      "code_example_correct": "self.drip_count += min(new_drips, space)"
    },
    {
      "mistake": "Not updating drips before setDripRate",
      "why_wrong": "Loses dripped tokens that accumulated at old rate",
      "correct_approach": "Always call _update_drips() first in setDripRate()",
      "code_example_wrong": "def set_drip_rate(self, rate): self.drip_rate = rate",
      "code_example_correct": "def set_drip_rate(self, rate): self._update_drips(); self.drip_rate = rate"
    },
    {
      "mistake": "Removing token on get()",
      "why_wrong": "Problem says get() is a peek operation",
      "correct_approach": "Return token without modifying tokens list",
      "code_example_wrong": "return self.tokens.pop(0)",
      "code_example_correct": "return self.tokens[0]"
    }
  ],
  "interview_tips": {
    "how_to_present": "Start by clarifying: 'This is a design problem, separate from the scheduling. Let me first explain the lazy evaluation approach...' Then sketch the data structure and key methods.",
    "what_to_mention": [
      "Lazy evaluation avoids threads/timers",
      "Dripped tokens are virtual (just a count)",
      "All operations are O(1)",
      "Time-based systems need careful testing"
    ],
    "time_allocation": "2 min understand, 3 min design, 10 min code, 3 min test",
    "if_stuck": [
      "Think about what state you need to track",
      "When do you actually need the dripped tokens?",
      "Can you compute instead of store?"
    ]
  },
  "connection_to_next_part": "A Part 4 might add: token removal (consume), priority tokens, distributed buckets, or token expiration. The lazy evaluation pattern scales well for these extensions.",
  "communication_script": {
    "transition_from_previous": "OK, so Parts 1-2 handle process scheduling. Part 3 is a completely different problem - a token bucket rate limiter. This is a classic system design component.",
    "explaining_changes": "The key insight is lazy evaluation. Instead of actually adding dripped tokens every second, I'll track the last update time and compute drips on-demand when add() or get() is called.",
    "while_extending_code": [
      "Adding TokenBucket as a new class alongside Solution...",
      "The _update_drips() helper does the lazy computation...",
      "Using time.time() for timestamps, with a test helper for simulation..."
    ],
    "after_completing": "TokenBucket now supports capacity-limited tokens with lazy dripping. All operations are O(1). The explicit tokens and virtual drip count together can't exceed capacity."
  },
  "time_milestones": {
    "time_budget": "15-18 minutes for this part",
    "by_3_min": "Understand the token bucket concept, identify lazy evaluation as the approach",
    "by_8_min": "Design data structures (tokens list, drip_count, last_update), start coding",
    "by_15_min": "Complete implementation, run through test cases",
    "warning_signs": "If confused about dripping at 5 min, ask for clarification. If stuck on lazy eval, mention timer approach as fallback."
  },
  "recovery_strategies": {
    "if_part_builds_wrong": "TokenBucket is independent - Part 1-2 bugs don't affect it. Focus on the new class.",
    "if_new_requirement_unclear": "Ask: 'For dripping, do I need real-time guarantees or is lazy computation OK?'",
    "if_running_behind": "Implement add() and get() first without dripping. Add setDripRate() and _update_drips() as follow-up."
  },
  "signal_points": {
    "wow_factors_for_followup": [
      "Immediately recognizing the lazy evaluation pattern",
      "Mentioning this is a classic rate limiter algorithm",
      "Discussing testability with injectable time source",
      "Proactively handling the 'update drips before changing rate' subtlety"
    ]
  },
  "pattern_recognition": {
    "pattern": "Lazy Evaluation / Virtual State",
    "indicators": [
      "Time-based state changes",
      "State computed on access",
      "Avoiding background threads"
    ],
    "similar_problems": [
      "LC 359 - Logger Rate Limiter",
      "LC 362 - Design Hit Counter",
      "Leaky Bucket algorithm"
    ],
    "template": "Track (last_update_time, virtual_count), compute on access: count += (now - last_update) * rate"
  },
  "thinking_process": [
    {
      "step": 1,
      "thought": "When I see 'tokens drip at rate r per second', I immediately think of timer/threads vs lazy evaluation",
      "why": "Lazy is simpler and more testable for interviews"
    },
    {
      "step": 2,
      "thought": "The key constraint is capacity - drips + explicit <= capacity",
      "why": "This forces careful tracking of both types"
    },
    {
      "step": 3,
      "thought": "get() doesn't remove means we just need to peek, not manage removal",
      "why": "Simplifies the design significantly"
    }
  ],
  "interviewer_perspective": {
    "what_they_evaluate": [
      "Can you switch contexts to a design problem?",
      "Do you recognize the lazy evaluation pattern?",
      "Is your code clean and testable?"
    ],
    "bonus_points": [
      "Discussing thread-safety considerations",
      "Mentioning this is a classic rate limiting algorithm",
      "Providing test helpers for time simulation"
    ],
    "red_flags": [
      "Using actual threads/timers in interview",
      "Over-complicating with stored dripped tokens",
      "Forgetting to update drips before operations"
    ]
  },
  "ai_copilot_tips": {
    "what_to_do": [
      "Let AI help with time.time() boilerplate",
      "Use AI for test case generation"
    ],
    "what_not_to_do": [
      "Don't let AI suggest threading solutions",
      "Verify the lazy evaluation logic yourself"
    ]
  },
  "red_flags_to_avoid": {
    "behavioral": [
      "Not clarifying that this is a different problem type",
      "Rushing without understanding dripping semantics"
    ],
    "technical": [
      "Using threads/timers unnecessarily",
      "Storing actual dripped token objects",
      "Forgetting the peek-only nature of get()"
    ],
    "communication": [
      "Not explaining why lazy evaluation works",
      "Skipping the capacity constraint explanation"
    ]
  },
  "final_checklist": {
    "before_saying_done": [
      "add() returns False when full (explicit + dripped >= capacity)",
      "get() doesn't remove tokens",
      "_update_drips() called before all operations",
      "setDripRate() updates drips with old rate first"
    ],
    "quick_code_review": [
      "TokenBucket is separate class (not nested)",
      "Method names match signatures exactly",
      "Test helper for time simulation included"
    ]
  },
  "production_considerations": {
    "what_i_would_add": [
      "Thread-safe synchronization",
      "Metrics for add/drop rates",
      "Injectable time source for testing",
      "Token expiration"
    ],
    "why_not_in_interview": "Focus on core lazy evaluation pattern; mention these verbally",
    "how_to_mention": "Say: 'In production, I'd add a lock for thread safety and inject the time source for testing.'"
  },
  "generated_at": "2026-01-19T04:58:31.101196",
  "_meta": {
    "problem_id": "process_scheduling",
    "part_number": 3,
    "model": "claude-opus-4-5-20251101"
  }
}