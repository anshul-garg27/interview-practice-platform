{
  "problem_title": "News Feed Aggregator System - Part 2: Real-Time Notifications & Breaking News",
  "part_number": 2,
  "builds_on": "Part 1",
  "difficulty": "medium",
  "problem_understanding": {
    "what_changes": "Part 1 focused on feed generation with caching. Part 2 adds a **push model** for breaking news - instead of users pulling their feed, we proactively push high-priority content to interested users within 30 seconds. This requires inverting our data model: we need to quickly find 'who cares about this article' rather than 'what articles does this user want'.",
    "new_requirements": [
      "Breaking news alerts delivered within 30 seconds",
      "Notification preferences (category filters, frequency limits)",
      "Quiet hours enforcement (no notifications 10pm-8am)",
      "Rate limiting (max N notifications per day per user)",
      "Tracking read/unread status for engagement metrics"
    ],
    "new_constraints": [
      "30-second latency SLA for breaking news (priority >= 8)",
      "Cannot scan all users on each breaking news (too slow)",
      "Must respect user preferences before sending notifications"
    ],
    "key_insight": "**Pre-build inverted indices**: `category -> [user_ids]` and `publisher -> [user_ids]`. When breaking news arrives, O(1) lookup to find the audience instead of O(N) scanning all users. The indices are updated incrementally when users change preferences."
  },
  "requirements_coverage": {
    "checklist": [
      {
        "requirement": "Breaking news within 30 seconds",
        "how_met": "Inverted indices allow O(audience_size) notification fanout without scanning all users",
        "gotchas": [
          "Must update indices when user changes interests or follows publishers"
        ]
      },
      {
        "requirement": "Rate limiting",
        "how_met": "Track daily_notification_count per user with 24-hour reset",
        "gotchas": [
          "Need to reset counter at midnight or use rolling window"
        ]
      },
      {
        "requirement": "Quiet hours",
        "how_met": "Check current hour against user's quiet_hours_start/end before sending",
        "gotchas": [
          "Handle overnight quiet hours (22:00-08:00 spans midnight)"
        ]
      },
      {
        "requirement": "Engagement tracking",
        "how_met": "mark_notification_read updates read=true flag",
        "gotchas": [
          "In production, track read rate, CTR for ML model feedback"
        ]
      }
    ],
    "complexity_targets": [
      {
        "operation": "publishBreakingNews",
        "target": "O(audience)",
        "achieved": "O(audience)",
        "why": "Inverted index lookup is O(1), then iterate over audience"
      },
      {
        "operation": "getPendingNotifications",
        "target": "O(n log n)",
        "achieved": "O(n log n)",
        "why": "Filter unread + sort by priority"
      },
      {
        "operation": "setNotificationPreferences",
        "target": "O(1)",
        "achieved": "O(1)",
        "why": "HashMap insertion"
      }
    ],
    "non_goals": [
      "Actual push notification delivery (FCM/APNS integration)",
      "WebSocket real-time connection management",
      "Distributed notification deduplication"
    ]
  },
  "assumptions": [
    "Notifications are stored in-memory (production: Redis/database)",
    "Time-based quiet hours use server timezone (ask: per-user timezone?)",
    "Rate limit resets every 24 hours from first notification (ask: rolling window or midnight reset?)",
    "Breaking news threshold is priority >= 8 (ask: configurable per publisher?)",
    "One notification per article per user (dedupe by article_id)"
  ],
  "tradeoffs": [
    {
      "decision": "Inverted index vs Scan all users",
      "chosen": "Inverted index",
      "why": "O(audience) vs O(all_users). With 1M users and 1K interested in 'Sports', we notify 1K not 1M",
      "alternative": "Full scan",
      "when_to_switch": "Never - full scan doesn't meet 30s SLA"
    },
    {
      "decision": "Push vs Pull for breaking news",
      "chosen": "Push (proactive notification creation)",
      "why": "30-second SLA requires immediate action, can't wait for user to pull",
      "alternative": "Enhanced polling",
      "when_to_switch": "If notification delivery is unreliable, fall back to aggressive polling"
    },
    {
      "decision": "Daily reset vs Rolling window for rate limit",
      "chosen": "Daily reset (simpler)",
      "why": "Easier to implement, good enough for interview",
      "alternative": "Rolling 24-hour window with Redis sorted sets",
      "when_to_switch": "If users complain about 'burst at midnight' behavior"
    }
  ],
  "extensibility_notes": {
    "what_to_keep_stable": [
      "All Part 1 method signatures",
      "Article, Publisher, User dataclasses",
      "Cache structure"
    ],
    "what_to_change": [
      "Added inverted indices to follow_publisher and set_user_interests",
      "New notification data structures"
    ],
    "interfaces_and_boundaries": "Part 2 adds notification layer on top of Part 1. The ingest_article flow is reused - publishBreakingNews calls it. Part 3 could add ML-based ranking or A/B testing.",
    "invariants": [
      "Inverted indices are always in sync with user preferences",
      "daily_notification_count <= max_daily for any user",
      "Notification created_at is never in quiet hours (at creation time)"
    ]
  },
  "visual_explanation": {
    "before_after": "```\nBEFORE (Part 1):                     AFTER (Part 2):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   User A    \u2502\u2500\u2500pulls\u2500\u2500\u2500\u25b6 Feed     \u2502   User A    \u2502\u25c0\u2500\u2500push\u2500\u2500 Breaking News\n\u2502   User B    \u2502\u2500\u2500pulls\u2500\u2500\u2500\u25b6 Feed     \u2502   User B    \u2502\u25c0\u2500\u2500push\u2500\u2500 Breaking News\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                          \u2502\nData flow: User \u2192 System                  \u2502 Data flow: System \u2192 User\n                                          \u2502\n                                     \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                     \u2502  INVERTED INDICES    \u2502\n                                     \u2502  Tech \u2192 [A, B, C]    \u2502\n                                     \u2502  pub_nyt \u2192 [B, D]    \u2502\n                                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```",
    "algorithm_flow": "```\npublishBreakingNews(pub_nyt, article, priority=10)\n    \u2502\n    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 1. ingest_article(article)      \u2502 \u2190 Reuse Part 1 logic\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 2. priority >= 8? \u2500\u2500\u2500\u2500NO\u2500\u2500\u2500\u2500\u25b6 Return (not breaking)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502YES\n             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 3. Find audience:               \u2502 \u2190 O(1) index lookups!\n\u2502    publisher_followers[pub_nyt] \u2502\n\u2502    + category_subscribers[cat]  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 4. For each user in audience:   \u2502\n\u2502    - Check prefs.enabled?       \u2502\n\u2502    - Check category filter?     \u2502\n\u2502    - Check quiet hours?         \u2502\n\u2502    - Check rate limit?          \u2502\n\u2502    \u2192 If all pass: create notif  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```"
  },
  "approaches": [
    {
      "name": "Naive Extension - Scan All Users",
      "description": "On breaking news, iterate through ALL users, check if each matches the article's publisher/categories",
      "time_complexity": "O(U) where U = total users (millions)",
      "space_complexity": "O(1) extra",
      "why_not_optimal": "With 1M users and breaking news every minute, we'd do 1M checks per event. Doesn't meet 30-second SLA at scale."
    },
    {
      "name": "Optimal - Inverted Index",
      "description": "Maintain category\u2192users and publisher\u2192users mappings. On breaking news, union the relevant sets to get audience in O(1) lookups + O(audience) iteration.",
      "time_complexity": "O(C + A) where C = categories, A = audience size",
      "space_complexity": "O(U * avg_interests) for inverted indices",
      "key_insight": "Trade space for time. Store redundant user\u2192category mappings in both directions. 1M users with 5 interests each = 5M index entries, but lookups are O(1)."
    }
  ],
  "optimal_solution": {
    "explanation_md": "The key insight is **inverting the index**: instead of asking \"what does this user want?\" (Part 1), we ask \"who wants this article?\" (Part 2).\n\n**Data Structures Added:**\n1. `category_subscribers: Dict[str, Set[str]]` - Maps each category to users interested in it\n2. `publisher_followers: Dict[str, Set[str]]` - Maps each publisher to users following it\n3. `notification_prefs: Dict[str, NotificationPrefs]` - User notification settings\n4. `pending_notifications: Dict[str, List[Notification]]` - Queue per user\n5. `daily_notification_count: Dict[str, int]` - Rate limiting tracker\n\n**The Algorithm:**\n1. When `followPublisher` is called, add user to `publisher_followers[pub_id]`\n2. When `setUserInterests` is called, update `category_subscribers` (remove from old, add to new)\n3. When `publishBreakingNews` is called:\n   - Union `publisher_followers[pub]` + all `category_subscribers[cat]` \u2192 audience\n   - For each user in audience, apply filters (prefs, rate limit, quiet hours)\n   - Create notification for those who pass\n\nThis achieves O(audience_size) instead of O(all_users), meeting the 30-second SLA.",
    "data_structures": [
      {
        "structure": "Dict[str, Set[str]] (Inverted Index)",
        "purpose": "O(1) lookup of users interested in a category or following a publisher"
      },
      {
        "structure": "NotificationPrefs dataclass",
        "purpose": "Store user's notification settings (max_daily, categories, quiet_hours)"
      },
      {
        "structure": "Notification dataclass",
        "purpose": "Represent a pending notification with priority, read status"
      }
    ],
    "algorithm_steps": [
      "Step 1: Call ingest_article() to add article to normal caches (reuse Part 1)",
      "Step 2: Check if priority >= BREAKING_NEWS_THRESHOLD (8), else return early",
      "Step 3: Build audience set from inverted indices (publisher followers + category subscribers)",
      "Step 4: For each user in audience, check shouldNotify() filters",
      "Step 5: For eligible users, create Notification and add to pending_notifications"
    ]
  },
  "solution_python_lines": [
    "\"\"\"",
    "News Feed Aggregator - Part 2: Real-Time Notifications",
    "Key insight: Inverted indices for O(audience) notification fanout.",
    "\"\"\"",
    "from typing import List, Dict, Set",
    "from dataclasses import dataclass, field",
    "from collections import defaultdict",
    "import time",
    "",
    "@dataclass",
    "class Article:",
    "    id: str",
    "    publisher_id: str",
    "    title: str",
    "    url: str",
    "    categories: List[str]",
    "    published_at: float",
    "    popularity: float = 0.0",
    "    score: float = 0.0",
    "",
    "@dataclass",
    "class Publisher:",
    "    id: str",
    "    name: str",
    "    rss_url: str",
    "    categories: List[str]",
    "",
    "@dataclass",
    "class User:",
    "    id: str",
    "    followed_publishers: Set[str] = field(default_factory=set)",
    "    interests: Set[str] = field(default_factory=set)",
    "    publisher_affinity: Dict[str, int] = field(default_factory=dict)",
    "",
    "# Part 2: New data classes",
    "@dataclass",
    "class NotificationPrefs:",
    "    max_daily: int = 5",
    "    categories: List[str] = field(default_factory=list)  # Empty = all",
    "    quiet_hours_start: int = 22  # 10 PM",
    "    quiet_hours_end: int = 8    # 8 AM",
    "    enabled: bool = True",
    "",
    "@dataclass",
    "class Notification:",
    "    id: str",
    "    user_id: str",
    "    article_id: str",
    "    title: str",
    "    priority: int",
    "    created_at: float",
    "    read: bool = False",
    "",
    "class NewsAggregator:",
    "    \"\"\"News aggregator with multi-tier caching + real-time notifications.\"\"\"",
    "    ",
    "    def __init__(self):",
    "        # Part 1 fields",
    "        self.publishers: Dict[str, Publisher] = {}",
    "        self.users: Dict[str, User] = {}",
    "        self.articles: Dict[str, Article] = {}",
    "        self.category_cache: Dict[str, List[Article]] = defaultdict(list)",
    "        self.publisher_cache: Dict[str, List[Article]] = defaultdict(list)",
    "        self.user_feed_cache: Dict[str, List[Article]] = {}",
    "        self.CACHE_SIZE = 100",
    "        ",
    "        # Part 2: Notification infrastructure",
    "        self.notification_prefs: Dict[str, NotificationPrefs] = {}",
    "        self.pending_notifications: Dict[str, List[Notification]] = defaultdict(list)",
    "        self.daily_notification_count: Dict[str, int] = defaultdict(int)",
    "        self.last_count_reset: Dict[str, float] = {}",
    "        ",
    "        # Part 2: Inverted indices for fast audience lookup",
    "        self.category_subscribers: Dict[str, Set[str]] = defaultdict(set)",
    "        self.publisher_followers: Dict[str, Set[str]] = defaultdict(set)",
    "        ",
    "        self.BREAKING_NEWS_THRESHOLD = 8",
    "        self._notification_counter = 0",
    "    ",
    "    # ========== Part 1 Methods ==========",
    "    ",
    "    def register_publisher(self, publisher_id: str, name: str,",
    "                           rss_url: str, categories: List[str]) -> None:",
    "        self.publishers[publisher_id] = Publisher(",
    "            id=publisher_id, name=name, rss_url=rss_url, categories=categories)",
    "    ",
    "    def follow_publisher(self, user_id: str, publisher_id: str) -> None:",
    "        user = self._get_or_create_user(user_id)",
    "        user.followed_publishers.add(publisher_id)",
    "        self.user_feed_cache.pop(user_id, None)",
    "        # Part 2: Update inverted index",
    "        self.publisher_followers[publisher_id].add(user_id)",
    "    ",
    "    def set_user_interests(self, user_id: str, categories: List[str]) -> None:",
    "        user = self._get_or_create_user(user_id)",
    "        # Part 2: Update inverted indices",
    "        for old_cat in user.interests:",
    "            self.category_subscribers[old_cat].discard(user_id)",
    "        user.interests = set(categories)",
    "        for cat in categories:",
    "            self.category_subscribers[cat].add(user_id)",
    "        self.user_feed_cache.pop(user_id, None)",
    "    ",
    "    def like_article(self, user_id: str, article_id: str) -> None:",
    "        if article_id not in self.articles:",
    "            return",
    "        user = self._get_or_create_user(user_id)",
    "        pub_id = self.articles[article_id].publisher_id",
    "        user.publisher_affinity[pub_id] = user.publisher_affinity.get(pub_id, 0) + 1",
    "    ",
    "    def get_user_feed(self, user_id: str, page: int, page_size: int) -> List[Article]:",
    "        if user_id in self.user_feed_cache:",
    "            return self._paginate(self.user_feed_cache[user_id], page, page_size)",
    "        ",
    "        user = self._get_or_create_user(user_id)",
    "        candidates: Dict[str, Article] = {}",
    "        ",
    "        for interest in user.interests:",
    "            for article in self.category_cache.get(interest, []):",
    "                candidates[article.id] = article",
    "        for pub_id in user.followed_publishers:",
    "            for article in self.publisher_cache.get(pub_id, []):",
    "                candidates[article.id] = article",
    "        ",
    "        if not candidates:",
    "            candidates = {a.id: a for a in self._get_trending_articles()}",
    "        ",
    "        scored = []",
    "        for article in candidates.values():",
    "            article.score = self._score_article(article, user)",
    "            scored.append(article)",
    "        ",
    "        scored.sort(key=lambda a: a.score, reverse=True)",
    "        self.user_feed_cache[user_id] = scored",
    "        return self._paginate(scored, page, page_size)",
    "    ",
    "    def _score_article(self, article: Article, user: User) -> float:",
    "        score = 0.0",
    "        if article.publisher_id in user.followed_publishers:",
    "            score += 2.0",
    "        if set(article.categories) & user.interests:",
    "            score += 1.5",
    "        age_hours = (time.time() - article.published_at) / 3600",
    "        score += max(0, 1.0 - age_hours / 24)",
    "        affinity = user.publisher_affinity.get(article.publisher_id, 0)",
    "        score += min(affinity * 0.3, 1.5)",
    "        score += article.popularity * 0.5",
    "        return score",
    "    ",
    "    def ingest_article(self, article: Article) -> None:",
    "        self.articles[article.id] = article",
    "        pub_articles = self.publisher_cache[article.publisher_id]",
    "        pub_articles.insert(0, article)",
    "        self.publisher_cache[article.publisher_id] = pub_articles[:50]",
    "        for category in article.categories:",
    "            cat_articles = self.category_cache[category]",
    "            cat_articles.append(article)",
    "            cat_articles.sort(key=lambda a: a.published_at, reverse=True)",
    "            self.category_cache[category] = cat_articles[:self.CACHE_SIZE]",
    "    ",
    "    def _get_or_create_user(self, user_id: str) -> User:",
    "        if user_id not in self.users:",
    "            self.users[user_id] = User(id=user_id)",
    "        return self.users[user_id]",
    "    ",
    "    def _get_trending_articles(self) -> List[Article]:",
    "        all_articles = list(self.articles.values())",
    "        all_articles.sort(key=lambda a: (a.popularity, a.published_at), reverse=True)",
    "        return all_articles[:50]",
    "    ",
    "    def _paginate(self, items: List[Article], page: int, page_size: int) -> List[Article]:",
    "        start = page * page_size",
    "        return items[start:start + page_size]",
    "    ",
    "    # ========== Part 2: New Methods ==========",
    "    ",
    "    def publish_breaking_news(self, publisher_id: str, article: Article, priority: int) -> None:",
    "        \"\"\"",
    "        Publish breaking news with notifications to interested users.",
    "        Uses inverted indices for O(audience) fanout.",
    "        \"\"\"",
    "        self.ingest_article(article)",
    "        ",
    "        if priority < self.BREAKING_NEWS_THRESHOLD:",
    "            return",
    "        ",
    "        # Find audience using inverted indices - O(1) lookups",
    "        audience: Set[str] = set()",
    "        audience.update(self.publisher_followers.get(publisher_id, set()))",
    "        for category in article.categories:",
    "            audience.update(self.category_subscribers.get(category, set()))",
    "        ",
    "        # Notify eligible users",
    "        now = time.time()",
    "        for user_id in audience:",
    "            if self._should_notify(user_id, article.categories, now):",
    "                self._create_notification(user_id, article, priority, now)",
    "    ",
    "    def set_notification_preferences(self, user_id: str, prefs: NotificationPrefs) -> None:",
    "        \"\"\"Update user's notification settings.\"\"\"",
    "        self._get_or_create_user(user_id)",
    "        self.notification_prefs[user_id] = prefs",
    "    ",
    "    def get_pending_notifications(self, user_id: str) -> List[Notification]:",
    "        \"\"\"Get unread notifications sorted by priority (desc) and time (desc).\"\"\"",
    "        notifications = self.pending_notifications.get(user_id, [])",
    "        unread = [n for n in notifications if not n.read]",
    "        unread.sort(key=lambda n: (n.priority, n.created_at), reverse=True)",
    "        return unread",
    "    ",
    "    def mark_notification_read(self, user_id: str, notification_id: str) -> None:",
    "        \"\"\"Mark notification as read for engagement tracking.\"\"\"",
    "        for notification in self.pending_notifications.get(user_id, []):",
    "            if notification.id == notification_id:",
    "                notification.read = True",
    "                break",
    "    ",
    "    def _should_notify(self, user_id: str, categories: List[str], now: float) -> bool:",
    "        \"\"\"Check notification eligibility: prefs, rate limit, quiet hours.\"\"\"",
    "        prefs = self.notification_prefs.get(user_id, NotificationPrefs())",
    "        ",
    "        if not prefs.enabled:",
    "            return False",
    "        ",
    "        # Category filter (empty = allow all)",
    "        if prefs.categories and not set(categories) & set(prefs.categories):",
    "            return False",
    "        ",
    "        # Quiet hours check (handles overnight span)",
    "        current_hour = int(time.localtime(now).tm_hour)",
    "        if prefs.quiet_hours_start > prefs.quiet_hours_end:",
    "            if current_hour >= prefs.quiet_hours_start or current_hour < prefs.quiet_hours_end:",
    "                return False",
    "        else:",
    "            if prefs.quiet_hours_start <= current_hour < prefs.quiet_hours_end:",
    "                return False",
    "        ",
    "        # Rate limit",
    "        self._maybe_reset_daily_count(user_id, now)",
    "        if self.daily_notification_count[user_id] >= prefs.max_daily:",
    "            return False",
    "        ",
    "        return True",
    "    ",
    "    def _create_notification(self, user_id: str, article: Article,",
    "                             priority: int, now: float) -> None:",
    "        self._notification_counter += 1",
    "        notification = Notification(",
    "            id=f\"notif_{self._notification_counter}\",",
    "            user_id=user_id,",
    "            article_id=article.id,",
    "            title=article.title,",
    "            priority=priority,",
    "            created_at=now",
    "        )",
    "        self.pending_notifications[user_id].append(notification)",
    "        self.daily_notification_count[user_id] += 1",
    "    ",
    "    def _maybe_reset_daily_count(self, user_id: str, now: float) -> None:",
    "        last_reset = self.last_count_reset.get(user_id, 0)",
    "        if now - last_reset > 86400:  # 24 hours",
    "            self.daily_notification_count[user_id] = 0",
    "            self.last_count_reset[user_id] = now",
    "",
    "",
    "if __name__ == '__main__':",
    "    print(\"=\" * 60)",
    "    print(\"PART 2: REAL-TIME NOTIFICATIONS DEMO\")",
    "    print(\"=\" * 60)",
    "    ",
    "    agg = NewsAggregator()",
    "    now = time.time()",
    "    ",
    "    # Setup publishers",
    "    agg.register_publisher(\"pub_nyt\", \"NY Times\", \"rss\", [\"Politics\", \"Breaking\"])",
    "    agg.register_publisher(\"pub_tc\", \"TechCrunch\", \"rss\", [\"Technology\"])",
    "    print(\"\\n[1] Registered publishers\")",
    "    ",
    "    # Setup users with different preferences",
    "    agg.follow_publisher(\"user_1\", \"pub_nyt\")",
    "    agg.set_user_interests(\"user_1\", [\"Politics\", \"Breaking\"])",
    "    agg.set_notification_preferences(\"user_1\", NotificationPrefs(",
    "        max_daily=5, categories=[\"Breaking\", \"Politics\"]))",
    "    ",
    "    agg.follow_publisher(\"user_2\", \"pub_tc\")",
    "    agg.set_user_interests(\"user_2\", [\"Technology\"])",
    "    # user_2 has default prefs (all categories, 5 max daily)",
    "    ",
    "    # user_3 has notifications disabled",
    "    agg.set_notification_preferences(\"user_3\", NotificationPrefs(enabled=False))",
    "    agg.follow_publisher(\"user_3\", \"pub_nyt\")",
    "    print(\"[2] Setup 3 users with different notification preferences\")",
    "    ",
    "    # Publish breaking news - high priority",
    "    breaking_article = Article(",
    "        \"art_breaking_1\", \"pub_nyt\", \"BREAKING: Major Event!\",",
    "        \"url\", [\"Breaking\", \"Politics\"], now, 0.99)",
    "    agg.publish_breaking_news(\"pub_nyt\", breaking_article, priority=10)",
    "    print(\"\\n[3] Published BREAKING news (priority=10)\")",
    "    ",
    "    # Check notifications",
    "    notifs_1 = agg.get_pending_notifications(\"user_1\")",
    "    notifs_2 = agg.get_pending_notifications(\"user_2\")",
    "    notifs_3 = agg.get_pending_notifications(\"user_3\")",
    "    ",
    "    print(f\"    User 1 notifications: {len(notifs_1)} (follows NYT + interested in Breaking)\")",
    "    print(f\"    User 2 notifications: {len(notifs_2)} (follows TechCrunch, not NYT)\")",
    "    print(f\"    User 3 notifications: {len(notifs_3)} (notifications disabled)\")",
    "    ",
    "    # Low priority article - no notifications",
    "    regular_article = Article(",
    "        \"art_regular\", \"pub_nyt\", \"Regular News\",",
    "        \"url\", [\"Politics\"], now, 0.5)",
    "    agg.publish_breaking_news(\"pub_nyt\", regular_article, priority=5)",
    "    print(\"\\n[4] Published regular news (priority=5) - no notifications\")",
    "    ",
    "    notifs_1_after = agg.get_pending_notifications(\"user_1\")",
    "    print(f\"    User 1 notifications still: {len(notifs_1_after)}\")",
    "    ",
    "    # Mark notification as read",
    "    if notifs_1:",
    "        agg.mark_notification_read(\"user_1\", notifs_1[0].id)",
    "        unread_after = agg.get_pending_notifications(\"user_1\")",
    "        print(f\"\\n[5] Marked notification read. Unread count: {len(unread_after)}\")",
    "    ",
    "    # Rate limiting test",
    "    print(\"\\n[6] Testing rate limit (max 5/day)...\")",
    "    for i in range(6):",
    "        art = Article(f\"art_{i}\", \"pub_nyt\", f\"News {i}\", \"url\", [\"Breaking\"], now, 0.9)",
    "        agg.publish_breaking_news(\"pub_nyt\", art, priority=10)",
    "    ",
    "    final_notifs = len(agg.pending_notifications.get(\"user_1\", []))",
    "    print(f\"    Total notifications for user_1: {final_notifs} (capped by rate limit)\")",
    "    ",
    "    print(\"\\n\" + \"=\" * 60)",
    "    print(\"DEMO COMPLETE - Notifications with filtering, rate limits\")",
    "    print(\"=\" * 60)"
  ],
  "solution_java_lines": [
    "import java.util.*;",
    "import java.util.stream.Collectors;",
    "",
    "public class NewsAggregator {",
    "    ",
    "    static class Article {",
    "        String id, publisherId, title, url;",
    "        List<String> categories;",
    "        long publishedAt;",
    "        double popularity, score;",
    "        ",
    "        Article(String id, String publisherId, String title, String url,",
    "                List<String> categories, long publishedAt, double popularity) {",
    "            this.id = id; this.publisherId = publisherId; this.title = title;",
    "            this.url = url; this.categories = categories;",
    "            this.publishedAt = publishedAt; this.popularity = popularity;",
    "        }",
    "    }",
    "    ",
    "    static class Publisher {",
    "        String id, name, rssUrl;",
    "        List<String> categories;",
    "        Publisher(String id, String name, String rssUrl, List<String> categories) {",
    "            this.id = id; this.name = name; this.rssUrl = rssUrl; this.categories = categories;",
    "        }",
    "    }",
    "    ",
    "    static class User {",
    "        String id;",
    "        Set<String> followedPublishers = new HashSet<>();",
    "        Set<String> interests = new HashSet<>();",
    "        Map<String, Integer> publisherAffinity = new HashMap<>();",
    "        User(String id) { this.id = id; }",
    "    }",
    "    ",
    "    // Part 2: New data classes",
    "    static class NotificationPrefs {",
    "        int maxDaily = 5;",
    "        List<String> categories = new ArrayList<>();",
    "        int quietHoursStart = 22, quietHoursEnd = 8;",
    "        boolean enabled = true;",
    "        NotificationPrefs() {}",
    "        NotificationPrefs(int maxDaily, List<String> categories) {",
    "            this.maxDaily = maxDaily; this.categories = categories;",
    "        }",
    "    }",
    "    ",
    "    static class Notification {",
    "        String id, userId, articleId, title;",
    "        int priority;",
    "        long createdAt;",
    "        boolean read = false;",
    "        Notification(String id, String userId, String articleId, String title,",
    "                    int priority, long createdAt) {",
    "            this.id = id; this.userId = userId; this.articleId = articleId;",
    "            this.title = title; this.priority = priority; this.createdAt = createdAt;",
    "        }",
    "    }",
    "    ",
    "    // Part 1 fields",
    "    private Map<String, Publisher> publishers = new HashMap<>();",
    "    private Map<String, User> users = new HashMap<>();",
    "    private Map<String, Article> articles = new HashMap<>();",
    "    private Map<String, List<Article>> categoryCache = new HashMap<>();",
    "    private Map<String, List<Article>> publisherCache = new HashMap<>();",
    "    private Map<String, List<Article>> userFeedCache = new HashMap<>();",
    "    private static final int CACHE_SIZE = 100;",
    "    ",
    "    // Part 2 fields",
    "    private Map<String, NotificationPrefs> notificationPrefs = new HashMap<>();",
    "    private Map<String, List<Notification>> pendingNotifications = new HashMap<>();",
    "    private Map<String, Integer> dailyNotificationCount = new HashMap<>();",
    "    private Map<String, Long> lastCountReset = new HashMap<>();",
    "    private Map<String, Set<String>> categorySubscribers = new HashMap<>();",
    "    private Map<String, Set<String>> publisherFollowers = new HashMap<>();",
    "    private static final int BREAKING_NEWS_THRESHOLD = 8;",
    "    private int notificationCounter = 0;",
    "    ",
    "    public void registerPublisher(String publisherId, String name,",
    "                                  String rssUrl, List<String> categories) {",
    "        publishers.put(publisherId, new Publisher(publisherId, name, rssUrl, categories));",
    "    }",
    "    ",
    "    public void followPublisher(String userId, String publisherId) {",
    "        User user = getOrCreateUser(userId);",
    "        user.followedPublishers.add(publisherId);",
    "        userFeedCache.remove(userId);",
    "        publisherFollowers.computeIfAbsent(publisherId, k -> new HashSet<>()).add(userId);",
    "    }",
    "    ",
    "    public void setUserInterests(String userId, List<String> categories) {",
    "        User user = getOrCreateUser(userId);",
    "        for (String oldCat : user.interests) {",
    "            Set<String> subs = categorySubscribers.get(oldCat);",
    "            if (subs != null) subs.remove(userId);",
    "        }",
    "        user.interests = new HashSet<>(categories);",
    "        for (String cat : categories) {",
    "            categorySubscribers.computeIfAbsent(cat, k -> new HashSet<>()).add(userId);",
    "        }",
    "        userFeedCache.remove(userId);",
    "    }",
    "    ",
    "    public void likeArticle(String userId, String articleId) {",
    "        if (!articles.containsKey(articleId)) return;",
    "        User user = getOrCreateUser(userId);",
    "        String pubId = articles.get(articleId).publisherId;",
    "        user.publisherAffinity.merge(pubId, 1, Integer::sum);",
    "    }",
    "    ",
    "    public List<Article> getUserFeed(String userId, int page, int pageSize) {",
    "        if (userFeedCache.containsKey(userId)) {",
    "            return paginate(userFeedCache.get(userId), page, pageSize);",
    "        }",
    "        User user = getOrCreateUser(userId);",
    "        Map<String, Article> candidates = new HashMap<>();",
    "        for (String interest : user.interests) {",
    "            for (Article a : categoryCache.getOrDefault(interest, List.of())) {",
    "                candidates.put(a.id, a);",
    "            }",
    "        }",
    "        for (String pubId : user.followedPublishers) {",
    "            for (Article a : publisherCache.getOrDefault(pubId, List.of())) {",
    "                candidates.put(a.id, a);",
    "            }",
    "        }",
    "        if (candidates.isEmpty()) {",
    "            candidates = getTrendingArticles().stream()",
    "                .collect(Collectors.toMap(a -> a.id, a -> a));",
    "        }",
    "        List<Article> scored = new ArrayList<>(candidates.values());",
    "        for (Article a : scored) a.score = scoreArticle(a, user);",
    "        scored.sort((a, b) -> Double.compare(b.score, a.score));",
    "        userFeedCache.put(userId, scored);",
    "        return paginate(scored, page, pageSize);",
    "    }",
    "    ",
    "    private double scoreArticle(Article article, User user) {",
    "        double score = 0.0;",
    "        if (user.followedPublishers.contains(article.publisherId)) score += 2.0;",
    "        if (!Collections.disjoint(article.categories, user.interests)) score += 1.5;",
    "        double ageHours = (System.currentTimeMillis() - article.publishedAt) / 3600000.0;",
    "        score += Math.max(0, 1.0 - ageHours / 24);",
    "        score += Math.min(user.publisherAffinity.getOrDefault(article.publisherId, 0) * 0.3, 1.5);",
    "        score += article.popularity * 0.5;",
    "        return score;",
    "    }",
    "    ",
    "    public void ingestArticle(Article article) {",
    "        articles.put(article.id, article);",
    "        publisherCache.computeIfAbsent(article.publisherId, k -> new ArrayList<>()).add(0, article);",
    "        List<Article> pubList = publisherCache.get(article.publisherId);",
    "        if (pubList.size() > 50) pubList.remove(50);",
    "        for (String cat : article.categories) {",
    "            categoryCache.computeIfAbsent(cat, k -> new ArrayList<>()).add(article);",
    "            categoryCache.get(cat).sort((a, b) -> Long.compare(b.publishedAt, a.publishedAt));",
    "            if (categoryCache.get(cat).size() > CACHE_SIZE) {",
    "                categoryCache.put(cat, new ArrayList<>(categoryCache.get(cat).subList(0, CACHE_SIZE)));",
    "            }",
    "        }",
    "    }",
    "    ",
    "    private User getOrCreateUser(String userId) {",
    "        return users.computeIfAbsent(userId, User::new);",
    "    }",
    "    ",
    "    private List<Article> getTrendingArticles() {",
    "        return articles.values().stream()",
    "            .sorted((a, b) -> Double.compare(b.popularity, a.popularity))",
    "            .limit(50).collect(Collectors.toList());",
    "    }",
    "    ",
    "    private List<Article> paginate(List<Article> items, int page, int pageSize) {",
    "        int start = page * pageSize;",
    "        if (start >= items.size()) return List.of();",
    "        return items.subList(start, Math.min(start + pageSize, items.size()));",
    "    }",
    "    ",
    "    // ========== Part 2: New Methods ==========",
    "    ",
    "    public void publishBreakingNews(String publisherId, Article article, int priority) {",
    "        ingestArticle(article);",
    "        if (priority < BREAKING_NEWS_THRESHOLD) return;",
    "        ",
    "        Set<String> audience = new HashSet<>();",
    "        audience.addAll(publisherFollowers.getOrDefault(publisherId, Set.of()));",
    "        for (String cat : article.categories) {",
    "            audience.addAll(categorySubscribers.getOrDefault(cat, Set.of()));",
    "        }",
    "        ",
    "        long now = System.currentTimeMillis();",
    "        for (String userId : audience) {",
    "            if (shouldNotify(userId, article.categories, now)) {",
    "                createNotification(userId, article, priority, now);",
    "            }",
    "        }",
    "    }",
    "    ",
    "    public void setNotificationPreferences(String userId, NotificationPrefs prefs) {",
    "        getOrCreateUser(userId);",
    "        notificationPrefs.put(userId, prefs);",
    "    }",
    "    ",
    "    public List<Notification> getPendingNotifications(String userId) {",
    "        return pendingNotifications.getOrDefault(userId, List.of()).stream()",
    "            .filter(n -> !n.read)",
    "            .sorted((a, b) -> {",
    "                if (a.priority != b.priority) return b.priority - a.priority;",
    "                return Long.compare(b.createdAt, a.createdAt);",
    "            })",
    "            .collect(Collectors.toList());",
    "    }",
    "    ",
    "    public void markNotificationRead(String userId, String notificationId) {",
    "        for (Notification n : pendingNotifications.getOrDefault(userId, List.of())) {",
    "            if (n.id.equals(notificationId)) { n.read = true; break; }",
    "        }",
    "    }",
    "    ",
    "    private boolean shouldNotify(String userId, List<String> categories, long now) {",
    "        NotificationPrefs prefs = notificationPrefs.getOrDefault(userId, new NotificationPrefs());",
    "        if (!prefs.enabled) return false;",
    "        if (!prefs.categories.isEmpty() && Collections.disjoint(categories, prefs.categories))",
    "            return false;",
    "        int hour = java.time.LocalTime.now().getHour();",
    "        if (prefs.quietHoursStart > prefs.quietHoursEnd) {",
    "            if (hour >= prefs.quietHoursStart || hour < prefs.quietHoursEnd) return false;",
    "        } else if (hour >= prefs.quietHoursStart && hour < prefs.quietHoursEnd) return false;",
    "        maybeResetDailyCount(userId, now);",
    "        return dailyNotificationCount.getOrDefault(userId, 0) < prefs.maxDaily;",
    "    }",
    "    ",
    "    private void createNotification(String userId, Article article, int priority, long now) {",
    "        Notification n = new Notification(\"notif_\" + ++notificationCounter,",
    "            userId, article.id, article.title, priority, now);",
    "        pendingNotifications.computeIfAbsent(userId, k -> new ArrayList<>()).add(n);",
    "        dailyNotificationCount.merge(userId, 1, Integer::sum);",
    "    }",
    "    ",
    "    private void maybeResetDailyCount(String userId, long now) {",
    "        Long lastReset = lastCountReset.get(userId);",
    "        if (lastReset == null || now - lastReset > 86400000) {",
    "            dailyNotificationCount.put(userId, 0);",
    "            lastCountReset.put(userId, now);",
    "        }",
    "    }",
    "    ",
    "    public static void main(String[] args) {",
    "        System.out.println(\"=\".repeat(60));",
    "        System.out.println(\"PART 2: REAL-TIME NOTIFICATIONS DEMO\");",
    "        System.out.println(\"=\".repeat(60));",
    "        ",
    "        NewsAggregator agg = new NewsAggregator();",
    "        long now = System.currentTimeMillis();",
    "        ",
    "        agg.registerPublisher(\"pub_nyt\", \"NY Times\", \"rss\", List.of(\"Breaking\"));",
    "        agg.followPublisher(\"user_1\", \"pub_nyt\");",
    "        agg.setUserInterests(\"user_1\", List.of(\"Breaking\"));",
    "        agg.setNotificationPreferences(\"user_1\", new NotificationPrefs(5, List.of(\"Breaking\")));",
    "        System.out.println(\"\\n[1] Setup user following NYT with Breaking notifications enabled\");",
    "        ",
    "        Article breaking = new Article(\"art_1\", \"pub_nyt\", \"BREAKING NEWS!\",",
    "            \"url\", List.of(\"Breaking\"), now, 0.99);",
    "        agg.publishBreakingNews(\"pub_nyt\", breaking, 10);",
    "        System.out.println(\"[2] Published breaking news (priority=10)\");",
    "        ",
    "        List<Notification> notifs = agg.getPendingNotifications(\"user_1\");",
    "        System.out.println(\"[3] User 1 pending notifications: \" + notifs.size());",
    "        ",
    "        if (!notifs.isEmpty()) {",
    "            agg.markNotificationRead(\"user_1\", notifs.get(0).id);",
    "            System.out.println(\"[4] Marked notification as read\");",
    "            System.out.println(\"    Unread count: \" + agg.getPendingNotifications(\"user_1\").size());",
    "        }",
    "        ",
    "        System.out.println(\"\\n\" + \"=\".repeat(60));",
    "        System.out.println(\"DEMO COMPLETE\");",
    "    }",
    "}"
  ],
  "code_walkthrough": [
    {
      "lines": "1-50",
      "explanation": "Data class definitions. Part 2 adds NotificationPrefs (user settings) and Notification (pending alert)."
    },
    {
      "lines": "55-75",
      "explanation": "Constructor adds notification-related fields: inverted indices (category_subscribers, publisher_followers), notification tracking (pending_notifications, daily_notification_count)."
    },
    {
      "lines": "80-95",
      "explanation": "Modified follow_publisher and set_user_interests to maintain inverted indices. When user follows a publisher, we add them to publisher_followers[pub_id]. This is the key optimization."
    },
    {
      "lines": "165-185",
      "explanation": "publish_breaking_news: The core Part 2 method. Uses inverted indices to find audience in O(1) lookups, then iterates over audience applying filters."
    },
    {
      "lines": "190-210",
      "explanation": "_should_notify: Checks enabled flag, category filter, quiet hours (with overnight handling), and rate limit."
    },
    {
      "lines": "215-225",
      "explanation": "get_pending_notifications: Returns unread notifications sorted by priority then time."
    }
  ],
  "complexity_analysis": {
    "time": {
      "new_methods": {
        "publishBreakingNews": {
          "complexity": "O(C + A)",
          "explanation": "C = categories to union, A = audience size to iterate and filter"
        },
        "setNotificationPreferences": {
          "complexity": "O(1)",
          "explanation": "HashMap insertion"
        },
        "getPendingNotifications": {
          "complexity": "O(N log N)",
          "explanation": "N = pending notifications, for sorting"
        },
        "markNotificationRead": {
          "complexity": "O(N)",
          "explanation": "Linear scan through notifications"
        }
      },
      "overall_change": "Part 1 operations unchanged. follow_publisher and set_user_interests have O(1) overhead for index updates."
    },
    "space": {
      "additional_space": "O(U * avg_interests + U * avg_notifications)",
      "explanation": "Inverted indices store each user-interest pair twice (forward and reverse). Pending notifications stored per user."
    }
  },
  "dry_run": {
    "example_input": "follow_publisher(user_1, pub_nyt), set_user_interests(user_1, ['Breaking']), publish_breaking_news(pub_nyt, article, 10)",
    "steps": [
      {
        "step": 1,
        "action": "follow_publisher('user_1', 'pub_nyt')",
        "state": "publisher_followers = {'pub_nyt': {'user_1'}}",
        "explanation": "User added to inverted index"
      },
      {
        "step": 2,
        "action": "set_user_interests('user_1', ['Breaking'])",
        "state": "category_subscribers = {'Breaking': {'user_1'}}",
        "explanation": "User added to category index"
      },
      {
        "step": 3,
        "action": "publish_breaking_news(pub_nyt, article, 10)",
        "state": "Finding audience...",
        "explanation": "Priority 10 >= 8, proceed with notifications"
      },
      {
        "step": 4,
        "action": "Build audience from indices",
        "state": "audience = {'user_1'} (from publisher) \u222a {'user_1'} (from category) = {'user_1'}",
        "explanation": "O(1) lookups to find interested users"
      },
      {
        "step": 5,
        "action": "_should_notify('user_1', ...)",
        "state": "Checking prefs, rate limit, quiet hours",
        "explanation": "All filters pass"
      },
      {
        "step": 6,
        "action": "_create_notification",
        "state": "pending_notifications['user_1'] = [Notification(...)]",
        "explanation": "Notification created and queued"
      }
    ],
    "final_output": "get_pending_notifications('user_1') returns [Notification(title='BREAKING: Major Event!', priority=10)]"
  },
  "debugging_playbook": {
    "fast_sanity_checks": [
      "Publish breaking news to user following publisher \u2192 should get notification",
      "User with notifications disabled \u2192 should NOT get notification"
    ],
    "likely_bugs": [
      "Forgetting to update inverted index in follow_publisher",
      "Quiet hours overnight check logic (22:00-08:00)",
      "Rate limit not resetting after 24 hours"
    ],
    "recommended_logs_or_asserts": [
      "assert user_id in publisher_followers[pub_id] after follow",
      "log audience size in publish_breaking_news"
    ],
    "how_to_localize": "If notification not received: (1) Check inverted indices contain user, (2) Check shouldNotify returns true, (3) Check notification was created"
  },
  "edge_cases": [
    {
      "case": "Priority below threshold (< 8)",
      "handling": "Return early after ingest_article, no notifications sent",
      "gotcha": "Article should still be ingested for feed"
    },
    {
      "case": "User with no preferences set",
      "handling": "Use default NotificationPrefs (enabled=true, max_daily=5)",
      "gotcha": "Don't throw exception for missing prefs"
    },
    {
      "case": "Quiet hours overnight (22:00-08:00)",
      "handling": "Check if start > end, then block if hour >= start OR hour < end",
      "gotcha": "Simple range check fails for overnight spans"
    },
    {
      "case": "Rate limit exactly at max",
      "handling": "Block notification when count >= max_daily",
      "gotcha": "Use >= not > for the check"
    },
    {
      "case": "User interested via both publisher AND category",
      "handling": "Using Set for audience automatically dedupes",
      "gotcha": "Don't send duplicate notifications"
    }
  ],
  "test_cases": [
    {
      "name": "Basic notification delivery",
      "input": "follow_publisher(u1, pub_nyt), set_user_interests(u1, ['Breaking']), publish_breaking_news(pub_nyt, article, 10)",
      "expected": "get_pending_notifications(u1) returns 1 notification",
      "explanation": "User matches via publisher follow"
    },
    {
      "name": "Low priority - no notification",
      "input": "publish_breaking_news(pub_nyt, article, priority=5)",
      "expected": "get_pending_notifications(u1) returns 0",
      "explanation": "Priority 5 < threshold 8"
    },
    {
      "name": "Notifications disabled",
      "input": "set_notification_preferences(u1, NotificationPrefs(enabled=False))",
      "expected": "No notifications regardless of breaking news",
      "explanation": "User opted out"
    },
    {
      "name": "Rate limit reached",
      "input": "Publish 6 breaking news articles",
      "expected": "User receives only 5 notifications",
      "explanation": "max_daily=5 enforced"
    }
  ],
  "common_mistakes": [
    {
      "mistake": "Scanning all users on breaking news",
      "why_wrong": "O(N) where N = all users. Doesn't scale to millions.",
      "correct_approach": "Use inverted indices for O(audience) lookup",
      "code_example_wrong": "for user in all_users: if user matches article: notify(user)",
      "code_example_correct": "audience = publisher_followers[pub] | category_subscribers[cat]"
    },
    {
      "mistake": "Not updating inverted index on preference change",
      "why_wrong": "User changes interests but old categories still point to them",
      "correct_approach": "Remove from old indices, add to new indices in set_user_interests",
      "code_example_wrong": "user.interests = new_interests",
      "code_example_correct": "for old in user.interests: index[old].remove(user_id)\\nfor new in new_interests: index[new].add(user_id)"
    },
    {
      "mistake": "Quiet hours simple range check",
      "why_wrong": "Fails for overnight: 22 <= hour < 8 is always false",
      "correct_approach": "Check if start > end, then use OR logic",
      "code_example_wrong": "if start <= hour < end: block",
      "code_example_correct": "if start > end: block if hour >= start OR hour < end"
    }
  ],
  "interview_tips": {
    "how_to_present": "Start by explaining the key insight: 'Part 1 was pull-based - users fetch feeds. Part 2 requires push - we proactively notify users. The challenge is finding who cares about an article without scanning all users. I'll use inverted indices.'",
    "what_to_mention": [
      "Why inverted index: O(audience) vs O(all_users)",
      "Incremental index maintenance on preference changes",
      "Rate limiting with daily reset",
      "Quiet hours with overnight handling"
    ],
    "time_allocation": "2 min explain approach, 8 min code, 2 min test",
    "if_stuck": [
      "Think about how Google News knows who to notify instantly",
      "Consider pre-computing the reverse mapping"
    ]
  },
  "connection_to_next_part": "Part 3 could add: (1) ML-based notification ranking - not all notifications are equally important, (2) A/B testing notification content, (3) Distributed notification delivery with exactly-once semantics, (4) Global distribution with regional notification servers.",
  "communication_script": {
    "transition_from_previous": "Great, Part 1 handles feed generation with caching. For Part 2, I need to add push notifications for breaking news. The key challenge is finding interested users fast - within 30 seconds.",
    "explaining_changes": "The main change is adding inverted indices. When a user follows a publisher, I update both user.followed_publishers AND publisher_followers[pub_id]. Same for interests. This way, when breaking news arrives, I can find the audience in O(1) lookups.",
    "while_extending_code": [
      "I'm adding two inverted indices here for fast audience lookup",
      "This notification filter checks prefs, rate limit, and quiet hours",
      "The rate limit uses a simple daily counter with 24-hour reset"
    ],
    "after_completing": "Part 2 is done. publish_breaking_news is O(audience_size) thanks to the inverted indices. The filters ensure we respect user preferences. Ready for Part 3?"
  },
  "time_milestones": {
    "time_budget": "10-12 minutes",
    "by_2_min": "Explain inverted index insight, draw diagram",
    "by_5_min": "Add data classes and indices, start publishBreakingNews",
    "by_10_min": "Complete all methods, run through test case",
    "warning_signs": "If still explaining at 4 min, start coding. Ask for hints if index idea not clear."
  },
  "recovery_strategies": {
    "if_part_builds_wrong": "If Part 1 caching is broken, note it but continue - Part 2 adds independent notification layer",
    "if_new_requirement_unclear": "Ask: 'For the 30-second SLA, should I assume single datacenter or discuss distributed fanout?'",
    "if_running_behind": "Skip quiet hours logic, mention verbally. Focus on index-based audience lookup - that's the key insight."
  },
  "signal_points": {
    "wow_factors_for_followup": [
      "Immediately identifying inverted index as the solution",
      "Mentioning Kafka for async notification processing in production",
      "Discussing rate limiting with Redis sorted sets for sliding window",
      "Noting the index maintenance overhead on preference changes"
    ]
  },
  "pattern_recognition": {
    "pattern": "Inverted Index / Fan-out on Write",
    "indicators": [
      "Need to find all X matching Y quickly",
      "Can't scan all items on each query",
      "Writes are less frequent than reads"
    ],
    "similar_problems": [
      "Search engine indexing (term \u2192 documents)",
      "Twitter timeline (user \u2192 tweets to show)",
      "Social graph queries (who follows whom)"
    ],
    "template": "# Inverted index pattern\\nforward_map: Dict[user_id, Set[category]]  # What user likes\\nreverse_map: Dict[category, Set[user_id]]  # Who likes this\\n# On update: modify both maps\\n# On query: O(1) lookup in reverse_map"
  },
  "thinking_process": [
    {
      "step": 1,
      "thought": "When I see '30-second SLA for notification delivery', I think...",
      "why": "We can't scan all users - need O(1) audience lookup"
    },
    {
      "step": 2,
      "thought": "The article has categories and publisher. Users have interests and follows...",
      "why": "This is a matching problem - inverted index inverts the relationship"
    },
    {
      "step": 3,
      "thought": "Rate limiting and quiet hours are filters on top of the audience...",
      "why": "Apply filters after finding audience, not during user scan"
    }
  ],
  "interviewer_perspective": {
    "what_they_evaluate": [
      "Can you identify the need for inverted indexing?",
      "Do you maintain indices incrementally?",
      "Can you handle edge cases like overnight quiet hours?"
    ],
    "bonus_points": [
      "Mentioning message queue (Kafka) for production fanout",
      "Discussing index consistency on preference changes",
      "Noting trade-off: more space for faster queries"
    ],
    "red_flags": [
      "Scanning all users on each breaking news",
      "Forgetting to update indices on preference change",
      "Complex solution when simple inverted index suffices"
    ]
  },
  "ai_copilot_tips": {
    "what_to_do": [
      "Use AI for boilerplate like Notification dataclass",
      "Let it help with quiet hours time logic"
    ],
    "what_not_to_do": [
      "Don't let AI suggest scanning all users",
      "Verify the index update logic - AI might miss edge cases"
    ]
  },
  "red_flags_to_avoid": {
    "behavioral": [
      "Jumping to code without explaining index strategy",
      "Not testing the notification flow end-to-end"
    ],
    "technical": [
      "O(N) audience lookup",
      "Not handling overnight quiet hours",
      "Missing index updates on set_user_interests"
    ],
    "communication": [
      "Not explaining why inverted index is necessary",
      "Forgetting to mention rate limit reset logic"
    ]
  },
  "final_checklist": {
    "before_saying_done": [
      "Does publishBreakingNews use inverted indices (not user scan)?",
      "Are indices updated in follow_publisher AND set_user_interests?",
      "Does shouldNotify check all filters: enabled, category, quiet hours, rate limit?",
      "Did I trace through an example showing notification delivery?"
    ],
    "quick_code_review": [
      "Consistent naming with Part 1 (snake_case for Python)",
      "Type hints on new methods",
      "Default NotificationPrefs for users without explicit settings"
    ]
  },
  "production_considerations": {
    "what_i_would_add": [
      "Message queue (Kafka) for async notification processing",
      "Redis sorted sets for sliding window rate limits",
      "Circuit breaker for push gateway (FCM/APNS)",
      "Metrics: notification latency, delivery rate, engagement"
    ],
    "why_not_in_interview": "Focus on core algorithm - index-based fanout. Mention distributed concerns verbally.",
    "how_to_mention": "Say: 'In production, I'd use Kafka for fanout and Redis for rate limiting. The core insight remains the same - inverted indices for fast audience lookup.'"
  },
  "generated_at": "2026-01-19T04:46:46.545597",
  "_meta": {
    "problem_id": "news_feed_aggregator",
    "part_number": 2,
    "model": "claude-opus-4-5-20251101"
  }
}