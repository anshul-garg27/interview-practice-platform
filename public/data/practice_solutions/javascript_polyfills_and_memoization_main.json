{
  "problem_title": "JavaScript Polyfills & Memoization",
  "difficulty": "medium",
  "category": "Frontend/JavaScript",
  "estimated_time": "45-60 minutes",
  "problem_analysis": {
    "first_impressions": "This is a **closure and higher-order function** problem. We need to wrap a function to intercept calls, cache results, and return cached values when the same arguments are seen again. The pattern is extremely common in frontend development (React's useMemo, Redux selectors, etc.).",
    "pattern_recognition": "**Closure Pattern** + **HashMap/Cache** + **Serialization**. The closure maintains private state (the cache), the HashMap provides O(1) lookup, and serialization creates unique keys from arguments.",
    "key_constraints": [
      "Type differentiation required - `fn(1)` vs `fn('1')` must have DIFFERENT cache keys",
      "Must handle multiple arguments of varying types",
      "Must preserve `this` context for methods",
      "JSON.stringify limitations with undefined, functions, and circular references"
    ],
    "clarifying_questions": [
      "**Q: What argument types should be supported?** - Determines if simple JSON.stringify works or if we need custom serialization",
      "**Q: Should identical objects (different references) be treated as same key?** - `fn({a:1})` called twice with separate objects",
      "**Q: Do we need cache eviction/LRU?** - For memory management in long-running apps",
      "**Q: Should we handle async functions?** - Part 2 covers this, so Part 1 is sync-only",
      "**Q: What about `this` binding?** - Important for memoizing methods on objects",
      "**Q: Should we handle recursive memoization?** - e.g., memoized fibonacci calling itself"
    ],
    "edge_cases_to_consider": [
      "Empty arguments: `fn()` should work",
      "null vs undefined arguments - must be distinguishable",
      "Number vs string that looks like number: `1` vs `'1'`",
      "Array argument vs multiple args: `fn([1,2])` vs `fn(1,2)`",
      "Object with same structure but different reference",
      "Functions returning undefined vs never cached"
    ]
  },
  "requirements_coverage": {
    "checklist": [
      {
        "requirement": "Takes any function as input",
        "how_met": "Accept `fn` parameter, return wrapper function",
        "gotchas": [
          "Don't validate fn type - assume it's callable"
        ]
      },
      {
        "requirement": "Returns memoized function that caches results",
        "how_met": "Closure with Map for cache storage",
        "gotchas": [
          "Must return the RESULT, not a promise (Part 1)"
        ]
      },
      {
        "requirement": "Cache key based on ALL arguments",
        "how_met": "JSON.stringify(args) captures full argument list",
        "gotchas": [
          "args.toString() fails for type differentiation"
        ]
      },
      {
        "requirement": "Handle primitives correctly",
        "how_met": "JSON.stringify preserves type: `[1]` vs `[\"1\"]`",
        "gotchas": [
          "undefined in arrays becomes null"
        ]
      },
      {
        "requirement": "Handle null and undefined",
        "how_met": "JSON.stringify works for null; undefined becomes null in arrays",
        "gotchas": [
          "Can use custom replacer for better handling"
        ]
      },
      {
        "requirement": "Preserve `this` context",
        "how_met": "Use `fn.apply(this, args)` not `fn(...args)`",
        "gotchas": [
          "Arrow functions don't have own `this`"
        ]
      }
    ],
    "complexity_targets": [
      {
        "operation": "Cache lookup",
        "target": "O(1)",
        "achieved": "O(1)",
        "why": "Map.has() and Map.get() are O(1)"
      },
      {
        "operation": "Cache storage",
        "target": "O(1)",
        "achieved": "O(1)",
        "why": "Map.set() is O(1)"
      },
      {
        "operation": "Key generation",
        "target": "O(k)",
        "achieved": "O(k)",
        "why": "JSON.stringify is O(k) where k = args size"
      },
      {
        "operation": "Function call (cache miss)",
        "target": "O(fn)",
        "achieved": "O(fn)",
        "why": "Depends on original function complexity"
      }
    ],
    "non_goals": [
      "Cache eviction (no LRU, no max size)",
      "Async function handling (Part 2)",
      "Object reference identity (using structural equality via JSON)",
      "Thread safety (JS is single-threaded)"
    ]
  },
  "assumptions": [
    "**Primitive focus**: Primary use case is primitive arguments (numbers, strings, booleans)",
    "**No circular references**: Objects passed don't have circular references (JSON.stringify would throw)",
    "**Unlimited cache**: No memory limits; cache grows unbounded",
    "**Sync functions only**: Part 1 assumes synchronous functions",
    "**Serializable arguments**: All arguments can be JSON.stringify'd meaningfully"
  ],
  "tradeoffs": [
    {
      "decision": "Map vs Object for cache",
      "chosen": "Map",
      "why": "Cleaner API (.has, .get, .set), no prototype chain issues, any key type",
      "alternative": "Plain Object {}",
      "when_to_switch": "If need to serialize cache for persistence, Object is easier"
    },
    {
      "decision": "JSON.stringify vs custom serializer",
      "chosen": "JSON.stringify",
      "why": "Built-in, handles most cases, type-safe for primitives",
      "alternative": "Custom serializer with type tags",
      "when_to_switch": "If need to handle functions, symbols, or circular refs"
    },
    {
      "decision": "Regular function vs arrow function for wrapper",
      "chosen": "Regular function",
      "why": "Preserves `this` binding for method memoization",
      "alternative": "Arrow function",
      "when_to_switch": "Never for memoize wrapper; arrow functions don't have own `this`"
    }
  ],
  "extensibility_and_followups": {
    "design_principles": [
      "Keep the core memoize function simple and focused",
      "Use closure to encapsulate cache state",
      "Separate concerns: key generation could be customizable"
    ],
    "why_this_design_scales": "The cache is isolated per memoized function. To add features like custom key generation, we can add optional parameter: `memoize(fn, keyGenerator)`. For async (Part 2), we wrap the Promise handling around the same core logic.",
    "expected_followup_hooks": [
      "Key generation function can be swapped for custom serialization",
      "Cache can be replaced with LRU cache for memory limits",
      "Result handler can be wrapped for async/Promise support",
      "Timer can be added for TTL-based expiration"
    ],
    "invariants": [
      "Same arguments (by serialization) ALWAYS return same cached result",
      "First call with new args ALWAYS executes original function",
      "Cache is private and cannot be accessed externally (unless exposed)"
    ]
  },
  "visual_explanation": {
    "problem_visualization": "```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  MEMOIZATION CONCEPT                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                             \u2502\n\u2502   Original Function:  add(a, b) => a + b                    \u2502\n\u2502                                                             \u2502\n\u2502   Without Memoization:                                      \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  add(1,2) \u2500\u2500compute\u2500\u2500> 3                            \u2502   \u2502\n\u2502   \u2502  add(1,2) \u2500\u2500compute\u2500\u2500> 3  (repeated work!)          \u2502   \u2502\n\u2502   \u2502  add(1,2) \u2500\u2500compute\u2500\u2500> 3  (repeated work!)          \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                             \u2502\n\u2502   With Memoization:                                         \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  add(1,2) \u2500\u2500compute\u2500\u2500> 3 \u2500\u2500store\u2500\u2500> cache['[1,2]']  \u2502   \u2502\n\u2502   \u2502  add(1,2) \u2500\u2500lookup\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500> cache hit! 3     \u2502   \u2502\n\u2502   \u2502  add(1,2) \u2500\u2500lookup\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500> cache hit! 3     \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```",
    "data_structure_state": "```\n                    CLOSURE STRUCTURE\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  memoize(fn) creates:                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Closure Scope (private):                       \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502  \u2502\n\u2502  \u2502  \u2502  fn: [original function reference]      \u2502    \u2502  \u2502\n\u2502  \u2502  \u2502  cache: Map {                           \u2502    \u2502  \u2502\n\u2502  \u2502  \u2502    '[1,2]' => 3,                        \u2502    \u2502  \u2502\n\u2502  \u2502  \u2502    '[5]' => 25,                         \u2502    \u2502  \u2502\n\u2502  \u2502  \u2502    '[]' => 0                            \u2502    \u2502  \u2502\n\u2502  \u2502  \u2502  }                                      \u2502    \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                          \u2502                            \u2502\n\u2502                          \u25bc                            \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Returns: function memoized(...args) { ... }   \u2502  \u2502\n\u2502  \u2502  - Has access to fn and cache via closure      \u2502  \u2502\n\u2502  \u2502  - Intercepts all calls to original function   \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```",
    "algorithm_flow": [
      {
        "step": 1,
        "description": "Receive arguments in memoized function",
        "visualization": "```\nmemoizedAdd(1, 2)\n     \u2502\n     \u25bc\nargs = [1, 2]\n```",
        "key_point": "Use rest parameters (...args) to capture all arguments"
      },
      {
        "step": 2,
        "description": "Generate cache key from arguments",
        "visualization": "```\nargs = [1, 2]\n     \u2502\n     \u25bc JSON.stringify\nkey = '[1,2]'\n```",
        "key_point": "JSON.stringify preserves types: number 1 vs string '1'"
      },
      {
        "step": 3,
        "description": "Check if key exists in cache",
        "visualization": "```\ncache.has('[1,2]')?\n     \u2502\n  \u250c\u2500\u2500\u2534\u2500\u2500\u2510\n YES   NO\n  \u2502     \u2502\n  \u25bc     \u25bc\n```",
        "key_point": "Map.has() is O(1) lookup"
      },
      {
        "step": 4,
        "description": "Return cached or compute new result",
        "visualization": "```\nCACHE HIT:              CACHE MISS:\nreturn cache.get(key)   result = fn.apply(this, args)\n                        cache.set(key, result)\n                        return result\n```",
        "key_point": "Use fn.apply(this, args) to preserve 'this' context"
      }
    ],
    "dry_run_table": "| Step | Call | Key Generated | Cache State | Action | Result |\n|------|------|--------------|-------------|--------|--------|\n| 1 | `memoizedAdd(1, 2)` | `'[1,2]'` | `{}` | MISS \u2192 Compute 1+2 | 3 |\n| 2 | `memoizedAdd(1, 2)` | `'[1,2]'` | `{'[1,2]': 3}` | HIT \u2192 Return cached | 3 |\n| 3 | `memoizedAdd(2, 3)` | `'[2,3]'` | `{'[1,2]': 3}` | MISS \u2192 Compute 2+3 | 5 |\n| 4 | `memoizedAdd('1', '2')` | `'[\"1\",\"2\"]'` | `{'[1,2]': 3, '[2,3]': 5}` | MISS \u2192 Compute | '12' |"
  },
  "thinking_process": {
    "step_by_step": [
      "**When I see 'memoization'**, I immediately think of closures and caching. The memoize function needs to create a private cache that persists across calls.",
      "**The key challenge is argument serialization**. I need a way to convert any set of arguments into a unique string key. JSON.stringify is the standard approach.",
      "**I must handle type differentiation**. The number `1` and string `'1'` must produce different keys. JSON.stringify handles this: `JSON.stringify([1])` \u2192 `'[1]'` vs `JSON.stringify(['1'])` \u2192 `'[\"1\"]'`.",
      "**The `this` context matters**. If someone memoizes a method, they expect `this` to work. I must use `fn.apply(this, args)` not `fn(...args)`.",
      "**Choose Map over Object for cache**. Map has cleaner API, no prototype issues, and works with any key type.",
      "**Return a regular function, not arrow**. Arrow functions don't have their own `this`, which would break method memoization."
    ],
    "key_insight": "**The 'aha' moment**: Memoization is essentially intercepting function calls with a proxy that maintains state. The closure provides the private state, JSON.stringify provides unique keys, and `fn.apply(this, args)` preserves the calling context. These three pieces together create a complete, correct memoization wrapper.",
    "why_this_works": "Closures in JavaScript allow the inner function to access variables from the outer scope (the cache and original function) even after the outer function returns. Each memoized function gets its own private cache. JSON.stringify is deterministic\u2014same input always produces same output string. Map provides O(1) key lookup. Together, these guarantee correctness and performance."
  },
  "approaches": [
    {
      "name": "Brute Force: toString() Key Generation",
      "description": "Use `args.toString()` or `args.join(',')` to create cache key",
      "pseudocode": "key = args.toString()  // or args.join(',')\nif (cache[key]) return cache[key]\nresult = fn(...args)\ncache[key] = result\nreturn result",
      "time_complexity": "O(k) for key generation, O(1) for lookup",
      "space_complexity": "O(n * k) where n = unique calls, k = arg size",
      "pros": [
        "Simple to implement",
        "Fast key generation"
      ],
      "cons": [
        "TYPE COLLISION: `[1,2]` and `['1','2']` both become `'1,2'`",
        "`[null]` and `['null']` collide",
        "Arrays within args cause issues"
      ],
      "when_to_use": "Never in production\u2014only for quick prototyping with known number-only inputs"
    },
    {
      "name": "Optimal: JSON.stringify with Map Cache",
      "description": "Use JSON.stringify for type-safe serialization and Map for storage",
      "pseudocode": "function memoize(fn) {\n  const cache = new Map()\n  return function(...args) {\n    const key = JSON.stringify(args)\n    if (cache.has(key)) return cache.get(key)\n    const result = fn.apply(this, args)\n    cache.set(key, result)\n    return result\n  }\n}",
      "time_complexity": "O(k) for JSON.stringify, O(1) for Map operations",
      "space_complexity": "O(n * k) for n unique argument sets of size k",
      "pros": [
        "Type-safe: numbers and strings differentiated",
        "Handles null properly",
        "Preserves `this` context",
        "Clean, readable code"
      ],
      "cons": [
        "undefined becomes null in arrays",
        "Can't handle circular references",
        "Functions/Symbols are ignored"
      ],
      "key_insight": "JSON.stringify is the standard because it's built-in, fast, and handles 95% of use cases. The edge cases it misses are rare in practice."
    },
    {
      "name": "Advanced: Custom Serializer with Type Tags",
      "description": "Prepend type tags to handle edge cases like undefined",
      "pseudocode": "function serialize(args) {\n  return args.map(arg => {\n    if (arg === undefined) return 'undefined:'\n    if (typeof arg === 'symbol') return `symbol:${arg.toString()}`\n    return `${typeof arg}:${JSON.stringify(arg)}`\n  }).join('|')\n}",
      "time_complexity": "O(k) same as JSON.stringify",
      "space_complexity": "O(n * k)",
      "pros": [
        "Handles undefined properly",
        "Can extend for symbols/functions",
        "More precise type handling"
      ],
      "cons": [
        "More complex",
        "Likely overkill for interview",
        "Still can't handle circular refs"
      ],
      "when_to_use": "Production code with strict requirements for edge cases"
    }
  ],
  "optimal_solution": {
    "name": "JSON.stringify with Map Cache and this Preservation",
    "explanation_md": "## Approach\n\nThe optimal solution uses three key JavaScript features:\n\n### 1. Closures for Private State\n```javascript\nfunction memoize(fn) {\n  const cache = new Map();  // Private, persists across calls\n  return function(...args) {\n    // Has access to cache and fn via closure\n  };\n}\n```\n\n### 2. JSON.stringify for Type-Safe Keys\n```javascript\nJSON.stringify([1, 2])     // '[1,2]'\nJSON.stringify(['1', '2']) // '[\"1\",\"2\"]'  <- Different!\nJSON.stringify([null])     // '[null]'\nJSON.stringify([])         // '[]'\n```\n\n### 3. fn.apply(this, args) for Context\n```javascript\nconst result = fn.apply(this, args);  // Preserves 'this'\n// NOT fn(...args) which loses 'this'\n```\n\n### Why This Works\n- **Closure** keeps cache private and persistent\n- **JSON.stringify** creates unique keys that differentiate types\n- **Map** provides O(1) lookup without prototype chain issues\n- **apply()** ensures methods work correctly when memoized",
    "data_structures": [
      {
        "structure": "Map<string, any>",
        "purpose": "O(1) cache storage and lookup by serialized key"
      },
      {
        "structure": "Closure scope",
        "purpose": "Maintains private reference to original fn and cache"
      }
    ],
    "algorithm_steps": [
      "1. Create empty Map as cache in closure scope",
      "2. Return wrapper function that captures all args with rest operator",
      "3. Serialize args to string using JSON.stringify",
      "4. Check if key exists in cache using Map.has()",
      "5. If cache hit: return cached value immediately",
      "6. If cache miss: call original fn with apply() to preserve this",
      "7. Store result in cache with key",
      "8. Return result"
    ],
    "why_decimal": "N/A for this problem - no currency/precision concerns"
  },
  "solution_python_lines": [
    "\"\"\"",
    "Memoization Implementation in Python",
    "",
    "Demonstrates the same concepts as JavaScript memoization:",
    "- Closures for private state",
    "- Serialization for cache keys",
    "- Caching for performance optimization",
    "\"\"\"",
    "import json",
    "from typing import Callable, Any, TypeVar",
    "from functools import wraps",
    "",
    "F = TypeVar('F', bound=Callable[..., Any])",
    "",
    "",
    "def memoize(fn: Callable) -> Callable:",
    "    \"\"\"",
    "    Returns memoized version of fn that caches results.",
    "    Uses JSON serialization for type-safe cache keys.",
    "    \"\"\"",
    "    cache = {}  # Private cache via closure",
    "    ",
    "    @wraps(fn)  # Preserves function metadata",
    "    def memoized(*args, **kwargs):",
    "        # Generate unique key from all arguments",
    "        # Combine positional and keyword args for complete key",
    "        key = json.dumps((args, sorted(kwargs.items())), default=str)",
    "        ",
    "        if key in cache:",
    "            return cache[key]  # Cache hit",
    "        ",
    "        result = fn(*args, **kwargs)  # Cache miss - compute",
    "        cache[key] = result",
    "        return result",
    "    ",
    "    # Expose cache for testing (optional)",
    "    memoized.cache = cache",
    "    return memoized",
    "",
    "",
    "# ============ Demo and Tests ============",
    "if __name__ == '__main__':",
    "    print('=' * 60)",
    "    print('MEMOIZATION DEMO')",
    "    print('=' * 60)",
    "    ",
    "    # Track call count to verify memoization",
    "    call_count = 0",
    "    ",
    "    def expensive_add(a, b):",
    "        global call_count",
    "        call_count += 1",
    "        print(f'  Computing {a} + {b}...')",
    "        return a + b",
    "    ",
    "    memoized_add = memoize(expensive_add)",
    "    ",
    "    # Test 1: Basic memoization",
    "    print('\\n[Test 1] Basic Memoization:')",
    "    print(f'  memoized_add(1, 2) = {memoized_add(1, 2)}')",
    "    print(f'  memoized_add(1, 2) = {memoized_add(1, 2)}  # Cache hit!')",
    "    print(f'  memoized_add(2, 3) = {memoized_add(2, 3)}')",
    "    print(f'  Call count: {call_count} (should be 2)')",
    "    ",
    "    # Test 2: Type differentiation",
    "    print('\\n[Test 2] Type Differentiation:')",
    "    def identity(x):",
    "        return x",
    "    ",
    "    memo_id = memoize(identity)",
    "    print(f'  identity(1) = {memo_id(1)} (type: {type(memo_id(1)).__name__})')",
    "    print(f'  identity(\"1\") = {memo_id(\"1\")} (type: {type(memo_id(\"1\")).__name__})')",
    "    print(f'  Cache keys: {list(memo_id.cache.keys())}')",
    "    ",
    "    # Test 3: Expensive computation (Fibonacci)",
    "    print('\\n[Test 3] Fibonacci Performance:')",
    "    fib_calls = 0",
    "    ",
    "    def fib(n):",
    "        global fib_calls",
    "        fib_calls += 1",
    "        if n <= 1:",
    "            return n",
    "        return fib(n - 1) + fib(n - 2)",
    "    ",
    "    memo_fib = memoize(fib)",
    "    ",
    "    import time",
    "    start = time.time()",
    "    result = memo_fib(30)",
    "    first_time = time.time() - start",
    "    print(f'  fib(30) = {result}')",
    "    print(f'  First call: {first_time:.4f}s')",
    "    ",
    "    start = time.time()",
    "    result = memo_fib(30)",
    "    second_time = time.time() - start",
    "    print(f'  Second call: {second_time:.6f}s (cache hit!)')",
    "    ",
    "    print('\\n' + '=' * 60)",
    "    print('All tests passed!')"
  ],
  "solution_java_lines": [
    "import java.util.*;",
    "import java.util.function.Function;",
    "import com.google.gson.Gson;  // For JSON serialization",
    "",
    "/**",
    " * Memoization utility for Java.",
    " * Demonstrates caching function results based on arguments.",
    " */",
    "public class Memoize {",
    "    ",
    "    private static final Gson gson = new Gson();",
    "    ",
    "    /**",
    "     * Creates a memoized version of a single-argument function.",
    "     * Uses JSON serialization for cache keys to handle different types.",
    "     */",
    "    public static <T, R> Function<T, R> memoize(Function<T, R> fn) {",
    "        Map<String, R> cache = new HashMap<>();",
    "        ",
    "        return (T arg) -> {",
    "            String key = gson.toJson(arg);",
    "            ",
    "            if (cache.containsKey(key)) {",
    "                return cache.get(key);  // Cache hit",
    "            }",
    "            ",
    "            R result = fn.apply(arg);  // Cache miss",
    "            cache.put(key, result);",
    "            return result;",
    "        };",
    "    }",
    "    ",
    "    /**",
    "     * Memoized function wrapper for multi-argument functions.",
    "     * Wraps varargs into a key using JSON array serialization.",
    "     */",
    "    @FunctionalInterface",
    "    public interface MultiArgFunction<R> {",
    "        R apply(Object... args);",
    "    }",
    "    ",
    "    public static <R> MultiArgFunction<R> memoizeMulti(MultiArgFunction<R> fn) {",
    "        Map<String, R> cache = new HashMap<>();",
    "        ",
    "        return (Object... args) -> {",
    "            String key = gson.toJson(args);",
    "            ",
    "            if (cache.containsKey(key)) {",
    "                return cache.get(key);",
    "            }",
    "            ",
    "            R result = fn.apply(args);",
    "            cache.put(key, result);",
    "            return result;",
    "        };",
    "    }",
    "    ",
    "    // ============ Demo ============",
    "    public static void main(String[] args) {",
    "        System.out.println(\"=\".repeat(60));",
    "        System.out.println(\"MEMOIZATION DEMO (Java)\");",
    "        System.out.println(\"=\".repeat(60));",
    "        ",
    "        // Test: Single argument memoization",
    "        int[] callCount = {0};  // Array for mutation in lambda",
    "        ",
    "        Function<Integer, Integer> square = n -> {",
    "            callCount[0]++;",
    "            System.out.println(\"  Computing \" + n + \"^2...\");",
    "            return n * n;",
    "        };",
    "        ",
    "        Function<Integer, Integer> memoSquare = memoize(square);",
    "        ",
    "        System.out.println(\"\\n[Test] Basic Memoization:\");",
    "        System.out.println(\"  square(5) = \" + memoSquare.apply(5));",
    "        System.out.println(\"  square(5) = \" + memoSquare.apply(5) + \" (cache hit!)\");",
    "        System.out.println(\"  square(7) = \" + memoSquare.apply(7));",
    "        System.out.println(\"  Call count: \" + callCount[0] + \" (should be 2)\");",
    "        ",
    "        System.out.println(\"\\n\" + \"=\".repeat(60));",
    "        System.out.println(\"Demo complete!\");",
    "    }",
    "}"
  ],
  "code_walkthrough": [
    {
      "lines": "1-15 (JS version)",
      "section": "Function Signature and Cache Setup",
      "explanation": "The `memoize` function takes any function `fn` as input. We immediately create a `Map` for our cache. This Map lives in the closure scope\u2014it's private and persists for the lifetime of the memoized function. Using Map over Object gives us cleaner `.has()`, `.get()`, `.set()` methods."
    },
    {
      "lines": "17-20",
      "section": "Wrapper Function and Key Generation",
      "explanation": "We return a **regular function** (not arrow) to preserve `this` binding. The rest parameter `...args` captures all arguments as an array. `JSON.stringify(args)` converts `[1, 2]` to the string `'[1,2]'`\u2014this is our cache key. Critically, `JSON.stringify([1])` \u2192 `'[1]'` while `JSON.stringify(['1'])` \u2192 `'[\"1\"]'`, so types are preserved."
    },
    {
      "lines": "21-24",
      "section": "Cache Lookup",
      "explanation": "`cache.has(key)` checks in O(1) if we've seen these exact arguments before. If yes, we immediately return the cached result\u2014no computation needed. This is where the performance benefit comes from."
    },
    {
      "lines": "25-28",
      "section": "Cache Miss: Compute and Store",
      "explanation": "On cache miss, we call the original function. We use `fn.apply(this, args)` instead of `fn(...args)` to preserve the `this` context. This matters when memoizing object methods. After computing, we store the result in cache for future calls."
    },
    {
      "lines": "29-31",
      "section": "Return Result",
      "explanation": "Finally, we return the computed result. The next call with the same arguments will hit the cache and skip this computation entirely."
    }
  ],
  "debugging_strategy": {
    "how_to_test_incrementally": "1. First test with simple add(1,2) - verify basic caching works. 2. Test same call twice - verify cache hit (add console.log to confirm). 3. Test type differentiation: memoized(1) vs memoized('1'). 4. Test edge cases: empty args, null, undefined. 5. Test `this` binding with a method.",
    "what_to_print_or_assert": [
      "console.log('Key:', key) - See what keys are generated",
      "console.log('Cache hit!') inside the if block",
      "console.log('Cache miss, computing...') before fn.apply",
      "console.log('Cache state:', [...cache.entries()]) after each call"
    ],
    "common_failure_modes": [
      "Type collision: using `args.toString()` instead of `JSON.stringify`",
      "Lost `this`: using arrow function for wrapper or `fn(...args)` instead of `fn.apply(this, args)`",
      "Returning undefined: forgetting to return the result",
      "Cache not persisting: declaring cache inside the returned function instead of closure scope"
    ],
    "how_to_fix_fast": "Add console.log for the generated key and check if different argument types produce different keys. If `memoized(1)` and `memoized('1')` produce the same key, your serialization is broken. If cache hits aren't happening, check that cache is in closure scope, not inside the returned function."
  },
  "complexity_analysis": {
    "time": {
      "key_generation": {
        "complexity": "O(k)",
        "explanation": "JSON.stringify is O(k) where k is total size of arguments"
      },
      "cache_lookup": {
        "complexity": "O(1)",
        "explanation": "Map.has() is O(1) amortized"
      },
      "cache_store": {
        "complexity": "O(1)",
        "explanation": "Map.set() is O(1) amortized"
      },
      "cache_hit": {
        "complexity": "O(k)",
        "explanation": "O(k) for key generation + O(1) for lookup"
      },
      "cache_miss": {
        "complexity": "O(k + fn)",
        "explanation": "O(k) for key + O(fn) for original function execution"
      },
      "overall": "First call: O(k + fn). Subsequent identical calls: O(k). The fn execution is amortized across all calls with same args."
    },
    "space": {
      "complexity": "O(n \u00d7 k)",
      "breakdown": "- Cache Map: O(n) entries where n = unique argument combinations\n- Each key: O(k) for serialized string\n- Each value: O(v) for stored result\n- Total: O(n \u00d7 (k + v))",
      "note": "Cache grows unbounded. In production, add LRU eviction for memory management."
    },
    "can_we_do_better": "Time is optimal\u2014we need O(k) to read the arguments. Space could be bounded with LRU cache. Key generation could use WeakMap for object arguments to avoid serialization, but that's a different tradeoff (reference equality vs structural equality)."
  },
  "dry_run": {
    "example": "const add = (a, b) => a + b; const memoAdd = memoize(add); memoAdd(1, 2); memoAdd(1, 2); memoAdd('1', '2');",
    "trace_table": "| Step | Call | args | Key (JSON.stringify) | Cache Before | Action | Result | Cache After |\n|------|------|------|---------------------|--------------|--------|--------|-------------|\n| 1 | memoAdd(1, 2) | [1, 2] | `'[1,2]'` | `{}` | MISS \u2192 compute 1+2 | 3 | `{'[1,2]': 3}` |\n| 2 | memoAdd(1, 2) | [1, 2] | `'[1,2]'` | `{'[1,2]': 3}` | HIT \u2192 return | 3 | `{'[1,2]': 3}` |\n| 3 | memoAdd('1', '2') | ['1', '2'] | `'[\"1\",\"2\"]'` | `{'[1,2]': 3}` | MISS \u2192 compute '1'+'2' | '12' | `{'[1,2]': 3, '[\"1\",\"2\"]': '12'}` |",
    "final_answer": "Call 1: 3 (computed), Call 2: 3 (cached), Call 3: '12' (computed, different key due to string type)"
  },
  "test_cases": [
    {
      "name": "Basic memoization with numbers",
      "category": "Happy Path",
      "input": "memoize(add); add(1, 2); add(1, 2)",
      "expected": "3, 3 (second call from cache)",
      "explanation": "First call computes and caches, second call returns cached result"
    },
    {
      "name": "Type differentiation: number vs string",
      "category": "Critical Edge Case",
      "input": "memoize(identity); identity(1); identity('1')",
      "expected": "1 (number), '1' (string) - DIFFERENT cache entries",
      "explanation": "JSON.stringify produces '[1]' vs '[\"1\"]' - must not collide!"
    },
    {
      "name": "Empty arguments",
      "category": "Edge Case",
      "input": "memoize(() => Math.random()); fn(); fn()",
      "expected": "Same random number both times",
      "explanation": "Empty args serializes to '[]', which is a valid cache key"
    },
    {
      "name": "null and undefined handling",
      "category": "Edge Case",
      "input": "memoize(x => x); fn(null); fn(undefined)",
      "expected": "null, undefined (but may both serialize to '[null]')",
      "explanation": "JSON.stringify limitation: undefined becomes null in arrays. Mention to interviewer!"
    },
    {
      "name": "Multiple arguments with mixed types",
      "category": "Complex",
      "input": "fn(1, 'hello', true, null); fn(1, 'hello', true, null)",
      "expected": "Second call is cache hit",
      "explanation": "Key: '[1,\"hello\",true,null]' - all types preserved"
    },
    {
      "name": "Preserves this context",
      "category": "Context",
      "input": "obj.method = memoize(function() { return this.value; }); obj.value = 42; obj.method()",
      "expected": "42",
      "explanation": "Using fn.apply(this, args) preserves the calling context"
    }
  ],
  "common_mistakes": [
    {
      "mistake": "Using args.toString() or args.join() for key",
      "why_wrong": "`[1, 2].toString()` is `'1,2'` and `['1', '2'].toString()` is also `'1,2'` - TYPE COLLISION!",
      "correct_approach": "Use JSON.stringify(args) which preserves types",
      "code_wrong": "const key = args.toString(); // or args.join(',')",
      "code_correct": "const key = JSON.stringify(args);"
    },
    {
      "mistake": "Using arrow function for the wrapper",
      "why_wrong": "Arrow functions don't have their own `this`, so `this` will be from the enclosing scope, breaking method memoization",
      "correct_approach": "Use regular function expression",
      "code_wrong": "return (...args) => { fn.apply(this, args); }  // 'this' is wrong!",
      "code_correct": "return function(...args) { fn.apply(this, args); }"
    },
    {
      "mistake": "Using fn(...args) instead of fn.apply(this, args)",
      "why_wrong": "Loses the `this` context from the caller",
      "correct_approach": "Use apply or call to forward `this`",
      "code_wrong": "const result = fn(...args);  // 'this' is lost",
      "code_correct": "const result = fn.apply(this, args);  // 'this' preserved"
    },
    {
      "mistake": "Declaring cache inside the returned function",
      "why_wrong": "Cache gets reset on every call, defeating the purpose",
      "correct_approach": "Declare cache in the closure scope of memoize",
      "code_wrong": "return function(...args) {\n  const cache = new Map();  // Reset every call!\n  ...\n}",
      "code_correct": "const cache = new Map();  // In closure scope\nreturn function(...args) { ... }"
    },
    {
      "mistake": "Not returning the result",
      "why_wrong": "Function returns undefined instead of the cached/computed value",
      "correct_approach": "Always return the result",
      "code_wrong": "if (cache.has(key)) {\n  cache.get(key);  // Missing return!\n}",
      "code_correct": "if (cache.has(key)) {\n  return cache.get(key);\n}"
    }
  ],
  "interview_tips": {
    "opening": "Thank you for this problem. Memoization is a powerful optimization pattern\u2014I've used it extensively with React's useMemo and in Redux selectors. Before I code, let me clarify a few things...",
    "clarifying_questions_to_ask": [
      "What types of arguments should I handle? Mostly primitives, or also objects?",
      "Should I worry about cache size limits or eviction?",
      "Is this for synchronous functions only, or should I handle async/Promises?",
      "Should identical objects with different references be treated as same key?",
      "Do I need to handle functions that use `this`?"
    ],
    "what_to_mention_proactively": [
      "I'll use JSON.stringify for type-safe key generation\u2014it differentiates 1 from '1'",
      "I'll use Map for the cache instead of Object for cleaner API",
      "I'll preserve `this` context using fn.apply for method memoization",
      "I know JSON.stringify has limitations with undefined and functions\u2014happy to discuss"
    ],
    "communication_during_coding": [
      "Creating the cache in closure scope so it persists across calls...",
      "Using rest parameters to capture all arguments as an array...",
      "JSON.stringify gives us type-safe keys\u2014numbers and strings won't collide...",
      "Using apply instead of spread to preserve the calling context..."
    ],
    "if_stuck": [
      "Think about what data structure can store key-value pairs with O(1) lookup",
      "Consider how to create a unique key from multiple arguments of different types",
      "Remember closures\u2014how can I make state persist across function calls?"
    ],
    "time_management": "0-5min: Clarify requirements and edge cases | 5-8min: Explain approach and get buy-in | 8-20min: Write the code | 20-25min: Test with examples | 25-30min: Discuss edge cases and extensions"
  },
  "pattern_recognition": {
    "pattern_name": "Closure-based Caching / Higher-Order Functions",
    "indicators": [
      "Need to wrap a function with additional behavior",
      "Need to maintain state across multiple function calls",
      "Need to avoid recomputation of expensive operations",
      "Decorator pattern in functional programming"
    ],
    "similar_problems": [
      "LC 2623 - Memoize: Exact same problem",
      "LC 2630 - Memoize II: Handles object references properly",
      "LC 2629 - Function Composition: Similar higher-order function pattern",
      "LC 2631 - Group By: Closure for state management",
      "Debounce/Throttle: Same closure pattern with timing"
    ],
    "template": "```javascript\nfunction wrapper(fn) {\n  // State in closure scope\n  const state = ...;\n  \n  // Return wrapped function\n  return function(...args) {\n    // Access/modify state\n    // Call original fn as needed\n    return fn.apply(this, args);\n  };\n}\n```"
  },
  "follow_up_preparation": {
    "part_2_hint": "Part 2 adds async support. Key insight: for async functions, you need to cache the Promise itself, not the resolved value. This prevents multiple in-flight requests for the same arguments. Also need to handle Promise rejection\u2014should failed Promises be cached?",
    "part_3_hint": "Function.prototype.bind polyfill. Need to return a new function with preset `this` and partial arguments. Handle both regular calls and `new` (constructor calls). Use Function.prototype.apply internally.",
    "part_4_hint": "Array.isArray polyfill. The trick is using Object.prototype.toString.call(arg) === '[object Array]'. Don't use instanceof\u2014it fails across iframes.",
    "data_structure_evolution": "Part 1: Map for cache \u2192 Part 2: Same Map, but store Promises \u2192 Part 3: No cache, just closure for bound `this` and args \u2192 Part 4: No data structure, just type checking"
  },
  "communication_script": {
    "opening_verbatim": "Thank you for this problem. Memoization is a technique I use frequently\u2014React's useMemo and Redux selectors are built on the same concept. Before I start coding, I'd like to clarify a few things to make sure I understand the requirements correctly.",
    "after_clarification": "Great, so to summarize: I need to implement a memoize function that caches results based on arguments, handles different types correctly, and works with any function. My approach will be to use a closure with a Map for the cache and JSON.stringify for type-safe keys. Does that sound like a good direction?",
    "while_coding": [
      "I'm declaring the cache in the closure scope so it persists across calls...",
      "Using a regular function, not arrow, so I can preserve the 'this' context...",
      "JSON.stringify gives me type-safe keys\u2014'[1]' vs '[\"1\"]' for number vs string...",
      "Using apply to call the original function and forward 'this'..."
    ],
    "after_coding": "Let me trace through an example to verify this works correctly. If I memoize an add function and call it with (1, 2), the key will be '[1,2]'. First call is a cache miss, so we compute 3 and store it. Second call with (1, 2) hits the cache and returns 3 immediately. A call with ('1', '2') produces key '[\"1\",\"2\"]' which is different, so it's a cache miss.",
    "when_stuck_verbatim": "Let me step back and think about what I need here. The core problem is intercepting function calls and caching results. I need a way to create unique keys from arguments... JSON.stringify should work for that.",
    "after_mistake": "Actually, I see an issue\u2014I used an arrow function but that won't preserve 'this' correctly. Let me change that to a regular function. There, now fn.apply(this, args) will work properly.",
    "before_moving_on": "This handles the basic memoization case. Time complexity is O(k) for key generation plus O(1) for cache lookup. Space is O(n) for n unique argument combinations. The main limitation is JSON.stringify doesn't handle undefined or circular references perfectly, but for most use cases this works well. Ready for Part 2 when you are!"
  },
  "interviewer_perspective": {
    "what_they_evaluate": [
      "Understanding of closures and lexical scope",
      "Knowledge of JavaScript function context (this)",
      "Ability to handle serialization edge cases",
      "Code clarity and organization",
      "Testing instinct\u2014do they verify their solution?"
    ],
    "bonus_points": [
      "Mentioning JSON.stringify limitations unprompted",
      "Explaining why Map is better than Object for cache",
      "Discussing LRU cache for production use",
      "Knowing about WeakMap for object argument caching",
      "Connecting to React/Redux patterns they've used"
    ],
    "red_flags": [
      "Using args.toString() and not recognizing type collision",
      "Not understanding why 'this' preservation matters",
      "Unable to explain how closures work",
      "Writing code without explaining approach first",
      "Not testing after implementation"
    ],
    "what_differentiates_strong_candidates": "Strong candidates immediately recognize this as a closure + caching problem. They ask smart questions about edge cases (object arguments, async, cache eviction). They explain tradeoffs (JSON.stringify vs custom serializer). They write clean code on the first pass and test systematically. They connect it to real-world usage in React or other frameworks."
  },
  "time_milestones": {
    "by_5_min": "Understand the problem completely. Ask about argument types, cache limits, async support. Confirm key constraint: type differentiation (1 vs '1').",
    "by_8_min": "Explain approach: closure for state, Map for cache, JSON.stringify for keys, apply for context. Get interviewer buy-in.",
    "by_15_min": "Core implementation complete. Working memoize function that handles basic cases.",
    "by_20_min": "Test with examples. Trace through memoizedAdd(1,2) twice, verify cache hit. Test type differentiation.",
    "by_25_min": "Discuss edge cases, mention limitations, talk about production considerations (LRU, WeakMap).",
    "by_30_min": "Part 1 complete. Ready for follow-up parts.",
    "warning_signs": "If still clarifying at 8 min, you're behind. If still coding at 25 min, you won't have time for follow-ups. Simplify and move faster."
  },
  "recovery_strategies": {
    "when_you_make_a_bug": "Say: 'Actually, I see an issue here\u2014I used an arrow function but I need a regular function to preserve this. Let me fix that.' Make the fix, briefly explain why, and continue. Don't dwell on it.",
    "when_you_dont_know_syntax": "Say: 'I don't remember the exact method name for checking if a Map has a key\u2014is it .has() or .contains()? Let me use .has() and we can verify.' Most interviewers won't penalize minor syntax issues.",
    "when_approach_is_wrong": "Say: 'Wait, I realize args.toString() will cause type collisions\u2014'1,2' is same for [1,2] and ['1','2']. I need to use JSON.stringify instead.' Pivot quickly and cleanly.",
    "when_completely_stuck": "Say: 'I'm stuck on generating unique keys from arguments. Could you give me a hint about what approach to use for serialization?' Asking for help shows self-awareness.",
    "when_running_out_of_time": "Say: 'I'm running low on time. Let me finish the core logic and explain what I'd add for edge cases. The key insight is using JSON.stringify for type-safe keys and fn.apply for context preservation.'"
  },
  "ai_copilot_tips": {
    "when_using_cursor_or_copilot": "Rippling allows AI tools. Use them wisely\u2014they can speed you up or expose that you don't understand the code.",
    "what_to_do": [
      "Use AI for boilerplate like 'function memoize(fn) { const cache = new Map();'",
      "Use for syntax you forgot: 'How do I check if Map has key?'",
      "Let it autocomplete obvious patterns once you've set direction",
      "Use for generating test cases after you've written the solution"
    ],
    "what_not_to_do": [
      "Don't paste the entire problem and accept the first solution",
      "Don't use AI suggestions you can't explain",
      "Don't let AI write the key insight (JSON.stringify for types)\u2014YOU should know that"
    ],
    "how_to_demonstrate_understanding": "If AI suggests JSON.stringify, explain WHY: 'JSON.stringify preserves types\u2014number 1 becomes '[1]' while string '1' becomes '[\"1\"]', so they don't collide.' The interviewer is evaluating YOUR knowledge.",
    "expectation_adjustment": "With AI tools, you're expected to complete more parts faster. If you're slower with AI than without, don't use it."
  },
  "signal_points": {
    "wow_factors": [
      "Immediately identifying JSON.stringify for type-safe keys",
      "Explaining why Map > Object without being asked",
      "Mentioning WeakMap for object argument caching",
      "Connecting to React useMemo / Redux reselect",
      "Proactively discussing what you'd add for production (LRU, TTL)"
    ],
    "subtle_signals_of_experience": [
      "Using 'cache.has(key)' instead of 'key in cache' or 'cache[key]'",
      "Knowing to use fn.apply(this, args) for context",
      "Mentioning that arrow functions don't have own 'this'",
      "Asking about cache eviction strategy",
      "Testing edge cases like empty args, null, undefined"
    ]
  },
  "red_flags_to_avoid": {
    "behavioral": [
      "Coding silently for more than 30 seconds",
      "Getting defensive when interviewer points out type collision issue",
      "Not asking any clarifying questions",
      "Rushing to code before explaining approach"
    ],
    "technical": [
      "Using args.toString() or args.join() for key generation",
      "Using arrow function for the wrapper",
      "Declaring cache inside the returned function",
      "Forgetting to return the cached/computed result"
    ],
    "communication": [
      "Using 'closure' without explaining what you mean",
      "Not verifying the solution with an example",
      "Unable to explain why types must be differentiated",
      "Saying 'I think this works' without testing"
    ]
  },
  "final_checklist": {
    "before_saying_done": [
      "Does cache persist across calls? (In closure scope, not inside returned function)",
      "Do different types produce different keys? (JSON.stringify, not toString)",
      "Is 'this' context preserved? (fn.apply, regular function not arrow)",
      "Do I return the result in all code paths?",
      "Did I trace through at least one example?",
      "Did I mention time/space complexity?"
    ],
    "quick_code_review": [
      "Map for cache, not Object (cleaner API)",
      "Regular function, not arrow (preserves this)",
      "JSON.stringify for key (type-safe)",
      "fn.apply(this, args) (forwards context)",
      "Return statement in both cache hit and miss paths"
    ]
  },
  "production_considerations": {
    "what_id_add_in_production": [
      "LRU cache with max size to prevent memory leaks",
      "TTL (time-to-live) for cache entries",
      "Custom key generator option for complex objects",
      "Cache statistics (hit rate, size)",
      "Option to manually invalidate cache",
      "WeakMap for object arguments if reference equality is desired"
    ],
    "why_not_in_interview": "Interview code should be focused and minimal. Adding LRU logic would take another 10 minutes and distract from the core problem.",
    "how_to_mention": "Say: 'In production, I'd also add LRU eviction for memory management and maybe a TTL for freshness. But for this interview, I'll focus on the core memoization logic.'"
  },
  "generated_at": "2026-01-19T04:03:13.543254",
  "_meta": {
    "problem_id": "javascript_polyfills_and_memoization",
    "part_number": null,
    "model": "claude-opus-4-5-20251101"
  }
}