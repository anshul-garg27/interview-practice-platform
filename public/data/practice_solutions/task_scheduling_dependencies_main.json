{
  "problem_title": "Task Scheduling with Dependencies",
  "difficulty": "medium",
  "category": "DSA/Graphs",
  "estimated_time": "45-60 minutes",
  "problem_analysis": {
    "first_impressions": "This is a **classic graph problem** combining two key concepts: (1) **Topological Sort** to find valid execution order, and (2) **Critical Path Analysis** to find minimum completion time with parallel execution. The dependency relationships form a **Directed Acyclic Graph (DAG)** - if there's a cycle, no valid schedule exists.",
    "pattern_recognition": "**Topological Sort + Dynamic Programming**. The topological sort gives us processing order, and we use DP to track completion times. This pattern appears in: Course Schedule (LC 207/210), Build Order, Parallel Courses (LC 1136), Alien Dictionary (LC 269).",
    "key_constraints": [
      "**Task IDs not consecutive** (1, 5, 100) - must use HashMap, not array indexing",
      "**Up to 10^4 tasks, 10^5 dependencies** - O(V+E) solution required, O(V*E) will TLE",
      "**Unlimited parallel workers** - critical path determines total time, not sequential sum",
      "**Cycle detection required** - return [-1, []] if impossible"
    ],
    "clarifying_questions": [
      "**Are task IDs guaranteed to be unique?** - Yes, important for HashMap keys",
      "**Can dependencies reference non-existent tasks?** - Assume no, but worth validating in production",
      "**What if taskList is empty?** - Return [0, []] (no work = zero time)",
      "**Is self-dependency (A depends on A) considered a cycle?** - Yes, treat as invalid",
      "**Multiple valid orders - any preference?** - Any valid topological order is acceptable",
      "**Can a task appear multiple times in dependencyList?** - Possible duplicate edges, should handle gracefully"
    ],
    "edge_cases_to_consider": [
      "Empty task list \u2192 [0, []]",
      "Single task with no dependencies \u2192 [duration, [task_id]]",
      "All tasks independent \u2192 max(durations), any order valid",
      "Linear chain (no parallelism) \u2192 sum of all durations",
      "Self-dependency cycle \u2192 [-1, []]",
      "Diamond pattern (multiple paths merge) \u2192 critical path analysis",
      "Disconnected components \u2192 can all run in parallel"
    ]
  },
  "requirements_coverage": {
    "checklist": [
      {
        "requirement": "Return valid topological order",
        "how_met": "Kahn's Algorithm (BFS-based topo sort) builds order list as we process",
        "gotchas": [
          "Must initialize in-degree for ALL tasks, not just those with dependencies"
        ]
      },
      {
        "requirement": "Calculate minimum total time with unlimited workers",
        "how_met": "Track completion_time[task] = max(completion_time[prereqs]) + duration[task], then take max",
        "gotchas": [
          "NOT sum of all durations - parallel execution reduces total time"
        ]
      },
      {
        "requirement": "Detect cycles and return [-1, []]",
        "how_met": "If len(order) != len(tasks) after Kahn's algorithm, cycle exists",
        "gotchas": [
          "Don't just check if queue empties - need to verify ALL tasks processed"
        ]
      }
    ],
    "complexity_targets": [
      {
        "operation": "schedule_tasks",
        "target": "O(V+E)",
        "achieved": "O(V+E)",
        "why": "Each task and dependency processed exactly once"
      }
    ],
    "non_goals": [
      "Handling limited workers (that's Part 2)",
      "Returning the actual critical path (that's Part 3)",
      "Dynamic task addition (that's Part 4)"
    ]
  },
  "assumptions": [
    "Task IDs in dependencyList all exist in taskList",
    "No duplicate tasks in taskList",
    "Durations are positive integers",
    "Dependencies are well-formed [from, to] pairs"
  ],
  "tradeoffs": [
    {
      "decision": "BFS (Kahn's) vs DFS for topological sort",
      "chosen": "BFS (Kahn's Algorithm)",
      "why": "Natural integration with completion time calculation - process in order of availability. Easier cycle detection (count processed nodes). More intuitive for interview.",
      "alternative": "DFS with finish times",
      "when_to_switch": "DFS preferred when you need post-order traversal or recursive structure fits better"
    },
    {
      "decision": "Track completion times during vs after topo sort",
      "chosen": "During topological sort",
      "why": "Single pass through graph, avoids second iteration. Completion time only valid when all prereqs processed (guaranteed by topo order).",
      "alternative": "Separate pass after getting order",
      "when_to_switch": "If requirements change and you need order without times, separate is cleaner"
    }
  ],
  "extensibility_and_followups": {
    "design_principles": [
      "Single pass algorithm - topo sort and critical path in one traversal",
      "Use HashMaps for sparse/non-consecutive task IDs",
      "Track both forward graph (task\u2192dependents) and reverse (task\u2192prerequisites)"
    ],
    "why_this_design_scales": "The reverse_graph enables O(1) lookup of prerequisites when calculating completion times. The same graph structure works for Part 2 (limited workers - use priority queue by completion time) and Part 3 (finding critical path - backtrack from max completion node).",
    "expected_followup_hooks": [
      "**Part 2**: Replace simple queue with PriorityQueue sorted by completion_time to simulate limited workers",
      "**Part 3**: Track 'critical predecessor' for each task to reconstruct path",
      "**Part 4**: Incremental topo sort using dynamic graph updates"
    ],
    "invariants": [
      "completion_time[task] \u2265 duration[task] always",
      "len(order) == len(tasks) iff no cycle",
      "completion_time computed in topological order guarantees correctness"
    ]
  },
  "visual_explanation": {
    "problem_visualization": "```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    TASK SCHEDULING OVERVIEW                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                \u2502\n\u2502  INPUT:                          OUTPUT:                       \u2502\n\u2502  tasks = [[1,3],[2,2],           order = [1,2,3,4]            \u2502\n\u2502           [3,5],[4,3]]           total_time = 11               \u2502\n\u2502  deps = [[1,2],[1,3],                                          \u2502\n\u2502          [2,4],[3,4]]                                          \u2502\n\u2502                                                                \u2502\n\u2502  DEPENDENCY GRAPH:               PARALLEL TIMELINE:            \u2502\n\u2502       \u250c\u2500\u2500\u25001(3)\u2500\u2500\u2500\u2510               t=0   t=3   t=5   t=8  t=11  \u2502\n\u2502       \u2502          \u2502                \u2502     \u2502     \u2502     \u2502     \u2502    \u2502\n\u2502       \u25bc          \u25bc               \u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550   \u2502\n\u2502     2(2)       3(5)               \u2502\u2593\u2593\u25931\u2593\u2502                      \u2502\n\u2502       \u2502          \u2502                \u2502     \u2502\u2593\u25932\u2593\u2502                 \u2502\n\u2502       \u25bc          \u25bc                \u2502     \u2502\u2593\u2593\u2593\u2593\u2593\u25933\u2593\u2593\u2593\u2502          \u2502\n\u2502       \u2514\u2500\u2500\u25004(3)\u2500\u2500\u2500\u2518                \u2502                 \u2502\u2593\u2593\u25934\u2593\u2502    \u2502\n\u2502                                                                \u2502\n\u2502  Critical Path: 1 \u2192 3 \u2192 4 = 3 + 5 + 3 = 11                    \u2502\n\u2502  (Path 1\u21922\u21924 = 3+2+3 = 8, shorter, not critical)              \u2502\n\u2502                                                                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```",
    "data_structure_state": "```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    DATA STRUCTURES STATE                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                 \u2502\n\u2502  duration = {1: 3, 2: 2, 3: 5, 4: 3}                           \u2502\n\u2502                                                                 \u2502\n\u2502  graph (forward):              reverse_graph (prerequisites):   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n\u2502  \u2502 1   \u2502 [2, 3]  \u2502             \u2502 1   \u2502 []      \u2502               \u2502\n\u2502  \u2502 2   \u2502 [4]     \u2502             \u2502 2   \u2502 [1]     \u2502               \u2502\n\u2502  \u2502 3   \u2502 [4]     \u2502             \u2502 3   \u2502 [1]     \u2502               \u2502\n\u2502  \u2502 4   \u2502 []      \u2502             \u2502 4   \u2502 [2, 3]  \u2502               \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n\u2502                                                                 \u2502\n\u2502  in_degree:  {1: 0, 2: 1, 3: 1, 4: 2}                          \u2502\n\u2502               \u2191 starts in queue                                 \u2502\n\u2502                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```",
    "algorithm_flow": [
      {
        "step": 1,
        "description": "Initialize: Find all tasks with in_degree=0 (no prerequisites)",
        "visualization": "```\nqueue = [1]  (only task 1 has no prerequisites)\nin_degree = {1:0, 2:1, 3:1, 4:2}\ncompletion_time = {}\norder = []\n```",
        "key_point": "Tasks with in_degree=0 can start immediately at t=0"
      },
      {
        "step": 2,
        "description": "Process task 1: Calculate completion time, update dependents",
        "visualization": "```\nProcess task 1:\n  prereqs of 1 = [] \u2192 max_prereq_time = 0\n  completion_time[1] = 0 + 3 = 3\n  \nDecrement in_degree of dependents [2, 3]:\n  in_degree[2] = 1-1 = 0 \u2192 add to queue\n  in_degree[3] = 1-1 = 0 \u2192 add to queue\n\nqueue = [2, 3], order = [1]\n```",
        "key_point": "When in_degree becomes 0, task is ready to execute"
      },
      {
        "step": 3,
        "description": "Process task 2: Completion time = prereq time + duration",
        "visualization": "```\nProcess task 2:\n  prereqs of 2 = [1] \u2192 max_prereq_time = 3\n  completion_time[2] = 3 + 2 = 5\n  \nDecrement in_degree of dependents [4]:\n  in_degree[4] = 2-1 = 1 \u2192 NOT ready yet\n\nqueue = [3], order = [1, 2]\n```",
        "key_point": "Task 4 still waiting on task 3"
      },
      {
        "step": 4,
        "description": "Process task 3: This is on the critical path!",
        "visualization": "```\nProcess task 3:\n  prereqs of 3 = [1] \u2192 max_prereq_time = 3\n  completion_time[3] = 3 + 5 = 8   \u2190 LONGER than path through 2!\n  \nDecrement in_degree of dependents [4]:\n  in_degree[4] = 1-1 = 0 \u2192 add to queue\n\nqueue = [4], order = [1, 2, 3]\n```",
        "key_point": "Task 3 finishes at t=8, task 2 finished at t=5. Task 4 waits for BOTH."
      },
      {
        "step": 5,
        "description": "Process task 4: Must wait for ALL prerequisites",
        "visualization": "```\nProcess task 4:\n  prereqs of 4 = [2, 3]\n  max_prereq_time = max(5, 8) = 8  \u2190 Takes the LATER completion\n  completion_time[4] = 8 + 3 = 11\n\nqueue = [], order = [1, 2, 3, 4]\n```",
        "key_point": "Task 4 starts at t=8 (waits for slower prereq), ends at t=11"
      },
      {
        "step": 6,
        "description": "Finalize: Check for cycles, return result",
        "visualization": "```\nlen(order) = 4 = len(tasks) \u2192 No cycle!\ntotal_time = max(completion_time.values())\n          = max(3, 5, 8, 11) = 11\n\nReturn: (11, [1, 2, 3, 4])\n```",
        "key_point": "If len(order) < len(tasks), cycle exists"
      }
    ],
    "dry_run_table": "| Step | Queue | Process | Prereq Max | Completion | in_degree after | Order |\n|------|-------|---------|------------|------------|-----------------|-------|\n| Init | [1] | - | - | {} | {1:0,2:1,3:1,4:2} | [] |\n| 1 | [2,3] | 1 | 0 | {1:3} | {2:0,3:0,4:2} | [1] |\n| 2 | [3] | 2 | 3 | {1:3,2:5} | {3:0,4:1} | [1,2] |\n| 3 | [4] | 3 | 3 | {1:3,2:5,3:8} | {4:0} | [1,2,3] |\n| 4 | [] | 4 | max(5,8)=8 | {1:3,2:5,3:8,4:11} | {} | [1,2,3,4] |\n| Done | - | - | - | **max=11** | - | **[1,2,3,4]** |"
  },
  "thinking_process": {
    "step_by_step": [
      "When I see **'tasks with dependencies'**, I immediately think **Directed Graph** where edges represent 'must complete before' relationships",
      "When I see **'valid execution order'**, I think **Topological Sort** - the classic algorithm for ordering nodes respecting directed edges",
      "When I see **'minimum time with unlimited workers'**, I realize this is NOT just sum of durations - parallel execution means we need **Critical Path Analysis**",
      "The key insight: **completion_time[task] = max(completion_time[all prereqs]) + duration[task]**. A task can't start until ALL its prerequisites finish",
      "I should use **Kahn's Algorithm (BFS)** because: (1) naturally gives topological order, (2) easy cycle detection, (3) can compute completion times in same pass",
      "For cycle detection: if we process fewer tasks than exist, remaining tasks are in a cycle (can't get in_degree to 0)"
    ],
    "key_insight": "**The minimum total time is the Critical Path** - the longest chain of dependent tasks. Parallel execution doesn't help the critical path; it just ensures non-critical paths don't slow us down. We compute this by tracking when each task can START (= max completion of prereqs) and when it ENDS (= start + duration).",
    "why_this_works": "Topological order guarantees that when we process a task, ALL its prerequisites have already been processed and have valid completion times. This means our DP recurrence `completion[t] = max(completion[prereqs]) + duration[t]` is always computed from known values. The final answer is the maximum completion time across all tasks."
  },
  "approaches": [
    {
      "name": "Brute Force: DFS from each node",
      "description": "For each task, do DFS to find the longest path ending at that task, then take maximum",
      "pseudocode": "for each task t:\n    longest_path_to[t] = DFS to find max path length\ntotal_time = max(longest_path_to)\n\nDFS(t):\n    if t has no prereqs: return duration[t]\n    return duration[t] + max(DFS(prereq) for prereq in prereqs[t])",
      "time_complexity": "O(V * (V+E)) - DFS from each node",
      "space_complexity": "O(V) for recursion stack",
      "pros": [
        "Intuitive recursive thinking",
        "Easy to understand"
      ],
      "cons": [
        "Redundant computation - same subpaths computed multiple times",
        "TLE for large graphs",
        "Cycle detection harder"
      ],
      "when_to_use": "Only for very small graphs or when explaining the concept"
    },
    {
      "name": "Optimal: Kahn's Algorithm + DP in Single Pass",
      "description": "Use BFS-based topological sort. As we process each task, compute its completion time using already-computed prerequisite times. Cycle detection is automatic.",
      "pseudocode": "1. Build graph, reverse_graph, in_degree\n2. queue = [tasks with in_degree=0]\n3. while queue not empty:\n     task = queue.pop()\n     completion[task] = max(completion[prereq] for prereq in reverse_graph[task]) + duration[task]\n     order.append(task)\n     for dependent in graph[task]:\n       in_degree[dependent] -= 1\n       if in_degree[dependent] == 0:\n         queue.append(dependent)\n4. if len(order) < len(tasks): return [-1, []]\n5. return [max(completion.values()), order]",
      "time_complexity": "O(V + E) - each node and edge processed once",
      "space_complexity": "O(V + E) for graph storage",
      "pros": [
        "Optimal time complexity",
        "Single pass",
        "Clean cycle detection",
        "Natural for interview"
      ],
      "cons": [
        "Requires understanding of topological sort"
      ],
      "key_insight": "Processing in topological order guarantees prerequisites are done first - perfect for DP!"
    }
  ],
  "optimal_solution": {
    "name": "Kahn's Algorithm with Critical Path Calculation",
    "explanation_md": "## Approach\n\nWe solve two problems simultaneously:\n1. **Topological Sort** using Kahn's Algorithm (BFS with in-degree tracking)\n2. **Critical Path** using dynamic programming on completion times\n\n### Why Kahn's Algorithm?\n\nKahn's algorithm processes nodes in **topological order** by:\n1. Starting with nodes that have no incoming edges (in-degree = 0)\n2. Processing a node, then decrementing in-degrees of its dependents\n3. Adding newly-ready nodes (in-degree becomes 0) to the queue\n\nThis is perfect for our DP: when we process a task, all its prerequisites are **already processed**, so their completion times are known.\n\n### Critical Path Calculation\n\nFor each task: `completion_time[task] = max(completion_time[prereq] for all prereqs) + duration[task]`\n\nIf no prereqs, the task starts at t=0, so `completion_time = duration`.\n\n### Cycle Detection\n\nIf there's a cycle, some tasks will **never** reach in-degree 0. After BFS completes, if we haven't processed all tasks, a cycle exists.\n\n### Time Complexity: O(V + E)\n- Build graph: O(V + E)\n- BFS: Each node dequeued once O(V), each edge checked once O(E)\n- Total: O(V + E)",
    "data_structures": [
      {
        "structure": "HashMap<task_id, duration>",
        "purpose": "O(1) lookup of task duration by ID"
      },
      {
        "structure": "HashMap<task_id, List<dependent_ids>> (graph)",
        "purpose": "Forward edges: which tasks depend on this one"
      },
      {
        "structure": "HashMap<task_id, List<prereq_ids>> (reverse_graph)",
        "purpose": "Backward edges: which tasks must complete before this one"
      },
      {
        "structure": "HashMap<task_id, int> (in_degree)",
        "purpose": "Count of unprocessed prerequisites"
      },
      {
        "structure": "HashMap<task_id, int> (completion_time)",
        "purpose": "Earliest completion time for each task"
      },
      {
        "structure": "Deque (queue)",
        "purpose": "BFS queue for tasks ready to process"
      }
    ],
    "algorithm_steps": [
      "1. **Parse input**: Build duration map from taskList",
      "2. **Build graphs**: Create forward graph (dependencies) and reverse graph (prerequisites) from dependencyList",
      "3. **Initialize in-degrees**: Count incoming edges for each task",
      "4. **Initialize queue**: Add all tasks with in_degree=0 (no prerequisites)",
      "5. **BFS loop**: For each task in queue:\n   - Calculate completion_time = max(prereq completion times) + duration\n   - Add to order list\n   - Decrement in_degree of dependents, enqueue if becomes 0",
      "6. **Check for cycle**: If len(order) != len(tasks), cycle exists \u2192 return [-1, []]",
      "7. **Return result**: [max(completion_times), order]"
    ],
    "why_decimal": "Not applicable for this problem - durations are integers"
  },
  "solution_python_lines": [
    "from collections import defaultdict, deque",
    "from typing import List, Tuple",
    "",
    "def schedule_tasks(task_list: List[List[int]], dependency_list: List[List[int]]) -> Tuple[int, List[int]]:",
    "    \"\"\"",
    "    Schedule tasks with dependencies using topological sort + critical path.",
    "    Returns (min_total_time, valid_execution_order) or (-1, []) if cycle.",
    "    \"\"\"",
    "    if not task_list:",
    "        return (0, [])",
    "    ",
    "    # Build duration map and initialize data structures",
    "    duration = {task_id: dur for task_id, dur in task_list}",
    "    graph = defaultdict(list)         # task -> [dependent tasks]",
    "    reverse_graph = defaultdict(list) # task -> [prerequisite tasks]",
    "    in_degree = {task_id: 0 for task_id in duration}",
    "    ",
    "    # Build graph from dependencies: [a, b] means a must complete before b",
    "    for task_a, task_b in dependency_list:",
    "        graph[task_a].append(task_b)",
    "        reverse_graph[task_b].append(task_a)",
    "        in_degree[task_b] += 1",
    "    ",
    "    # Kahn's algorithm: start with tasks having no prerequisites",
    "    queue = deque(task_id for task_id in duration if in_degree[task_id] == 0)",
    "    order = []",
    "    completion_time = {}",
    "    ",
    "    while queue:",
    "        task = queue.popleft()",
    "        order.append(task)",
    "        ",
    "        # Completion time = max(prereq completion times) + this task's duration",
    "        # If no prereqs, task starts at t=0",
    "        max_prereq_time = 0",
    "        for prereq in reverse_graph[task]:",
    "            max_prereq_time = max(max_prereq_time, completion_time[prereq])",
    "        completion_time[task] = max_prereq_time + duration[task]",
    "        ",
    "        # Decrement in-degree of dependent tasks",
    "        for dependent in graph[task]:",
    "            in_degree[dependent] -= 1",
    "            if in_degree[dependent] == 0:",
    "                queue.append(dependent)",
    "    ",
    "    # Cycle detection: if not all tasks processed, cycle exists",
    "    if len(order) != len(duration):",
    "        return (-1, [])",
    "    ",
    "    # Total time = maximum completion time (critical path)",
    "    total_time = max(completion_time.values())",
    "    return (total_time, order)",
    "",
    "",
    "if __name__ == '__main__':",
    "    print(\"=\" * 60)",
    "    print(\"Task Scheduling with Dependencies - Demo\")",
    "    print(\"=\" * 60)",
    "    ",
    "    # Example 1: Diamond pattern",
    "    tasks1 = [[1, 3], [2, 2], [3, 5], [4, 3]]",
    "    deps1 = [[1, 2], [1, 3], [2, 4], [3, 4]]",
    "    result1 = schedule_tasks(tasks1, deps1)",
    "    print(f\"\\nDiamond Pattern:\")",
    "    print(f\"  Tasks: {tasks1}\")",
    "    print(f\"  Dependencies: {deps1}\")",
    "    print(f\"  Result: time={result1[0]}, order={result1[1]}\")",
    "    print(f\"  Expected: time=11, critical path 1->3->4 (3+5+3)\")",
    "    ",
    "    # Example 2: Independent tasks (all parallel)",
    "    tasks2 = [[1, 5], [2, 3], [3, 4]]",
    "    deps2 = []",
    "    result2 = schedule_tasks(tasks2, deps2)",
    "    print(f\"\\nIndependent Tasks:\")",
    "    print(f\"  Tasks: {tasks2}\")",
    "    print(f\"  Result: time={result2[0]}, order={result2[1]}\")",
    "    print(f\"  Expected: time=5 (max duration, all parallel)\")",
    "    ",
    "    # Example 3: Linear chain (no parallelism)",
    "    tasks3 = [[1, 2], [2, 3], [3, 1]]",
    "    deps3 = [[1, 2], [2, 3]]",
    "    result3 = schedule_tasks(tasks3, deps3)",
    "    print(f\"\\nLinear Chain:\")",
    "    print(f\"  Tasks: {tasks3}\")",
    "    print(f\"  Dependencies: {deps3}\")",
    "    print(f\"  Result: time={result3[0]}, order={result3[1]}\")",
    "    print(f\"  Expected: time=6 (2+3+1, sequential)\")",
    "    ",
    "    # Example 4: Cycle detection",
    "    tasks4 = [[1, 2], [2, 3], [3, 1]]",
    "    deps4 = [[1, 2], [2, 3], [3, 1]]  # Cycle: 1->2->3->1",
    "    result4 = schedule_tasks(tasks4, deps4)",
    "    print(f\"\\nCycle Detection:\")",
    "    print(f\"  Tasks: {tasks4}\")",
    "    print(f\"  Dependencies: {deps4}\")",
    "    print(f\"  Result: {result4}\")",
    "    print(f\"  Expected: (-1, []) - cycle detected!\")",
    "    ",
    "    print(\"\\n\" + \"=\" * 60)",
    "    print(\"All demos complete!\")"
  ],
  "solution_java_lines": [
    "import java.util.*;",
    "",
    "public class TaskScheduler {",
    "    ",
    "    /**",
    "     * Schedule tasks with dependencies using topological sort + critical path.",
    "     * @return [min_total_time, ...valid_execution_order] or [-1] if cycle",
    "     */",
    "    public int[] scheduleTasks(int[][] taskList, int[][] dependencyList) {",
    "        if (taskList == null || taskList.length == 0) {",
    "            return new int[]{0};",
    "        }",
    "        ",
    "        // Build duration map and initialize data structures",
    "        Map<Integer, Integer> duration = new HashMap<>();",
    "        Map<Integer, List<Integer>> graph = new HashMap<>();",
    "        Map<Integer, List<Integer>> reverseGraph = new HashMap<>();",
    "        Map<Integer, Integer> inDegree = new HashMap<>();",
    "        ",
    "        for (int[] task : taskList) {",
    "            int taskId = task[0], dur = task[1];",
    "            duration.put(taskId, dur);",
    "            graph.put(taskId, new ArrayList<>());",
    "            reverseGraph.put(taskId, new ArrayList<>());",
    "            inDegree.put(taskId, 0);",
    "        }",
    "        ",
    "        // Build graph from dependencies: [a, b] means a before b",
    "        for (int[] dep : dependencyList) {",
    "            int taskA = dep[0], taskB = dep[1];",
    "            graph.get(taskA).add(taskB);",
    "            reverseGraph.get(taskB).add(taskA);",
    "            inDegree.put(taskB, inDegree.get(taskB) + 1);",
    "        }",
    "        ",
    "        // Kahn's algorithm: start with tasks having no prerequisites",
    "        Queue<Integer> queue = new LinkedList<>();",
    "        for (int taskId : duration.keySet()) {",
    "            if (inDegree.get(taskId) == 0) {",
    "                queue.offer(taskId);",
    "            }",
    "        }",
    "        ",
    "        List<Integer> order = new ArrayList<>();",
    "        Map<Integer, Integer> completionTime = new HashMap<>();",
    "        ",
    "        while (!queue.isEmpty()) {",
    "            int task = queue.poll();",
    "            order.add(task);",
    "            ",
    "            // Completion = max(prereq times) + duration",
    "            int maxPrereqTime = 0;",
    "            for (int prereq : reverseGraph.get(task)) {",
    "                maxPrereqTime = Math.max(maxPrereqTime, completionTime.get(prereq));",
    "            }",
    "            completionTime.put(task, maxPrereqTime + duration.get(task));",
    "            ",
    "            // Decrement in-degree of dependents",
    "            for (int dependent : graph.get(task)) {",
    "                inDegree.put(dependent, inDegree.get(dependent) - 1);",
    "                if (inDegree.get(dependent) == 0) {",
    "                    queue.offer(dependent);",
    "                }",
    "            }",
    "        }",
    "        ",
    "        // Cycle detection",
    "        if (order.size() != duration.size()) {",
    "            return new int[]{-1};",
    "        }",
    "        ",
    "        // Build result: [totalTime, order...]",
    "        int totalTime = Collections.max(completionTime.values());",
    "        int[] result = new int[order.size() + 1];",
    "        result[0] = totalTime;",
    "        for (int i = 0; i < order.size(); i++) {",
    "            result[i + 1] = order.get(i);",
    "        }",
    "        return result;",
    "    }",
    "    ",
    "    public static void main(String[] args) {",
    "        TaskScheduler scheduler = new TaskScheduler();",
    "        ",
    "        // Diamond pattern",
    "        int[][] tasks1 = {{1, 3}, {2, 2}, {3, 5}, {4, 3}};",
    "        int[][] deps1 = {{1, 2}, {1, 3}, {2, 4}, {3, 4}};",
    "        int[] result1 = scheduler.scheduleTasks(tasks1, deps1);",
    "        System.out.println(\"Diamond: \" + Arrays.toString(result1));",
    "        System.out.println(\"Expected: [11, 1, 2, 3, 4] (or similar order)\");",
    "        ",
    "        // Cycle",
    "        int[][] tasks2 = {{1, 2}, {2, 3}, {3, 1}};",
    "        int[][] deps2 = {{1, 2}, {2, 3}, {3, 1}};",
    "        int[] result2 = scheduler.scheduleTasks(tasks2, deps2);",
    "        System.out.println(\"Cycle: \" + Arrays.toString(result2));",
    "        System.out.println(\"Expected: [-1]\");",
    "    }",
    "}"
  ],
  "code_walkthrough": [
    {
      "lines": "1-3",
      "section": "Imports",
      "explanation": "We use `defaultdict` for auto-initializing lists, `deque` for efficient BFS queue operations. Type hints improve readability."
    },
    {
      "lines": "5-10",
      "section": "Function signature and base case",
      "explanation": "Handle empty input immediately. Return (0, []) - no tasks means zero time."
    },
    {
      "lines": "12-16",
      "section": "Initialize data structures",
      "explanation": "**duration**: task_id \u2192 duration for O(1) lookup. **graph**: forward edges (who depends on me). **reverse_graph**: backward edges (who do I depend on). **in_degree**: how many prereqs remain. Using dict comprehension to initialize in_degree for ALL tasks is crucial."
    },
    {
      "lines": "18-22",
      "section": "Build graph from dependencies",
      "explanation": "[a, b] means 'a must complete before b'. So a\u2192b in graph (a has dependent b), b's in_degree increases. reverse_graph stores b\u2192a (b has prerequisite a) for quick prereq lookup during DP."
    },
    {
      "lines": "24-27",
      "section": "Initialize BFS queue",
      "explanation": "**Kahn's Algorithm starts here**. Any task with in_degree=0 has no prerequisites and can start immediately. These are our 'roots' for BFS."
    },
    {
      "lines": "29-42",
      "section": "Main BFS loop - the heart of the algorithm",
      "explanation": "For each task we dequeue:\n1. **Calculate completion_time**: Find max completion time among all prerequisites (they're guaranteed to be processed already due to topological order), add this task's duration.\n2. **Update dependents**: Decrement their in_degree. When in_degree hits 0, that task is ready.\n\nThis is elegant because we compute topological order AND completion times in ONE pass."
    },
    {
      "lines": "44-46",
      "section": "Cycle detection",
      "explanation": "If any task remains unprocessed, its in_degree never reached 0 \u2192 it's part of a cycle. All tasks in the cycle (and depending on the cycle) are stuck."
    },
    {
      "lines": "48-50",
      "section": "Compute and return result",
      "explanation": "**Critical path = max completion time**. The longest path through the graph determines total time. We return both the time and a valid execution order."
    },
    {
      "lines": "53-88",
      "section": "Demo / test cases",
      "explanation": "Four cases demonstrating: (1) Diamond pattern with critical path, (2) Independent tasks (max duration), (3) Linear chain (sum of durations), (4) Cycle detection."
    }
  ],
  "debugging_strategy": {
    "how_to_test_incrementally": "1. First verify graph is built correctly (print graph, reverse_graph, in_degree). 2. Verify BFS processes nodes in correct order. 3. Check completion times are calculated correctly. 4. Test cycle detection separately.",
    "what_to_print_or_assert": [
      "print(f'Graph: {dict(graph)}')",
      "print(f'in_degree: {in_degree}')",
      "print(f'Processing task {task}, completion={completion_time[task]}')",
      "assert len(order) == len(duration) or 'cycle'"
    ],
    "common_failure_modes": [
      "**Forgot to initialize in_degree for all tasks** - tasks with no deps not in map",
      "**Used array index instead of task_id** - fails for non-consecutive IDs",
      "**Summed durations instead of max** - wrong understanding of parallel execution",
      "**Didn't handle empty input** - division by zero or empty max()"
    ],
    "how_to_fix_fast": "If order is incomplete, print remaining in_degrees - non-zero ones are in/blocked by cycle. If times are wrong, trace through one task manually: what's max prereq time? Add duration."
  },
  "complexity_analysis": {
    "time": {
      "build_graph": {
        "complexity": "O(V + E)",
        "explanation": "V tasks to initialize, E dependencies to process"
      },
      "topological_sort": {
        "complexity": "O(V + E)",
        "explanation": "Each task dequeued once (V), each edge checked once when dependent's in_degree decremented (E)"
      },
      "critical_path": {
        "complexity": "O(V + E)",
        "explanation": "Integrated into BFS - checking prereq completion times uses reverse_graph edges"
      },
      "overall": "**O(V + E)** where V = number of tasks, E = number of dependencies"
    },
    "space": {
      "complexity": "**O(V + E)**",
      "breakdown": "- duration map: O(V)\n- graph (forward): O(V + E)\n- reverse_graph: O(V + E)\n- in_degree: O(V)\n- completion_time: O(V)\n- queue: O(V) worst case\n- order: O(V)",
      "note": "We could avoid reverse_graph by computing completion times differently, but it's cleaner this way"
    },
    "can_we_do_better": "No - we must examine each task and dependency at least once, so O(V+E) is optimal."
  },
  "dry_run": {
    "example": "tasks=[[1,3],[2,2],[3,5],[4,3]], deps=[[1,2],[1,3],[2,4],[3,4]]",
    "trace_table": "| Step | Action | Queue | Order | in_degree | completion_time |\n|------|--------|-------|-------|-----------|----------------|\n| Init | Build structures | - | - | {1:0,2:1,3:1,4:2} | {} |\n| Init | Find roots (in_degree=0) | [1] | [] | - | {} |\n| 1 | Process task 1 | [] | [1] | {2:0,3:0,4:2} | {1:3} |\n| 1 | Add ready tasks 2,3 | [2,3] | [1] | - | - |\n| 2 | Process task 2 (prereq 1\u21923) | [3] | [1,2] | {4:1} | {1:3,2:5} |\n| 3 | Process task 3 (prereq 1\u21923) | [] | [1,2,3] | {4:0} | {1:3,2:5,3:8} |\n| 3 | Add ready task 4 | [4] | - | - | - |\n| 4 | Process task 4 (prereqs 2\u21925,3\u21928) | [] | [1,2,3,4] | {} | {1:3,2:5,3:8,4:11} |\n| Done | len(order)=4=len(tasks) \u2713 | - | - | - | max=11 |",
    "final_answer": "(11, [1, 2, 3, 4])"
  },
  "test_cases": [
    {
      "name": "Diamond Pattern - Critical Path",
      "category": "Core Logic",
      "input": "tasks=[[1,3],[2,2],[3,5],[4,3]], deps=[[1,2],[1,3],[2,4],[3,4]]",
      "expected": "(11, [1,2,3,4] or [1,3,2,4])",
      "explanation": "Two paths: 1\u21922\u21924 (8) vs 1\u21923\u21924 (11). Critical path is longer one."
    },
    {
      "name": "All Independent Tasks",
      "category": "Edge Case",
      "input": "tasks=[[1,5],[2,3],[3,4]], deps=[]",
      "expected": "(5, any permutation)",
      "explanation": "No dependencies = all parallel. Time = max(5,3,4) = 5."
    },
    {
      "name": "Linear Chain - No Parallelism",
      "category": "Edge Case",
      "input": "tasks=[[1,2],[2,3],[3,1]], deps=[[1,2],[2,3]]",
      "expected": "(6, [1,2,3])",
      "explanation": "Strict sequence. Time = sum(2+3+1) = 6."
    },
    {
      "name": "Cycle Detection",
      "category": "Error Handling",
      "input": "tasks=[[1,2],[2,3],[3,1]], deps=[[1,2],[2,3],[3,1]]",
      "expected": "(-1, [])",
      "explanation": "Cycle 1\u21922\u21923\u21921. No valid schedule exists."
    },
    {
      "name": "Single Task",
      "category": "Base Case",
      "input": "tasks=[[42,7]], deps=[]",
      "expected": "(7, [42])",
      "explanation": "One task, no deps. Time = duration."
    },
    {
      "name": "Non-consecutive IDs",
      "category": "Gotcha",
      "input": "tasks=[[1,2],[100,3],[500,4]], deps=[[1,100],[100,500]]",
      "expected": "(9, [1,100,500])",
      "explanation": "Verifies HashMap usage, not array indexing."
    },
    {
      "name": "Self-Dependency",
      "category": "Error Handling",
      "input": "tasks=[[1,5]], deps=[[1,1]]",
      "expected": "(-1, [])",
      "explanation": "Task depends on itself = cycle of length 1."
    }
  ],
  "common_mistakes": [
    {
      "mistake": "Using array indexing instead of HashMap for task IDs",
      "why_wrong": "Task IDs can be non-consecutive (1, 5, 100). Array index would fail or waste space.",
      "correct_approach": "Always use HashMap<task_id, value> for all data structures",
      "code_wrong": "duration = [0] * (max_task_id + 1)  # May be huge or miss IDs",
      "code_correct": "duration = {task_id: dur for task_id, dur in task_list}"
    },
    {
      "mistake": "Summing all durations for total time",
      "why_wrong": "Parallel execution means independent tasks run simultaneously. Total time is critical path, not sum.",
      "correct_approach": "Track completion time per task, return max(all completion times)",
      "code_wrong": "total = sum(duration.values())  # Wrong!",
      "code_correct": "total = max(completion_time.values())  # Critical path"
    },
    {
      "mistake": "Forgetting to initialize in_degree for tasks with no prerequisites",
      "why_wrong": "If not initialized, `in_degree[task]` might not exist, or worse, might be garbage.",
      "correct_approach": "Initialize in_degree to 0 for ALL tasks before processing dependencies",
      "code_wrong": "for a, b in deps: in_degree[b] += 1  # Only tasks with deps get entries",
      "code_correct": "in_degree = {t: 0 for t in duration}  # All tasks start at 0\nfor a, b in deps: in_degree[b] += 1"
    },
    {
      "mistake": "Not detecting cycles properly",
      "why_wrong": "Just checking if queue is empty isn't enough. Must verify ALL tasks processed.",
      "correct_approach": "After BFS, check `len(order) == len(tasks)`",
      "code_wrong": "if not queue: return order  # Queue empty doesn't mean success",
      "code_correct": "if len(order) != len(duration): return (-1, [])"
    }
  ],
  "interview_tips": {
    "opening": "Thank you for this problem. I see this is a task scheduling problem with dependencies. Before I start, let me clarify a few things and share my initial approach.",
    "clarifying_questions_to_ask": [
      "Are task IDs guaranteed to be unique? (Yes - confirms HashMap approach)",
      "Can task IDs be non-consecutive like 1, 5, 100? (Yes - must use HashMap, not array)",
      "What does 'unlimited parallel workers' mean exactly? (Tasks without dep can run simultaneously)",
      "Should I return any valid topological order, or a specific one? (Any valid order is fine)",
      "What if there are duplicate dependencies? (Handle gracefully, or assume no duplicates)"
    ],
    "what_to_mention_proactively": [
      "I recognize this as a topological sort problem combined with critical path analysis",
      "I'll use Kahn's Algorithm (BFS-based) for topological sort because it naturally integrates with completion time calculation",
      "Cycle detection is automatic: if not all tasks are processed, a cycle exists",
      "The minimum time is the critical path - longest chain of dependent tasks"
    ],
    "communication_during_coding": [
      "I'm building two graphs - forward for BFS, reverse for quick prereq lookup",
      "I'm initializing in_degree for ALL tasks, not just those with dependencies",
      "Here's the key insight: in topological order, all prereqs are processed first, so I can use their completion times",
      "Cycle detection is just checking if we processed all tasks"
    ],
    "if_stuck": [
      "Step back: What's the core pattern? Topological sort + DP",
      "Ask yourself: When can a task start? When ALL its prerequisites are done",
      "Draw the dependency graph and trace through manually",
      "If unsure about completion time formula: it's max(prereq times) + duration, NOT sum"
    ],
    "time_management": "0-5min: Understand & clarify | 5-12min: Explain approach & data structures | 12-30min: Implement | 30-40min: Test & trace | 40-45min: Complexity analysis & follow-ups"
  },
  "pattern_recognition": {
    "pattern_name": "Topological Sort + Dynamic Programming (Critical Path)",
    "indicators": [
      "Tasks/courses with prerequisites",
      "Find valid ordering",
      "Dependency graph",
      "Minimum/maximum time with parallelism",
      "Detect if ordering is possible (cycle detection)"
    ],
    "similar_problems": [
      "LC 207 - Course Schedule: Just cycle detection (can finish?)",
      "LC 210 - Course Schedule II: Return the order (our sub-problem)",
      "LC 1136 - Parallel Courses: Minimum semesters = critical path depth",
      "LC 269 - Alien Dictionary: Build graph from constraints, topo sort",
      "LC 329 - Longest Increasing Path: DFS + memoization (alternative to Kahn's)"
    ],
    "template": "1. Build adjacency list\n2. Track in-degrees\n3. BFS from in-degree=0 nodes\n4. Decrement in-degrees, enqueue when 0\n5. Check processed count for cycles\n6. (If needed) Track DP values in topo order"
  },
  "follow_up_preparation": {
    "part_2_hint": "**Limited Workers**: With K workers, you can't run all ready tasks in parallel. Use a **PriorityQueue** sorted by completion time. When a worker finishes, pick the next ready task. This becomes a simulation problem.",
    "part_3_hint": "**Find Critical Path**: Track which prerequisite gave the max completion time for each task (`critical_pred[t]`). After finding the task with max completion time, backtrack through critical_pred to reconstruct the path.",
    "data_structure_evolution": "Part 1: HashMap + Deque \u2192 Part 2: Add PriorityQueue<(end_time, task)> \u2192 Part 3: Add critical_pred HashMap for path reconstruction"
  },
  "communication_script": {
    "opening_verbatim": "Thank you for this problem. I can see this is about scheduling tasks with dependencies, which is a classic topological sort problem. The twist here is calculating minimum time with parallel execution, which requires critical path analysis. Let me ask a few clarifying questions before I proceed.",
    "after_clarification": "Great, so to summarize: task IDs may be non-consecutive, unlimited workers means all independent tasks run in parallel, and I need to detect cycles. My approach will be Kahn's Algorithm for topological sort, combined with tracking completion times to find the critical path. Does that sound like the right direction?",
    "while_coding": [
      "I'm creating the forward graph for BFS traversal and reverse graph for quick prerequisite lookup...",
      "This line initializes in-degree for ALL tasks - important because tasks with no deps need to start at 0...",
      "Here's where the DP happens: completion time is max of prereq times plus this task's duration..."
    ],
    "after_coding": "Let me trace through the diamond example to verify this works. Task 1 has no prereqs, completes at t=3. Tasks 2 and 3 both start at t=3, complete at t=5 and t=8 respectively. Task 4 must wait for both, so it starts at t=8 and ends at t=11. That matches our expected output.",
    "when_stuck_verbatim": "Let me step back and think about this. The key insight for parallel execution is that a task's start time is determined by its SLOWEST prerequisite, not the sum of all prereqs...",
    "after_mistake": "Ah, I see the issue - I was incrementing in_degree before initializing it. Let me fix that by initializing all in-degrees to 0 first.",
    "before_moving_on": "This solution runs in O(V+E) time and space. It handles cycles by checking if all tasks were processed. Ready to discuss follow-ups or optimizations?"
  },
  "interviewer_perspective": {
    "what_they_evaluate": [
      "**Graph modeling**: Can you translate dependencies into a directed graph?",
      "**Algorithm knowledge**: Do you know topological sort and when to use it?",
      "**Critical thinking**: Do you understand parallel execution and critical path?",
      "**Edge case awareness**: Cycles, empty input, non-consecutive IDs",
      "**Communication**: Can you explain your approach clearly?"
    ],
    "bonus_points": [
      "Immediately recognizing the topological sort + critical path pattern",
      "Explaining WHY Kahn's is better than DFS here (integrates with DP)",
      "Proactively mentioning cycle detection",
      "Using appropriate data structures (HashMap for sparse IDs)",
      "Clean variable names: 'reverse_graph' not 'g2'"
    ],
    "red_flags": [
      "Trying to solve with brute force DFS from each node",
      "Confusing total time with sum of all durations",
      "Using arrays when task IDs can be non-consecutive",
      "Not knowing what topological sort is",
      "Silent coding without explaining"
    ],
    "what_differentiates_strong_candidates": "Strong candidates immediately recognize this as a well-known pattern, explain the connection to critical path in project management, use clear variable names, and handle edge cases naturally. They treat this as a conversation, not an exam."
  },
  "time_milestones": {
    "by_5_min": "Understand problem, recognize topological sort + critical path, ask clarifying questions",
    "by_10_min": "Explain approach, get buy-in, describe data structures (graph, reverse_graph, in_degree, completion_time)",
    "by_20_min": "Core implementation complete (graph building, BFS loop)",
    "by_30_min": "Full solution including cycle detection, basic testing",
    "by_40_min": "Dry run complete, complexity analysis discussed",
    "warning_signs": "If you're still confused about parallel execution at 10min, or still building the graph at 25min, you're behind."
  },
  "recovery_strategies": {
    "when_you_make_a_bug": "Stay calm. Say 'I see an issue here - I'm incrementing before initializing. Let me fix that.' Bugs are expected; recovery shows maturity.",
    "when_you_dont_know_syntax": "Say 'I don't remember exact syntax for deque in Python, but I need a queue with O(1) popleft. Let me write it and we can check.' This is fine.",
    "when_approach_is_wrong": "If you realize summing durations is wrong: 'Actually, I realize with parallel execution, independent tasks run simultaneously. Let me reconsider - the total time should be the critical path.'",
    "when_completely_stuck": "Ask: 'I'm stuck on how to efficiently find the minimum time. Could you give me a hint about what determines total time with parallel workers?' Asking shows self-awareness.",
    "when_running_out_of_time": "Say: 'I'm running low on time. Let me focus on the core BFS logic and explain how I'd add cycle detection and completion time tracking.'"
  },
  "ai_copilot_tips": {
    "when_using_cursor_or_copilot": "AI tools can help with boilerplate and syntax, but the algorithm design must be YOURS.",
    "what_to_do": [
      "Use AI for class/function scaffolding",
      "Use for remembering defaultdict syntax",
      "Let it autocomplete obvious parts (like dict comprehensions)",
      "Use for generating test cases"
    ],
    "what_not_to_do": [
      "Don't paste the problem and ask for solution",
      "Don't accept 'topological sort' suggestion without explaining WHY",
      "Don't let AI write the completion time logic without understanding it"
    ],
    "how_to_demonstrate_understanding": "If AI suggests Kahn's algorithm, explain: 'Yes, Kahn's because it processes in topological order, which means when I process a task, all its prerequisites already have computed completion times - perfect for DP.'",
    "expectation_adjustment": "Using AI means you should finish faster and handle more edge cases. If AI slows you down, don't use it."
  },
  "signal_points": {
    "wow_factors": [
      "Immediately drawing the dependency graph and timeline",
      "Mentioning 'this is like project management critical path analysis'",
      "Explaining why BFS is better than DFS here",
      "Noting that reverse_graph enables O(1) prereq lookup",
      "Proactively testing with non-consecutive IDs"
    ],
    "subtle_signals_of_experience": [
      "Using defaultdict without thinking about it",
      "Initializing in_degree for all tasks without being told",
      "Checking len(order) vs len(tasks) for cycle detection",
      "Clean naming: 'dependent' vs 'next' or 'child'"
    ]
  },
  "red_flags_to_avoid": {
    "behavioral": [
      "Jumping to code without explaining approach",
      "Going silent for over 30 seconds",
      "Getting defensive when pointed to issues",
      "Not testing after coding"
    ],
    "technical": [
      "Using O(V*E) algorithm when O(V+E) is needed",
      "Confusing critical path with sum of durations",
      "Array indexing with non-consecutive IDs",
      "Missing cycle detection"
    ],
    "communication": [
      "Using jargon without explanation ('I'll use Kahn's' without saying what it does)",
      "Not summarizing approach before coding",
      "Going too deep into irrelevant optimizations"
    ]
  },
  "final_checklist": {
    "before_saying_done": [
      "Did I handle cycle detection (return [-1, []])?",
      "Did I use HashMap for non-consecutive task IDs?",
      "Did I calculate critical path (max completion time), not sum?",
      "Did I trace through at least one example?",
      "Did I mention O(V+E) time and space complexity?",
      "Are my variable names clear (graph, reverse_graph, completion_time)?"
    ],
    "quick_code_review": [
      "No array indexing for task IDs",
      "in_degree initialized for ALL tasks",
      "completion_time uses max of prereqs, not sum",
      "Cycle check: len(order) != len(tasks)"
    ]
  },
  "production_considerations": {
    "what_id_add_in_production": [
      "Input validation: task IDs exist, no duplicate tasks",
      "Logging: which task is being processed, current completion times",
      "Return more info: which tasks are in the cycle, what the critical path is",
      "Handle disconnected components explicitly",
      "Thread-safety if graph is modified during execution"
    ],
    "why_not_in_interview": "Keep interview code focused on core algorithm. Mention these to show senior thinking, but don't over-engineer.",
    "how_to_mention": "Say: 'In production, I'd add input validation, logging, and probably return the actual critical path for debugging. But for now, let me focus on the core algorithm.'"
  },
  "generated_at": "2026-01-19T04:08:37.591386",
  "_meta": {
    "problem_id": "task_scheduling_dependencies",
    "part_number": null,
    "model": "claude-opus-4-5-20251101"
  }
}