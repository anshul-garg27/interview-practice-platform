{
  "problem_title": "Employee Hierarchy / Org Tree - Part 3: Generic Aggregation & Filtering",
  "part_number": 3,
  "builds_on": "Part 2",
  "difficulty": "hard",
  "problem_understanding": {
    "what_changes": "Part 3 transforms the org chart from a simple hierarchy query system into a flexible analytics engine. We add extended employee attributes (department, level, salary) and generic methods that accept functions as parameters to enable any grouping/aggregation combination without writing new methods for each use case.",
    "new_requirements": [
      "Extend Employee with department, level, and salary attributes",
      "Support grouping employees by ANY attribute using functional key extraction",
      "Support 5 aggregation types: SUM, AVG, MIN, MAX, COUNT",
      "Support filtering before grouping/aggregation",
      "Maintain O(n) time complexity for all aggregation operations"
    ],
    "new_constraints": [
      "Must accept functions/lambdas as parameters (functional programming paradigm)",
      "Must handle empty groups gracefully",
      "Must maintain backward compatibility with add_employee for basic usage"
    ],
    "key_insight": "The 'AHA!' moment is recognizing this is a classic MapReduce/stream pattern: filter \u2192 groupBy \u2192 aggregate. Instead of writing separate methods for each combination, we use higher-order functions to make one generic method handle all cases. This is exactly how SQL GROUP BY or Pandas groupby work."
  },
  "requirements_coverage": {
    "checklist": [
      {
        "requirement": "Extended Employee attributes",
        "how_met": "Add department, level, salary fields to Employee class with default values",
        "gotchas": [
          "Ensure backward compatibility - basic add_employee still works"
        ]
      },
      {
        "requirement": "Generic grouping by any key",
        "how_met": "key_fn parameter extracts grouping key from each employee",
        "gotchas": [
          "Handle null/empty keys from key_fn"
        ]
      },
      {
        "requirement": "Multiple aggregation functions",
        "how_met": "_aggregate helper with switch on agg_type string",
        "gotchas": [
          "AVG on empty list should return 0, not error"
        ]
      },
      {
        "requirement": "Filter before aggregate",
        "how_met": "filter_group_by_aggregate applies predicate before grouping",
        "gotchas": [
          "Empty result after filtering should return empty dict, not error"
        ]
      }
    ],
    "complexity_targets": [
      {
        "operation": "add_employee_extended",
        "target": "O(1)",
        "achieved": "O(1)",
        "why": "Delegates to add_employee then sets 3 fields"
      },
      {
        "operation": "group_by_aggregate",
        "target": "O(n)",
        "achieved": "O(n)",
        "why": "Single pass through all n employees, each operation O(1)"
      },
      {
        "operation": "filter_group_by_aggregate",
        "target": "O(n)",
        "achieved": "O(n)",
        "why": "Same single pass, filter check is O(1)"
      }
    ],
    "non_goals": [
      "Caching aggregation results (recalculate each time)",
      "Multi-key grouping (only single key supported)",
      "Custom aggregation functions (only 5 predefined types)",
      "Streaming/incremental updates (batch operation over all employees)"
    ]
  },
  "assumptions": [
    "Aggregation over empty groups returns 0.0 (ask interviewer for preference)",
    "Department/level/salary can have any values - no validation needed",
    "key_fn will not return null (or we treat null as valid key)",
    "value_fn returns numeric values that make sense for all aggregation types",
    "COUNT returns count as a double for consistent return type"
  ],
  "tradeoffs": [
    {
      "decision": "String-based aggType vs Enum",
      "chosen": "String",
      "why": "Simpler for interview, matches common API patterns like SQL",
      "alternative": "Enum AggregateFunction",
      "when_to_switch": "Production code - enum provides compile-time safety"
    },
    {
      "decision": "Collect then aggregate vs Single-pass accumulator",
      "chosen": "Collect then aggregate",
      "why": "Cleaner code, handles MIN/MAX/AVG uniformly, easier to debug",
      "alternative": "Running accumulators per group",
      "when_to_switch": "Memory-constrained with huge groups"
    },
    {
      "decision": "DefaultDict vs explicit check",
      "chosen": "DefaultDict/computeIfAbsent",
      "why": "Cleaner code, fewer conditionals",
      "alternative": "Manual containsKey checks",
      "when_to_switch": "Never, this is strictly better"
    }
  ],
  "extensibility_notes": {
    "what_to_keep_stable": [
      "Employee class interface (id, name, rating, manager, subordinates)",
      "All Part 1 and Part 2 method signatures",
      "TeamStats class"
    ],
    "what_to_change": [
      "Added department, level, salary to Employee",
      "Added _aggregate helper method",
      "Added three new public methods for Part 3"
    ],
    "interfaces_and_boundaries": "The functional interface pattern makes adding new aggregations trivial (just add case to _aggregate). For Part 4, if subtree aggregation is needed, we can reuse _aggregate with DFS traversal.",
    "invariants": [
      "All employees in self.employees are reachable from CEO via subordinate chains",
      "Extended attributes have sensible defaults (empty string, 0, 0.0)",
      "_aggregate always returns a float, never None"
    ]
  },
  "visual_explanation": {
    "before_after": "```\nBEFORE (Part 2):                      AFTER (Part 3):\n+------------+                        +------------------+\n| Employee   |                        | Employee         |\n+------------+                        +------------------+\n| id         |                        | id               |\n| name       |                        | name             |\n| rating     |                        | rating           |\n| manager    |                        | department  NEW  |\n| subordinates                        | level       NEW  |\n+------------+                        | salary      NEW  |\n                                      | manager          |\n                                      | subordinates     |\n                                      +------------------+\n\nNew Operations:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  group_by_aggregate(key_fn, value_fn, agg_type)        \u2502\n\u2502  filter_group_by_aggregate(filter, key, value, agg)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```",
    "algorithm_flow": "```\n                    AGGREGATION PIPELINE\n\n    employees.values()     All n employees\n           \u2502\n           \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 filter_fn?   \u2502\u2500\u2500\u2500\u25b6 Skip if filter returns False\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502 passes\n           \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 key_fn(emp)  \u2502\u2500\u2500\u2500\u25b6 e.g., emp.department \u2192 \"Eng\"\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n           \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 value_fn(emp)\u2502\u2500\u2500\u2500\u25b6 e.g., emp.salary \u2192 120000.0\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n           \u25bc\n    groups[\"Eng\"].append(120000.0)\n           \u2502\n    After all employees:\n           \u2502\n           \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 _aggregate() \u2502\u2500\u2500\u2500\u25b6 SUM: 320000, AVG: 160000, etc.\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n           \u25bc\n    {\"Eng\": 320000, \"Sales\": 230000}\n```"
  },
  "approaches": [
    {
      "name": "Naive: Multiple Specialized Methods",
      "description": "Write separate methods: getSalaryByDepartment(), getAvgRatingByLevel(), etc.",
      "time_complexity": "O(n) each",
      "space_complexity": "O(k) groups",
      "why_not_optimal": "Code explosion - need new method for each combination. Not scalable or maintainable."
    },
    {
      "name": "Optimal: Functional Higher-Order Methods",
      "description": "Accept key/value extractors and aggregator as function parameters. Single generic method handles all combinations.",
      "time_complexity": "O(n)",
      "space_complexity": "O(n) worst case for collected values",
      "key_insight": "Functions as first-class citizens. The same pattern used by Stream.collect() in Java, pandas.groupby() in Python, and SQL GROUP BY."
    }
  ],
  "optimal_solution": {
    "explanation_md": "The solution uses the **MapReduce pattern** with functional programming:\n\n1. **Map Phase**: For each employee, extract (key, value) pair using provided functions\n2. **Shuffle Phase**: Group values by key using HashMap\n3. **Reduce Phase**: Apply aggregation function to each group's values\n\n**Key Design Decisions:**\n- `add_employee_extended` **delegates** to `add_employee` then sets extra fields - maintains DRY\n- `_aggregate` helper **centralizes** aggregation logic - easy to add new functions\n- `defaultdict(list)` / `computeIfAbsent` **elegantly handles** new groups\n- Both aggregation methods share `_aggregate` - **code reuse**",
    "data_structures": [
      {
        "structure": "defaultdict(list) / HashMap<String, List>",
        "purpose": "Collect values per group before aggregation"
      },
      {
        "structure": "dict / HashMap for result",
        "purpose": "Store final aggregated value per group"
      }
    ],
    "algorithm_steps": [
      "Step 1: Initialize empty groups dictionary",
      "Step 2: For each employee in self.employees.values():",
      "  - If filtering, skip if filter_fn(emp) is False",
      "  - Extract key = key_fn(emp)",
      "  - Extract value = value_fn(emp)",
      "  - Append value to groups[key]",
      "Step 3: For each (key, values) in groups:",
      "  - result[key] = _aggregate(values, agg_type)",
      "Step 4: Return result dictionary"
    ]
  },
  "solution_python_lines": [
    "from typing import Optional, List, Dict, Callable",
    "from collections import defaultdict",
    "",
    "class TeamStats:",
    "    \"\"\"Statistics for a team (employee + all subordinates).\"\"\"",
    "    def __init__(self, total_rating: int, team_size: int):",
    "        self.total_rating = total_rating",
    "        self.team_size = team_size",
    "        self.average = total_rating / team_size if team_size > 0 else 0.0",
    "",
    "",
    "class Employee:",
    "    \"\"\"Employee node with extended attributes for Part 3.\"\"\"",
    "    def __init__(self, id: int, name: str, rating: int):",
    "        self.id = id",
    "        self.name = name",
    "        self.rating = rating",
    "        self.manager: Optional['Employee'] = None",
    "        self.subordinates: List['Employee'] = []",
    "        # Part 3: Extended attributes",
    "        self.department: str = \"\"",
    "        self.level: int = 0",
    "        self.salary: float = 0.0",
    "    ",
    "    def __repr__(self):",
    "        return f\"Employee({self.id}, '{self.name}', dept={self.department})\"",
    "",
    "",
    "class OrgChart:",
    "    \"\"\"Org chart with hierarchy queries, team metrics, and aggregations.\"\"\"",
    "    ",
    "    def __init__(self):",
    "        self.employees: Dict[int, Employee] = {}",
    "        self.ceo: Optional[Employee] = None",
    "    ",
    "    # ========== Part 1 Methods ==========",
    "    ",
    "    def add_employee(self, id: int, name: str, rating: int,",
    "                     manager_id: Optional[int]) -> bool:",
    "        if id in self.employees:",
    "            return False",
    "        if manager_id is not None:",
    "            if manager_id not in self.employees:",
    "                return False",
    "            manager = self.employees[manager_id]",
    "        else:",
    "            if self.ceo is not None:",
    "                return False",
    "            manager = None",
    "        ",
    "        employee = Employee(id, name, rating)",
    "        employee.manager = manager",
    "        if manager:",
    "            manager.subordinates.append(employee)",
    "        else:",
    "            self.ceo = employee",
    "        self.employees[id] = employee",
    "        return True",
    "    ",
    "    def get_direct_report_count(self, employee_id: int) -> int:",
    "        if employee_id not in self.employees:",
    "            return -1",
    "        return len(self.employees[employee_id].subordinates)",
    "    ",
    "    def get_employee(self, employee_id: int) -> Optional[Employee]:",
    "        return self.employees.get(employee_id)",
    "    ",
    "    # ========== Part 2 Methods ==========",
    "    ",
    "    def get_team_stats(self, employee_id: int) -> Optional[TeamStats]:",
    "        if employee_id not in self.employees:",
    "            return None",
    "        total, size = self._compute_subtree_stats(self.employees[employee_id])",
    "        return TeamStats(total, size)",
    "    ",
    "    def _compute_subtree_stats(self, emp: Employee) -> tuple:",
    "        total, size = emp.rating, 1",
    "        for sub in emp.subordinates:",
    "            sub_total, sub_size = self._compute_subtree_stats(sub)",
    "            total += sub_total",
    "            size += sub_size",
    "        return (total, size)",
    "    ",
    "    def get_best_performing_team_lead(self) -> Optional[Employee]:",
    "        if self.ceo is None:",
    "            return None",
    "        best = [None, float('-inf')]",
    "        self._find_best_dfs(self.ceo, best)",
    "        return best[0]",
    "    ",
    "    def _find_best_dfs(self, emp: Employee, best: list) -> tuple:",
    "        total, size = emp.rating, 1",
    "        for sub in emp.subordinates:",
    "            sub_total, sub_size = self._find_best_dfs(sub, best)",
    "            total += sub_total",
    "            size += sub_size",
    "        avg = total / size",
    "        if avg > best[1]:",
    "            best[0], best[1] = emp, avg",
    "        return (total, size)",
    "    ",
    "    # ========== Part 3 Methods (NEW) ==========",
    "    ",
    "    def add_employee_extended(self, id: int, name: str, rating: int,",
    "                               dept: str, level: int, salary: float,",
    "                               manager_id: Optional[int]) -> bool:",
    "        \"\"\"Add employee with extended attributes. Delegates to add_employee.\"\"\"",
    "        if not self.add_employee(id, name, rating, manager_id):",
    "            return False",
    "        emp = self.employees[id]",
    "        emp.department = dept",
    "        emp.level = level",
    "        emp.salary = salary",
    "        return True",
    "    ",
    "    def group_by_aggregate(self, key_fn: Callable[[Employee], str],",
    "                           value_fn: Callable[[Employee], float],",
    "                           agg_type: str) -> Dict[str, float]:",
    "        \"\"\"Group all employees by key_fn, aggregate values with agg_type. O(n).\"\"\"",
    "        groups: Dict[str, List[float]] = defaultdict(list)",
    "        for emp in self.employees.values():",
    "            groups[key_fn(emp)].append(value_fn(emp))",
    "        return {k: self._aggregate(v, agg_type) for k, v in groups.items()}",
    "    ",
    "    def filter_group_by_aggregate(self, filter_fn: Callable[[Employee], bool],",
    "                                   key_fn: Callable[[Employee], str],",
    "                                   value_fn: Callable[[Employee], float],",
    "                                   agg_type: str) -> Dict[str, float]:",
    "        \"\"\"Filter employees, then group and aggregate. O(n).\"\"\"",
    "        groups: Dict[str, List[float]] = defaultdict(list)",
    "        for emp in self.employees.values():",
    "            if filter_fn(emp):",
    "                groups[key_fn(emp)].append(value_fn(emp))",
    "        return {k: self._aggregate(v, agg_type) for k, v in groups.items()}",
    "    ",
    "    def _aggregate(self, values: List[float], agg_type: str) -> float:",
    "        \"\"\"Apply aggregation to list of values.\"\"\"",
    "        if not values:",
    "            return 0.0",
    "        if agg_type == \"SUM\":",
    "            return sum(values)",
    "        elif agg_type == \"AVG\":",
    "            return sum(values) / len(values)",
    "        elif agg_type == \"MIN\":",
    "            return min(values)",
    "        elif agg_type == \"MAX\":",
    "            return max(values)",
    "        elif agg_type == \"COUNT\":",
    "            return float(len(values))",
    "        return 0.0",
    "",
    "",
    "if __name__ == '__main__':",
    "    print(\"=\" * 60)",
    "    print(\"Part 3: Generic Aggregation & Filtering\")",
    "    print(\"=\" * 60)",
    "    ",
    "    org = OrgChart()",
    "    ",
    "    # Build org with extended attributes",
    "    print(\"\\n1. Building organization with extended attributes...\")",
    "    org.add_employee_extended(1, 'Alice', 8, 'Engineering', 5, 200000, None)",
    "    org.add_employee_extended(2, 'Bob', 7, 'Engineering', 3, 120000, 1)",
    "    org.add_employee_extended(3, 'Carol', 6, 'Sales', 4, 150000, 1)",
    "    org.add_employee_extended(4, 'Dave', 5, 'Sales', 2, 80000, 3)",
    "    print(\"   Added: Alice(Eng,L5), Bob(Eng,L3), Carol(Sales,L4), Dave(Sales,L2)\")",
    "    ",
    "    # Test group_by_aggregate - Total salary by department",
    "    print(\"\\n2. Total Salary by Department (SUM):\")",
    "    result = org.group_by_aggregate(",
    "        lambda e: e.department,",
    "        lambda e: e.salary,",
    "        \"SUM\"",
    "    )",
    "    print(f\"   {result}\")",
    "    print(f\"   Expected: Engineering=320000, Sales=230000\")",
    "    ",
    "    # Test AVG rating by department",
    "    print(\"\\n3. Average Rating by Department (AVG):\")",
    "    result = org.group_by_aggregate(",
    "        lambda e: e.department,",
    "        lambda e: float(e.rating),",
    "        \"AVG\"",
    "    )",
    "    print(f\"   {result}\")",
    "    ",
    "    # Test filter_group_by_aggregate - Senior employees only (level >= 3)",
    "    print(\"\\n4. Avg Salary of Senior Employees (level >= 3) by Dept:\")",
    "    result = org.filter_group_by_aggregate(",
    "        lambda e: e.level >= 3,",
    "        lambda e: e.department,",
    "        lambda e: e.salary,",
    "        \"AVG\"",
    "    )",
    "    print(f\"   {result}\")",
    "    print(f\"   Senior: Alice(200k), Bob(120k), Carol(150k) -> Eng avg=160k, Sales=150k\")",
    "    ",
    "    # Test COUNT",
    "    print(\"\\n5. Employee Count by Department (COUNT):\")",
    "    result = org.group_by_aggregate(",
    "        lambda e: e.department,",
    "        lambda e: 1.0,  # value doesn't matter for COUNT",
    "        \"COUNT\"",
    "    )",
    "    print(f\"   {result}\")",
    "    ",
    "    # Edge case: Empty filter result",
    "    print(\"\\n6. Edge Case - No one matches filter (level > 10):\")",
    "    result = org.filter_group_by_aggregate(",
    "        lambda e: e.level > 10,",
    "        lambda e: e.department,",
    "        lambda e: e.salary,",
    "        \"SUM\"",
    "    )",
    "    print(f\"   {result}  (empty dict as expected)\")",
    "    ",
    "    print(\"\\n\" + \"=\" * 60)",
    "    print(\"All Part 3 tests passed!\")"
  ],
  "solution_java_lines": [
    "import java.util.*;",
    "import java.util.function.*;",
    "",
    "public class OrgChart {",
    "    private Map<Integer, Employee> employees = new HashMap<>();",
    "    private Employee ceo = null;",
    "    ",
    "    /** Employee with extended attributes for Part 3. */",
    "    public static class Employee {",
    "        int id;",
    "        String name;",
    "        int rating;",
    "        Employee manager;",
    "        List<Employee> subordinates = new ArrayList<>();",
    "        // Part 3: Extended attributes",
    "        String department = \"\";",
    "        int level = 0;",
    "        double salary = 0.0;",
    "        ",
    "        Employee(int id, String name, int rating) {",
    "            this.id = id;",
    "            this.name = name;",
    "            this.rating = rating;",
    "        }",
    "        ",
    "        public String toString() {",
    "            return \"Employee(\" + id + \", '\" + name + \"', dept=\" + department + \")\";",
    "        }",
    "    }",
    "    ",
    "    /** Team statistics for subtree. */",
    "    public static class TeamStats {",
    "        public int totalRating;",
    "        public int teamSize;",
    "        public double average;",
    "        ",
    "        TeamStats(int totalRating, int teamSize) {",
    "            this.totalRating = totalRating;",
    "            this.teamSize = teamSize;",
    "            this.average = teamSize > 0 ? (double) totalRating / teamSize : 0.0;",
    "        }",
    "    }",
    "    ",
    "    // ========== Part 1 Methods ==========",
    "    ",
    "    public boolean addEmployee(int id, String name, int rating, Integer managerId) {",
    "        if (employees.containsKey(id)) return false;",
    "        Employee manager;",
    "        if (managerId != null) {",
    "            if (!employees.containsKey(managerId)) return false;",
    "            manager = employees.get(managerId);",
    "        } else {",
    "            if (ceo != null) return false;",
    "            manager = null;",
    "        }",
    "        Employee employee = new Employee(id, name, rating);",
    "        employee.manager = manager;",
    "        if (manager != null) manager.subordinates.add(employee);",
    "        else ceo = employee;",
    "        employees.put(id, employee);",
    "        return true;",
    "    }",
    "    ",
    "    public int getDirectReportCount(int employeeId) {",
    "        if (!employees.containsKey(employeeId)) return -1;",
    "        return employees.get(employeeId).subordinates.size();",
    "    }",
    "    ",
    "    public Employee getEmployee(int employeeId) {",
    "        return employees.get(employeeId);",
    "    }",
    "    ",
    "    // ========== Part 2 Methods ==========",
    "    ",
    "    public TeamStats getTeamStats(int employeeId) {",
    "        if (!employees.containsKey(employeeId)) return null;",
    "        int[] stats = computeSubtreeStats(employees.get(employeeId));",
    "        return new TeamStats(stats[0], stats[1]);",
    "    }",
    "    ",
    "    private int[] computeSubtreeStats(Employee emp) {",
    "        int total = emp.rating, size = 1;",
    "        for (Employee sub : emp.subordinates) {",
    "            int[] subStats = computeSubtreeStats(sub);",
    "            total += subStats[0];",
    "            size += subStats[1];",
    "        }",
    "        return new int[]{total, size};",
    "    }",
    "    ",
    "    public Employee getBestPerformingTeamLead() {",
    "        if (ceo == null) return null;",
    "        Employee[] best = {null};",
    "        double[] bestAvg = {Double.NEGATIVE_INFINITY};",
    "        findBestDFS(ceo, best, bestAvg);",
    "        return best[0];",
    "    }",
    "    ",
    "    private int[] findBestDFS(Employee emp, Employee[] best, double[] bestAvg) {",
    "        int total = emp.rating, size = 1;",
    "        for (Employee sub : emp.subordinates) {",
    "            int[] subStats = findBestDFS(sub, best, bestAvg);",
    "            total += subStats[0];",
    "            size += subStats[1];",
    "        }",
    "        double avg = (double) total / size;",
    "        if (avg > bestAvg[0]) {",
    "            best[0] = emp;",
    "            bestAvg[0] = avg;",
    "        }",
    "        return new int[]{total, size};",
    "    }",
    "    ",
    "    // ========== Part 3 Methods (NEW) ==========",
    "    ",
    "    /** Add employee with extended attributes. */",
    "    public boolean addEmployeeExtended(int id, String name, int rating,",
    "            String dept, int level, double salary, Integer managerId) {",
    "        if (!addEmployee(id, name, rating, managerId)) return false;",
    "        Employee emp = employees.get(id);",
    "        emp.department = dept;",
    "        emp.level = level;",
    "        emp.salary = salary;",
    "        return true;",
    "    }",
    "    ",
    "    /** Group all employees by key, aggregate values. O(n). */",
    "    public Map<String, Double> groupByAggregate(",
    "            Function<Employee, String> keyFn,",
    "            Function<Employee, Double> valueFn,",
    "            String aggType) {",
    "        Map<String, List<Double>> groups = new HashMap<>();",
    "        for (Employee emp : employees.values()) {",
    "            String key = keyFn.apply(emp);",
    "            groups.computeIfAbsent(key, k -> new ArrayList<>()).add(valueFn.apply(emp));",
    "        }",
    "        Map<String, Double> result = new HashMap<>();",
    "        for (var entry : groups.entrySet()) {",
    "            result.put(entry.getKey(), aggregate(entry.getValue(), aggType));",
    "        }",
    "        return result;",
    "    }",
    "    ",
    "    /** Filter, then group and aggregate. O(n). */",
    "    public Map<String, Double> filterGroupByAggregate(",
    "            Predicate<Employee> filter,",
    "            Function<Employee, String> keyFn,",
    "            Function<Employee, Double> valueFn,",
    "            String aggType) {",
    "        Map<String, List<Double>> groups = new HashMap<>();",
    "        for (Employee emp : employees.values()) {",
    "            if (filter.test(emp)) {",
    "                String key = keyFn.apply(emp);",
    "                groups.computeIfAbsent(key, k -> new ArrayList<>()).add(valueFn.apply(emp));",
    "            }",
    "        }",
    "        Map<String, Double> result = new HashMap<>();",
    "        for (var entry : groups.entrySet()) {",
    "            result.put(entry.getKey(), aggregate(entry.getValue(), aggType));",
    "        }",
    "        return result;",
    "    }",
    "    ",
    "    /** Apply aggregation function to list of values. */",
    "    private double aggregate(List<Double> values, String aggType) {",
    "        if (values.isEmpty()) return 0.0;",
    "        switch (aggType) {",
    "            case \"SUM\": return values.stream().mapToDouble(d -> d).sum();",
    "            case \"AVG\": return values.stream().mapToDouble(d -> d).average().orElse(0);",
    "            case \"MIN\": return values.stream().mapToDouble(d -> d).min().orElse(0);",
    "            case \"MAX\": return values.stream().mapToDouble(d -> d).max().orElse(0);",
    "            case \"COUNT\": return (double) values.size();",
    "            default: return 0.0;",
    "        }",
    "    }",
    "    ",
    "    public static void main(String[] args) {",
    "        System.out.println(\"============================================================\");",
    "        System.out.println(\"Part 3: Generic Aggregation & Filtering\");",
    "        System.out.println(\"============================================================\");",
    "        ",
    "        OrgChart org = new OrgChart();",
    "        ",
    "        System.out.println(\"\\n1. Building organization with extended attributes...\");",
    "        org.addEmployeeExtended(1, \"Alice\", 8, \"Engineering\", 5, 200000, null);",
    "        org.addEmployeeExtended(2, \"Bob\", 7, \"Engineering\", 3, 120000, 1);",
    "        org.addEmployeeExtended(3, \"Carol\", 6, \"Sales\", 4, 150000, 1);",
    "        org.addEmployeeExtended(4, \"Dave\", 5, \"Sales\", 2, 80000, 3);",
    "        ",
    "        System.out.println(\"\\n2. Total Salary by Department (SUM):\");",
    "        var result = org.groupByAggregate(e -> e.department, e -> e.salary, \"SUM\");",
    "        System.out.println(\"   \" + result);",
    "        ",
    "        System.out.println(\"\\n3. Avg Salary of Senior (level>=3) by Dept:\");",
    "        result = org.filterGroupByAggregate(",
    "            e -> e.level >= 3,",
    "            e -> e.department,",
    "            e -> e.salary,",
    "            \"AVG\"",
    "        );",
    "        System.out.println(\"   \" + result);",
    "        ",
    "        System.out.println(\"\\n4. Employee Count by Department:\");",
    "        result = org.groupByAggregate(e -> e.department, e -> 1.0, \"COUNT\");",
    "        System.out.println(\"   \" + result);",
    "        ",
    "        System.out.println(\"\\n============================================================\");",
    "        System.out.println(\"All Part 3 tests passed!\");",
    "    }",
    "}"
  ],
  "code_walkthrough": [
    {
      "lines": "1-10",
      "explanation": "Imports including Callable for Python, Function/Predicate for Java to support functional parameters"
    },
    {
      "lines": "12-25",
      "explanation": "Extended Employee class with new department, level, salary attributes (initialized to defaults)"
    },
    {
      "lines": "90-100",
      "explanation": "add_employee_extended: Delegates to add_employee, then sets extended fields. Maintains DRY principle."
    },
    {
      "lines": "102-108",
      "explanation": "group_by_aggregate: Core MapReduce - iterate all employees, extract key/value, group, then aggregate each group"
    },
    {
      "lines": "110-120",
      "explanation": "filter_group_by_aggregate: Same as above but skip employees failing filter predicate"
    },
    {
      "lines": "122-135",
      "explanation": "_aggregate helper: Switch on agg_type to apply SUM/AVG/MIN/MAX/COUNT. Returns 0.0 for empty lists."
    }
  ],
  "complexity_analysis": {
    "time": {
      "new_methods": {
        "add_employee_extended": {
          "complexity": "O(1)",
          "explanation": "Delegates to O(1) add_employee, then 3 field assignments"
        },
        "group_by_aggregate": {
          "complexity": "O(n)",
          "explanation": "Single pass through n employees. key_fn, value_fn assumed O(1). Final aggregation O(total values) = O(n)"
        },
        "filter_group_by_aggregate": {
          "complexity": "O(n)",
          "explanation": "Same as above, filter check is O(1) per employee"
        },
        "_aggregate": {
          "complexity": "O(k)",
          "explanation": "k = size of values list. For all groups combined, total is O(n)"
        }
      },
      "overall_change": "Part 1/2 methods unchanged. New aggregation methods are O(n) which is optimal (must read all employees at least once)."
    },
    "space": {
      "additional_space": "O(n)",
      "explanation": "groups dictionary stores all values before aggregation. In worst case (all unique keys), stores n lists with 1 value each = O(n). Employee class adds 3 fields but that's per-employee, already counted."
    }
  },
  "dry_run": {
    "example_input": "4 employees: Alice(Eng,L5,$200k), Bob(Eng,L3,$120k), Carol(Sales,L4,$150k), Dave(Sales,L2,$80k). Query: group_by_aggregate(dept, salary, SUM)",
    "steps": [
      {
        "step": 1,
        "action": "Process Alice",
        "state": "groups = {Eng: [200000]}",
        "explanation": "key=Engineering, value=200000"
      },
      {
        "step": 2,
        "action": "Process Bob",
        "state": "groups = {Eng: [200000, 120000]}",
        "explanation": "key=Engineering, append 120000"
      },
      {
        "step": 3,
        "action": "Process Carol",
        "state": "groups = {Eng: [200000, 120000], Sales: [150000]}",
        "explanation": "key=Sales, new group"
      },
      {
        "step": 4,
        "action": "Process Dave",
        "state": "groups = {Eng: [200000, 120000], Sales: [150000, 80000]}",
        "explanation": "key=Sales, append 80000"
      },
      {
        "step": 5,
        "action": "Aggregate Eng",
        "state": "result = {Eng: 320000}",
        "explanation": "SUM([200000, 120000]) = 320000"
      },
      {
        "step": 6,
        "action": "Aggregate Sales",
        "state": "result = {Eng: 320000, Sales: 230000}",
        "explanation": "SUM([150000, 80000]) = 230000"
      }
    ],
    "final_output": "{\"Engineering\": 320000, \"Sales\": 230000}"
  },
  "debugging_playbook": {
    "fast_sanity_checks": [
      "Empty org returns empty dict",
      "Single employee returns single-key dict",
      "Unknown agg_type returns 0s"
    ],
    "likely_bugs": [
      "AVG returning integer division (use float)",
      "Empty filter result causing error (check for empty list in _aggregate)",
      "Forgetting to call value_fn (appending employee instead of value)"
    ],
    "recommended_logs_or_asserts": [
      "print(f'Groups before aggregation: {groups}')",
      "assert len(result) <= len(employees), 'More groups than employees impossible'"
    ],
    "how_to_localize": "1) Print groups dict after collection phase. 2) Verify key extraction. 3) Verify value extraction. 4) Check _aggregate output for one group."
  },
  "edge_cases": [
    {
      "case": "Empty organization",
      "handling": "employees.values() is empty, loop doesn't execute, returns {}",
      "gotcha": "Don't try to aggregate empty result"
    },
    {
      "case": "Filter excludes everyone",
      "handling": "groups stays empty, returns {}",
      "gotcha": "Return empty dict, not None or error"
    },
    {
      "case": "All employees same department",
      "handling": "Single key in result, all values in one list",
      "gotcha": "Works correctly, just one group"
    },
    {
      "case": "COUNT with any value_fn",
      "handling": "COUNT ignores actual values, counts list length",
      "gotcha": "Convention: pass lambda e: 1.0 or any value"
    },
    {
      "case": "AVG of single value",
      "handling": "sum/1 = the value itself",
      "gotcha": "Works correctly"
    },
    {
      "case": "Unknown agg_type",
      "handling": "Returns 0.0 for each group",
      "gotcha": "Consider throwing exception in production"
    }
  ],
  "test_cases": [
    {
      "name": "Basic SUM by department",
      "input": "4 employees, group_by_aggregate(dept, salary, SUM)",
      "expected": "{Engineering: 320000, Sales: 230000}",
      "explanation": "Eng: 200k+120k, Sales: 150k+80k"
    },
    {
      "name": "AVG rating by department",
      "input": "Same org, group_by_aggregate(dept, rating, AVG)",
      "expected": "{Engineering: 7.5, Sales: 5.5}",
      "explanation": "Eng: (8+7)/2, Sales: (6+5)/2"
    },
    {
      "name": "Filter senior + AVG salary",
      "input": "filter_group_by_aggregate(level>=3, dept, salary, AVG)",
      "expected": "{Engineering: 160000, Sales: 150000}",
      "explanation": "Senior: Alice, Bob, Carol. Dave excluded (L2)."
    },
    {
      "name": "COUNT employees",
      "input": "group_by_aggregate(dept, any, COUNT)",
      "expected": "{Engineering: 2.0, Sales: 2.0}",
      "explanation": "2 employees per department"
    }
  ],
  "common_mistakes": [
    {
      "mistake": "Using regular dict instead of defaultdict",
      "why_wrong": "KeyError on first append to new group",
      "correct_approach": "Use defaultdict(list) or check key existence",
      "code_example_wrong": "groups[key].append(value)  # KeyError if key not exists",
      "code_example_correct": "groups = defaultdict(list); groups[key].append(value)"
    },
    {
      "mistake": "Integer division for AVG",
      "why_wrong": "Python 2 or explicit int cast loses precision",
      "correct_approach": "Use float division",
      "code_example_wrong": "return sum(values) // len(values)",
      "code_example_correct": "return sum(values) / len(values)"
    },
    {
      "mistake": "Modifying Employee class destructively",
      "why_wrong": "Breaking Part 1/2 functionality",
      "correct_approach": "Add new fields with defaults, keep existing structure",
      "code_example_wrong": "class Employee: def __init__(self, id, name, rating, dept, level, salary):",
      "code_example_correct": "class Employee: def __init__(self, id, name, rating): ... self.department = ''"
    }
  ],
  "interview_tips": {
    "how_to_present": "Start by explaining this is a classic MapReduce/stream pattern. Draw the pipeline: filter\u2192group\u2192aggregate. Then explain you'll use higher-order functions to make it generic.",
    "what_to_mention": [
      "This is exactly how pandas groupby and SQL GROUP BY work",
      "Functional approach avoids code explosion from specialized methods",
      "Single pass O(n) is optimal - must read all employees",
      "Could easily add more aggregation types by extending _aggregate"
    ],
    "time_allocation": "2 min: understand requirements, 5 min: explain approach and extend Employee, 8 min: implement aggregation methods, 3 min: test",
    "if_stuck": [
      "Think about what pandas df.groupby('dept')['salary'].sum() does internally",
      "First collect all values into groups, then reduce each group",
      "Use HashMap<String, List<Double>> to collect before aggregating"
    ]
  },
  "connection_to_next_part": "Part 4 might add subtree aggregation (aggregate within someone's reporting chain) or time-based filtering (employees hired after date). The _aggregate helper and functional pattern make these extensions straightforward - just change which employees are iterated.",
  "communication_script": {
    "transition_from_previous": "Great, Part 2 finds the best performing team. For Part 3, I need to add generic aggregation - grouping employees by any attribute and applying any aggregation function. This is essentially building a mini analytics engine.",
    "explaining_changes": "The key insight is this is a MapReduce pattern: filter \u2192 groupBy \u2192 aggregate. Instead of writing separate methods for each combination, I'll accept functions as parameters. I need to extend Employee with department, level, salary, then add two generic aggregation methods.",
    "while_extending_code": [
      "First, I'll add the new fields to Employee with sensible defaults...",
      "add_employee_extended delegates to add_employee to maintain DRY...",
      "For group_by_aggregate, I collect all values into groups first, then aggregate each group...",
      "The _aggregate helper centralizes the logic for all aggregation types..."
    ],
    "after_completing": "This handles Part 3. Both aggregation methods are O(n) since we must visit every employee. The functional approach makes it trivial to add new aggregation types. Ready for Part 4?"
  },
  "time_milestones": {
    "time_budget": "15-18 minutes for this part",
    "by_3_min": "Understand new requirements, recognize MapReduce pattern, plan Employee extension",
    "by_8_min": "Employee extended, add_employee_extended working, group_by_aggregate structure in place",
    "by_15_min": "Both aggregation methods complete, _aggregate helper done, basic testing",
    "warning_signs": "If still designing at 8 min, simplify: skip filter version first. If stuck on functional syntax, use explicit loops."
  },
  "recovery_strategies": {
    "if_part_builds_wrong": "Aggregation methods are independent of Part 1/2, so bugs there won't affect this. But if Employee class is broken, fix it first.",
    "if_new_requirement_unclear": "Ask: 'Should filter_group_by_aggregate return empty dict or throw if nothing matches?' 'What should unknown agg_type do?'",
    "if_running_behind": "Implement group_by_aggregate first (simpler). Mention filter version would just add an if check. Skip edge case handling, mention verbally."
  },
  "signal_points": {
    "wow_factors_for_followup": [
      "Immediately recognizing MapReduce/stream pattern",
      "Mentioning this is how pandas/SQL GROUP BY works internally",
      "Noting that functional parameters avoid code explosion",
      "Discussing memory tradeoff (collect vs running accumulator)",
      "Proactively extending _aggregate to be easily modifiable"
    ]
  },
  "pattern_recognition": {
    "pattern": "MapReduce / GroupBy-Aggregate / Stream Processing",
    "indicators": [
      "Group by any attribute suggests parameterized grouping",
      "Multiple aggregation types suggests generic reduce",
      "Filter before aggregate is classic stream pipeline"
    ],
    "similar_problems": [
      "LC 1070 - Product Sales Analysis III (GROUP BY pattern)",
      "LC 1158 - Market Analysis I (aggregation)",
      "Any SQL GROUP BY query implementation"
    ],
    "template": "```python\ngroups = defaultdict(list)\nfor item in items:\n    if filter_fn(item):\n        groups[key_fn(item)].append(value_fn(item))\nreturn {k: aggregate(v) for k, v in groups.items()}\n```"
  },
  "thinking_process": [
    {
      "step": 1,
      "thought": "When I see 'group by any attribute', I immediately think of parameterized key extraction",
      "why": "Hardcoding department/level/etc would cause code explosion"
    },
    {
      "step": 2,
      "thought": "Multiple aggregation types suggests a reduce function parameter",
      "why": "Same reason - avoid writing sum_by_dept, avg_by_dept, etc."
    },
    {
      "step": 3,
      "thought": "Filter-group-aggregate is the classic stream pipeline",
      "why": "This is exactly SQL: SELECT dept, SUM(salary) FROM emp WHERE level>=3 GROUP BY dept"
    },
    {
      "step": 4,
      "thought": "Collect then aggregate vs running accumulator",
      "why": "Collect is cleaner and handles MIN/MAX/AVG uniformly; running is memory-efficient but complex"
    }
  ],
  "interviewer_perspective": {
    "what_they_evaluate": [
      "Can you recognize and apply the MapReduce pattern?",
      "Do you understand higher-order functions?",
      "Can you extend code cleanly without rewriting?",
      "Do you handle edge cases (empty results, unknown types)?"
    ],
    "bonus_points": [
      "Connecting to real-world (pandas, SQL)",
      "Discussing collect vs running accumulator tradeoff",
      "Clean helper method extraction (_aggregate)",
      "Mentioning how to add new aggregation types"
    ],
    "red_flags": [
      "Writing separate methods for each group-by combination",
      "Not understanding how to pass functions as parameters",
      "Breaking existing functionality",
      "Overcomplicating with unnecessary abstractions"
    ]
  },
  "ai_copilot_tips": {
    "what_to_do": [
      "Use AI for boilerplate (defaultdict import, lambda syntax)",
      "Let it help with Java functional interface syntax (Function, Predicate)",
      "Ask for stream API equivalents if unsure"
    ],
    "what_not_to_do": [
      "Don't let AI dictate the overall MapReduce approach - understand it yourself",
      "Don't accept overly complex stream chains without understanding",
      "Verify lambda syntax matches your intent"
    ]
  },
  "red_flags_to_avoid": {
    "behavioral": [
      "Jumping to code without explaining the pattern",
      "Not asking about edge cases (empty filter, unknown agg)"
    ],
    "technical": [
      "Writing specialized methods instead of generic ones",
      "Mutating employees list during iteration",
      "Forgetting float division for AVG"
    ],
    "communication": [
      "Not mentioning this is MapReduce pattern",
      "Forgetting to test with provided example",
      "Not explaining why functional approach is better"
    ]
  },
  "final_checklist": {
    "before_saying_done": [
      "Does group_by_aggregate work with the example (SUM salary by dept)?",
      "Does filter_group_by_aggregate correctly exclude employees?",
      "Does _aggregate handle all 5 types (SUM, AVG, MIN, MAX, COUNT)?",
      "Does empty filter result return {} not error?",
      "Are Part 1/2 methods still working?"
    ],
    "quick_code_review": [
      "No unused imports",
      "Consistent naming (snake_case Python, camelCase Java)",
      "Type hints on new methods",
      "Employee extended fields have defaults"
    ]
  },
  "production_considerations": {
    "what_i_would_add": [
      "Enum for AggregateType instead of string",
      "Validation on agg_type with descriptive error",
      "Caching for frequently-run aggregations",
      "Logging aggregation queries for analytics"
    ],
    "why_not_in_interview": "Focus on demonstrating the pattern; mention these verbally",
    "how_to_mention": "Say: 'In production, I'd use an enum for type safety on aggType, add validation, and potentially cache frequent queries.'"
  },
  "generated_at": "2026-01-19T04:40:17.980640",
  "_meta": {
    "problem_id": "employee_hierarchy_org_tree",
    "part_number": 3,
    "model": "claude-opus-4-5-20251101"
  }
}